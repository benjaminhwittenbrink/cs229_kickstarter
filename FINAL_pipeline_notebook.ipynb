{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5939ab2-77fb-4d71-8de6-1853c972c626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import json\n",
    "\n",
    "from model_metrics import format_results\n",
    "import data_clean_for_model\n",
    "import PipelineHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d791bc-227a-4158-bc75-07ad70a5aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level = logging.INFO, \n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a8502e-bad9-4655-acc6-30c9d20f2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Load Data\n",
    "df = pd.read_parquet(\"data/all_processed_df.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8d8b9f-8517-48c5-ad79-cfb406eff77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "rseed = 229\n",
    "df[\"outcome\"] = np.where( df[\"state\"]==\"successful\", 1, 0, )\n",
    "df[\"un_id\"] = np.arange(0, df.shape[0], 1 )\n",
    "df[\"name_len\"] = df[\"name\"].str.len()\n",
    "df[\"cv_group\"] = np.random.choice( np.arange(0, k), size=df.shape[0] )\n",
    "df[\"binned_usd_goal\"] = pd.qcut( np.log(df[\"usd_goal\"]+1), 20 )\n",
    "\n",
    "with open(\"model_config.json\", 'r') as j:\n",
    "     model_params = json.loads(j.read())\n",
    "model_params['naive_bayes']['ngram_range'] = tuple(model_params['naive_bayes']['ngram_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d5d1c6-3ebc-4af4-b08a-9a0aaa05f509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:05:21 INFO     Loading features\n"
     ]
    }
   ],
   "source": [
    "## load project metadata\n",
    "logger.info(\"Loading features\")\n",
    "_refresh = False\n",
    "try:\n",
    "    if _refresh: raise Exception(\"Reloading\")\n",
    "    f = open(\"data/features.pkl\", \"rb\")\n",
    "    ft_dict = pickle.load(f)\n",
    "    f.close()\n",
    "    X_train, y_train, X_test, y_test = ft_dict.values()\n",
    "except:\n",
    "    X_train, X_test, y_train, y_test = data_clean_for_model.data_clean_for_model(df, \"outcome\", model_params, cv=model_params[\"cv\"])\n",
    "    f = open(\"data/features.pkl\", \"wb\")\n",
    "    pickle.dump({\n",
    "        'X_train':X_train, 'y_train':y_train, 'X_test':X_test, 'y_test':y_test\n",
    "    }, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b413f82b-ccf4-4b6c-9f55-0aad924d507d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:05:21 INFO     Processing text data\n"
     ]
    }
   ],
   "source": [
    "# load text\n",
    "logger.info(\"Processing text data\")\n",
    "blurb_train, blurb_test, _, _    = data_clean_for_model.process_blurb(df, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7af42c4-e439-45f6-b9e9-0ffa37a1807f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:05:24 INFO     Loading Naive Bayes predictions\n",
      "2021-06-02 23:05:24 INFO     Loading LDA topic predictions\n",
      "2021-06-02 23:05:24 INFO     Loading Word2Vec dimension predictions\n"
     ]
    }
   ],
   "source": [
    "## 2. Run text models\n",
    "\n",
    "try: \n",
    "    f = open(\"data/res/text_models.pkl\", \"rb\")\n",
    "    text_models = pickle.load(f)\n",
    "    f.close()\n",
    "except:\n",
    "    raise Warning(\"Text models do not exist. Will load from scratch\")\n",
    "# get naive bayes predictions\n",
    "logger.info(\"Loading Naive Bayes predictions\")\n",
    "try:\n",
    "    #nb_proba_train = np.load(\"data/res/multi_nb_preds_train.npy\")\n",
    "    #nb_proba_test = np.load(\"data/res/multi_nb_preds_test.npy\")\n",
    "    nb_proba_train, nb_proba_test = text_models['nb_train'], text_models['nb_test']\n",
    "except:\n",
    "    logger.info(\"Running Naive Bayes model\")\n",
    "    nb_params = model_params['naive_bayes']\n",
    "    nb_train_pred, nb_proba_train, nb_test_pred, nb_proba_test = PipelineHelper.naive_bayes_predictions(\n",
    "        blurb_train, y_train, blurb_test,\n",
    "        tfidf=nb_params['tf-idf'], ngram_range=nb_params['ngram_range']\n",
    "    )\n",
    "    np.save(\"data/res/multi_nb_preds_train.npy\", nb_proba_train)\n",
    "    np.save(\"data/res/multi_nb_preds_test.npy\", nb_proba_test)\n",
    "\n",
    "# get LDA topic model\n",
    "logger.info(\"Loading LDA topic predictions\")\n",
    "try:\n",
    "    lda_train, lda_test = text_models['lda_train'], text_models['lda_test']\n",
    "    #lda_train = pd.read_csv(\"data/res/lda_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "    #lda_test = pd.read_csv(\"data/res/lda_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "except:\n",
    "    logger.info(\"Running LDA topic model\")\n",
    "    lda_params = model_params['lda']\n",
    "    tokenized_train = blurb_train.apply(data_clean_for_model.tokenize_text)\n",
    "    tokenized_test = blurb_test.apply(data_clean_for_model.tokenize_text)\n",
    "    lda_train, lda_test = PipelineHelper.train_lda_model(tokenized_train, tokenized_test, params['lda'])\n",
    "    lda_train.to_csv(\"data/res/lda_train.csv\")\n",
    "    lda_test.to_csv(\"data/res/lda_test.csv\")\n",
    "\n",
    "# get Word2Vec model predictions\n",
    "logger.info(\"Loading Word2Vec dimension predictions\")\n",
    "try:\n",
    "    #f = open(\"data/res/w2v_dict.pkl\", \"rb\")\n",
    "    #w2v_dict = pickle.load(f)\n",
    "    #f.close()\n",
    "    #w2v_train, w2v_test = w2v_dict.values()\n",
    "    w2v_train, w2v_test = text_models['w2v_train'], text_models['w2v_test']\n",
    "except:\n",
    "    raise Warning(\"Word2Vec function not implemented. Running without it -- likely will crash.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1481d846-e71c-4a0b-b28c-d527165ab84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ignore=True\n",
    "if not _ignore: \n",
    "    text_models = {\n",
    "        'nb_train':nb_proba_train, \n",
    "        'nb_test':nb_proba_test,\n",
    "        'lda_train':lda_train, \n",
    "        'lda_test':lda_test,\n",
    "        'w2v_train':w2v_train, \n",
    "        'w2v_test':w2v_test\n",
    "    }\n",
    "    f = open(\"data/res/text_models.pkl\", \"wb\")\n",
    "    pickle.dump(text_models, f)\n",
    "    f.close()\n",
    "    \n",
    "_increment_rseed = False\n",
    "if _increment_rseed: \n",
    "    model_params['rseed'] += 1\n",
    "    model_params['rseed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c341fc-2410-4cf0-83b6-3339de1e6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = [\"un_id\", \"cv_group\"]\n",
    "id_train = X_train[id_vars]\n",
    "id_test = X_test[id_vars]\n",
    "X_train = X_train.drop(columns=id_vars)\n",
    "X_test = X_test.drop(columns=id_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6604263-6d0e-4d71-ad97-589ab7687cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': True,\n",
       " 'test_frac': 0.3,\n",
       " 'lnom_usdgoal': True,\n",
       " 'dummies': True,\n",
       " 'rseed': 229,\n",
       " 'naive_bayes': {'tf-idf': True, 'ngram_range': (1, 1)},\n",
       " 'lda': {'corpus': {'no_below': 10, 'no_above': 0.35},\n",
       "  'n_topics': 20,\n",
       "  'chunksize': 100,\n",
       "  'passes': 50,\n",
       "  'rseed': 229},\n",
       " 'linear_models': {'lasso_alpha': 0.75,\n",
       "  'ridge_alpha': 0.75,\n",
       "  'logreg_C': 1000,\n",
       "  'logreg_penalty': 'none'},\n",
       " 'lightgbm': {'bagging_fraction': 0.75,\n",
       "  'feature_fraction': 0.2,\n",
       "  'max_depth': 55,\n",
       "  'max_bin': 500,\n",
       "  'num_leaves': 400,\n",
       "  'lambda_l1': 0,\n",
       "  'lambda_l2': 0},\n",
       " 'random_forest': {'bootstrap': False,\n",
       "  'max_depth': 55,\n",
       "  'max_features': 'auto',\n",
       "  'min_samples_leaf': 10,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 200},\n",
       " 'svm': {'C': 0.1, 'dual': False, 'class_weight': 'balanced'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2c57d7-5c25-4626-972f-f399935667a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:05:24 INFO     Getting metadata results\n",
      "2021-06-02 23:05:24 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.19718e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "2021-06-02 23:05:34 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:05:38 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### a. Just on metadata\n",
    "logger.info(\"Getting metadata results\")\n",
    "stat_df, pred_df, models = PipelineHelper.run_analyses(X_train, y_train, X_test, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e8adcfa-361d-40cd-82cf-6a081153e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:07:45 INFO     Getting metadata - binned_usd_goal_outcome_mean results\n",
      "2021-06-02 23:07:45 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.19718e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2021-06-02 23:07:54 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:07:59 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### b. Just on metadata, - binned_usd_goal_outcome_mean\n",
    "logger.info(\"Getting metadata - binned_usd_goal_outcome_mean results\")\n",
    "stat_df_nobinusd, pred_df_nobinusd, models_nobinusd = PipelineHelper.run_analyses(\n",
    "    X_train.drop(columns=['binned_usd_goal_outcome_mean']), y_train, \n",
    "    X_test.drop(columns=['binned_usd_goal_outcome_mean']), y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cbfd208-9ad4-4ffb-b2ac-280787a10db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:09:58 INFO     Getting metadata + naive bayes results\n",
      "2021-06-02 23:09:58 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.1972e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "2021-06-02 23:10:07 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:10:11 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### c. Just on metadata + nb \n",
    "logger.info(\"Getting metadata + naive bayes results\")\n",
    "X_train_nb = X_train.copy()\n",
    "X_test_nb = X_test.copy()\n",
    "# NB \n",
    "X_train_nb['nb_proba'] = nb_proba_train[:, 1]\n",
    "X_test_nb['nb_proba'] = nb_proba_test[:, 1]\n",
    "stat_df_nb, pred_df_nb, models_nb = PipelineHelper.run_analyses(X_train_nb, y_train, X_test_nb, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c77140a-458a-467a-ae65-3ffda3a94431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:13:42 INFO     Getting metadata + naive bayes + LDA results\n",
      "2021-06-02 23:13:42 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.19707e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "2021-06-02 23:13:52 INFO     Fitting lightgbm\n",
      "2021-06-02 23:13:59 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### d. Just on metadata + nb + lda\n",
    "logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "X_train_nb_lda = pd.concat((X_train_nb, lda_train), axis=1)\n",
    "X_test_nb_lda = pd.concat((X_test_nb, lda_test), axis=1)\n",
    "stat_df_nb_lda, pred_df_nb_lda, models_nb_lda = PipelineHelper.run_analyses(X_train_nb_lda, y_train, X_test_nb_lda, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4875a726-87b3-47f6-8767-a910190fbdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:15:23 INFO     Getting metadata + naive bayes + w2v results\n",
      "2021-06-02 23:15:26 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "2021-06-02 23:15:57 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:16:26 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### e. Just on metadata + nb + w2v\n",
    "logger.info(\"Getting metadata + naive bayes + w2v results\")\n",
    "X_train_nb_w2v = pd.concat((X_train_nb, pd.DataFrame(w2v_train)), axis=1)\n",
    "X_test_nb_w2v = pd.concat((X_test_nb, pd.DataFrame(w2v_test)), axis=1)\n",
    "stat_df_nb_w2v, pred_df_nb_w2v, models_nb_w2v = PipelineHelper.run_analyses(X_train_nb_w2v, y_train, X_test_nb_w2v, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14d8f514-855e-433b-a933-8a2d04a18e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:22:16 INFO     Getting metadata + naive bayes + LDA results\n",
      "2021-06-02 23:22:17 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.8325e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2021-06-02 23:22:27 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:22:33 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### f. Just on metadata + nb + lda - cols to drop \n",
    "logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "cols_to_drop = [\n",
    "    'dummy_cat_id_290', 'dummy_cat_id_300', 'dummy_cat_id_317','dummy_cat_id_386', 'dummy_cat_id_352', #'dummy_cat_id_1',\n",
    "    'dummy_cat_id_355', 'dummy_cat_id_354', 'dummy_cat_id_321', 'dummy_cat_id_12', 'dummy_cat_id_340', 'dummy_cat_id_268', 'binned_usd_goal_outcome_mean'\n",
    "]\n",
    "stat_df_nb_lda_drop, pred_df_nb_lda_drop, models_nb_lda_drop = PipelineHelper.run_analyses(\n",
    "    X_train_nb_lda.drop(columns=cols_to_drop), y_train, \n",
    "    X_test_nb_lda.drop(columns=cols_to_drop), y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16d2d9ef-6c10-4492-9f5f-73d0ec095006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:23:47 INFO     Getting metadata + naive bayes w/ scaled vars\n",
      "2021-06-02 23:23:47 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-06-02 23:23:55 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:24:00 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### g. Just on metadata + nb, scaled vars \n",
    "model_params['linear_models']['logreg_penalty'] = 'l2'\n",
    "model_params['linear_models']['logreg_C'] = 0.75\n",
    "model_params['linear_models']['ridge_alpha'] = 0.5\n",
    "model_params['linear_models']['lasso_alpha'] = 1\n",
    "\n",
    "X_train_nb_scale, X_test_nb_scale = PipelineHelper.scale_data(X_train_nb, X_test_nb)\n",
    "logger.info(\"Getting metadata + naive bayes w/ scaled vars\")\n",
    "stat_df_nb_scale, pred_df_nb_scale, models_nb_scale = PipelineHelper.run_analyses(\n",
    "    X_train_nb_scale, y_train, \n",
    "    X_test_nb_scale, y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ae0909e-97d2-4b20-a214-b19693a4d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:24:53 INFO     Getting metadata + naive bayes w/ scaled vars\n",
      "2021-06-02 23:24:53 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-06-02 23:25:01 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:25:05 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### g. Just on metadata, scaled vars \n",
    "#X_train_nb_scale, X_test_nb_scale = PipelineHelper.scale_data(X_train_nb, X_test_nb)\n",
    "logger.info(\"Getting metadata + naive bayes w/ scaled vars\")\n",
    "stat_df_scale, pred_df_scale, models_scale = PipelineHelper.run_analyses(\n",
    "    X_train_nb_scale.drop(columns=['nb_proba']), y_train, \n",
    "    X_test_nb_scale.drop(columns=['nb_proba']), y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b9cde1b-e236-42be-80e2-a492e3066638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:25:56 INFO     Getting metadata + naive bayes + lda w/ scaled vars\n",
      "2021-06-02 23:25:56 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-06-02 23:26:05 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:26:13 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### h. Metadata + nb + lda, scaled vars \n",
    "X_train_nb_lda_scale, X_test_nb_lda_scale = PipelineHelper.scale_data(X_train_nb_lda, X_test_nb_lda, addtl_cols=lda_train.columns)\n",
    "logger.info(\"Getting metadata + naive bayes + lda w/ scaled vars\")\n",
    "stat_df_nb_lda_scale, pred_df_nb_lda_scale, models_nb_lda_scale = PipelineHelper.run_analyses(\n",
    "    X_train_nb_lda_scale, y_train, \n",
    "    X_test_nb_lda_scale, y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faae7cb7-a7df-463c-b20e-ae8cab400be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:27:46 INFO     Getting metadata + naive bayes + w2v w/ scaled vars\n",
      "2021-06-02 23:27:46 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-06-02 23:28:03 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:28:32 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### i. Metadata + nb + w2v, scaled vars \n",
    "X_train_nb_w2v_scale, X_test_nb_w2v_scale = PipelineHelper.scale_data(X_train_nb_w2v, X_test_nb_w2v, addtl_cols=w2v_train.columns)\n",
    "logger.info(\"Getting metadata + naive bayes + w2v w/ scaled vars\")\n",
    "stat_df_nb_w2v_scale, pred_df_nb_w2v_scale, models_nb_w2v_scale = PipelineHelper.run_analyses(\n",
    "    X_train_nb_w2v_scale, y_train, \n",
    "    X_test_nb_w2v_scale, y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34fdd94b-9f9d-4034-b1c2-2c28ec5a1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_nlp_sentiment = pd.read_csv(\"data/res/sentiment_col.csv\")\n",
    "core_nlp_sentiment['un_id'] = np.arange(0, core_nlp_sentiment.shape[0], 1 )\n",
    "core_nlp_train = id_train.merge(core_nlp_sentiment, on=\"un_id\", how=\"left\")\n",
    "core_nlp_test = id_test.merge(core_nlp_sentiment, on=\"un_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "896cecee-6213-483b-898d-4dc54df2d0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:35:00 INFO     Getting metadata + naive bayes + w2v w/ scaled vars\n",
      "2021-06-02 23:35:00 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.14157e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "2021-06-02 23:35:11 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 23:35:17 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### i. Metadata + nb + w2v, scaled vars \n",
    "X_train_nb_nlp = X_train_nb.copy()\n",
    "X_test_nb_nlp = X_test_nb.copy()\n",
    "X_train_nb_nlp['sentiment'] = core_nlp_train['sentiment']\n",
    "X_test_nb_nlp['sentiment'] = core_nlp_test['sentiment']\n",
    "logger.info(\"Getting metadata + naive bayes + w2v w/ scaled vars\")\n",
    "stat_df_nb_nlp, pred_df_nb_nlp, models_nb_nlp = PipelineHelper.run_analyses(\n",
    "    X_train_nb_nlp, y_train, \n",
    "    X_test_nb_nlp, y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c8a4414-da7d-4e9e-8d5a-6fabf282b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j. neural net (takes FOREVER so am just loading in one model on X_train_nb) \n",
    "load_nn=True\n",
    "if load_nn:\n",
    "    import tensorflow as tf \n",
    "    from model_metrics import calculate_performance\n",
    "    nn = tf.keras.models.load_model(\"data/nns/nn_batch5_epochs30_dim_25.tf\")\n",
    "    ypred = nn.predict(X_test_nb_scale)\n",
    "    ypred = np.round(ypred.ravel())\n",
    "    res = calculate_performance(y_test, ypred)\n",
    "    res = [\"KerasClassifier\"] + res\n",
    "    res = [\"metadata_nb_scale\"] + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21bf0d89-4d56-47d8-8f5f-9ced834f6748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.81, 0.85, 0.83, 0.78, 0.86, 0.74, 0.8, 0.19]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.round(i, 2) for i in res if type(i)!=str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b2b87f9-27bd-4256-8fdb-eacf0fa2142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df.insert(0, \"data\", \"metadata\"), \n",
    "stat_df_nobinusd.insert(0, \"data\", \"metadata_nobin\"), \n",
    "stat_df_nb.insert(0, \"data\", \"metadata_nb\"),\n",
    "stat_df_nb_lda.insert(0, \"data\", \"metadata_nb_lda\"),\n",
    "stat_df_nb_w2v.insert(0, \"data\", \"metadata_nb_w2v\"),\n",
    "stat_df_nb_lda_drop.insert(0, \"data\", \"metadata_nb_lda_drop\")\n",
    "stat_df_nb_scale.insert(0, \"data\", \"metadata_nb_scale\")\n",
    "stat_df_nb_lda_scale.insert(0, \"data\", \"metadata_nb_lda_scale\")\n",
    "stat_df_nb_w2v_scale.insert(0, \"data\", \"metadata_nb_w2v_scale\")\n",
    "stat_df_nb_nlp.insert(0, \"data\", \"metadata_nb_nlp\")\n",
    "stat_df_scale.insert(0, \"data\", \"metadata_scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8027d3b-1b9c-44c0-babd-14174e045f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = (pd.concat((stat_df, stat_df_scale, stat_df_nobinusd, stat_df_nb, stat_df_nb_lda, stat_df_nb_w2v, stat_df_nb_lda_drop, stat_df_nb_scale, stat_df_nb_lda_scale, stat_df_nb_w2v_scale, stat_df_nb_nlp))\n",
    "       .sort_values('accuracy', ascending=False)\n",
    "       .assign(\n",
    "           accuracy_rank = lambda x:np.arange(1, x.shape[0]+1, 1), \n",
    "           random_state = model_params['rseed']\n",
    "       )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab181e83-66ce-48c6-9adf-0d69b0e3f461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrrrr}\n",
      "\\toprule\n",
      "{} &               data &                   model &  accuracy &  f1\\_score &  precision\\_1 &  precision\\_0 &  recall\\_1 &  recall\\_0 \\\\\n",
      "\\midrule\n",
      "0 &        metadata\\_nb &          LGBMClassifier &      0.83 &      0.85 &         0.89 &         0.75 &      0.81 &      0.84 \\\\\n",
      "0 &  metadata\\_nb\\_scale &          LGBMClassifier &      0.83 &      0.85 &         0.89 &         0.75 &      0.81 &      0.84 \\\\\n",
      "1 &        metadata\\_nb &  RandomForestClassifier &      0.82 &      0.84 &         0.88 &         0.74 &      0.80 &      0.84 \\\\\n",
      "1 &  metadata\\_nb\\_scale &  RandomForestClassifier &      0.81 &      0.84 &         0.88 &         0.73 &      0.80 &      0.84 \\\\\n",
      "2 &        metadata\\_nb &                   Ridge &      0.80 &      0.83 &         0.83 &         0.75 &      0.84 &      0.74 \\\\\n",
      "2 &  metadata\\_nb\\_scale &                   Ridge &      0.80 &      0.83 &         0.83 &         0.75 &      0.84 &      0.74 \\\\\n",
      "0 &        metadata\\_nb &        LinearRegression &      0.80 &      0.83 &         0.83 &         0.75 &      0.84 &      0.74 \\\\\n",
      "0 &  metadata\\_nb\\_scale &        LinearRegression &      0.80 &      0.83 &         0.83 &         0.75 &      0.84 &      0.74 \\\\\n",
      "3 &  metadata\\_nb\\_scale &      LogisticRegression &      0.80 &      0.83 &         0.86 &         0.72 &      0.79 &      0.80 \\\\\n",
      "1 &        metadata\\_nb &                   Lasso &      0.70 &      0.76 &         0.72 &         0.65 &      0.81 &      0.53 \\\\\n",
      "3 &        metadata\\_nb &      LogisticRegression &      0.67 &      0.73 &         0.72 &         0.59 &      0.74 &      0.57 \\\\\n",
      "1 &  metadata\\_nb\\_scale &                   Lasso &      0.60 &      0.75 &         0.60 &         0.00 &      1.00 &      0.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.round(fin[np.logical_or(fin.data==\"metadata_nb\", fin.data==\"metadata_nb_scale\")][['data', 'model', 'accuracy', 'f1_score', 'precision_1', 'precision_0','recall_1', 'recall_0']],2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "558d9ca2-72c8-435c-b30c-e026977bb83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "             data &                  model &  accuracy &  f1\\_score &  precision\\_1 &  precision\\_0 &  recall\\_1 &  recall\\_0 \\\\\n",
      "\\midrule\n",
      "      metadata\\_nb &         LGBMClassifier &      0.83 &      0.85 &         0.89 &         0.75 &      0.81 &      0.84 \\\\\n",
      "metadata\\_nb\\_scale &         LGBMClassifier &      0.83 &      0.85 &         0.89 &         0.75 &      0.81 &      0.84 \\\\\n",
      "      metadata\\_nb & RandomForestClassifier &      0.82 &      0.84 &         0.88 &         0.74 &      0.80 &      0.84 \\\\\n",
      "metadata\\_nb\\_scale & RandomForestClassifier &      0.81 &      0.84 &         0.88 &         0.73 &      0.80 &      0.84 \\\\\n",
      "      metadata\\_nb &                  Ridge &      0.80 &      0.83 &         0.83 &         0.75 &      0.84 &      0.74 \\\\\n",
      "metadata\\_nb\\_scale &                  Ridge &      0.80 &      0.83 &         0.83 &         0.75 &      0.84 &      0.74 \\\\\n",
      "      metadata\\_nb &       LinearRegression &      0.80 &      0.83 &         0.83 &         0.75 &      0.84 &      0.74 \\\\\n",
      "metadata\\_nb\\_scale &       LinearRegression &      0.80 &      0.83 &         0.83 &         0.75 &      0.84 &      0.74 \\\\\n",
      "metadata\\_nb\\_scale &     LogisticRegression &      0.80 &      0.83 &         0.86 &         0.72 &      0.79 &      0.80 \\\\\n",
      "      metadata\\_nb &                  Lasso &      0.70 &      0.76 &         0.72 &         0.65 &      0.81 &      0.53 \\\\\n",
      "      metadata\\_nb &     LogisticRegression &      0.67 &      0.73 &         0.72 &         0.59 &      0.74 &      0.57 \\\\\n",
      "metadata\\_nb\\_scale &                  Lasso &      0.60 &      0.75 &         0.60 &         0.00 &      1.00 &      0.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.round(fin[np.logical_or(fin.data==\"metadata_nb\", fin.data==\"metadata_nb_scale\")][['data', 'model', 'accuracy', 'f1_score', 'precision_1', 'precision_0','recall_1', 'recall_0']],2).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab11ad8-1687-42ab-a514-ac8949ebde8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
