{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f8f71cd-8353-4f66-b480-289cd13a6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import json \n",
    "import os\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0d19957-408c-4be9-8c8e-a93d8a3d94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb309b2-20b7-4986-a05b-84a7d1253a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_loc = \"/Users/benji/Downloads/Kickstarter_2021-04-15T03_20_08_451Z/\"\n",
    "#file_loc = \"/Users/benji/Downloads/Kickstarter_2021-03-18T03_20_11_507Z/\"\n",
    "file_loc = \"/Users/benji/Downloads/Kickstarter_2021-02-11T03_20_07_976Z/\"\n",
    "file_loc = \"/Users/benji/Downloads/Kickstarter_2020-04-16T03_20_04_541Z/\"\n",
    "files = sorted(os.listdir(file_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03c7f544-4e17-4cd3-927f-26efe711bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(path_to_file):\n",
    "    \"\"\"\n",
    "    Note: main speed limitation is json.loads() which is ~ slow \n",
    "    Averages around 1.65 seconds per iteration w/ a dataframe ~ 3k rows \n",
    "    \"\"\"\n",
    "    \n",
    "    # load df \n",
    "    df = pd.read_csv(path_to_file)\n",
    "    # filter rows to finished projects  \n",
    "    df = df[df['state'].isin(['successful', 'failed'])]\n",
    "    # add some features \n",
    "    df = df.assign(\n",
    "        usd_goal = lambda x:x['goal'] * x['fx_rate'], \n",
    "        available_time = lambda x:x['deadline'] - x['launched_at'], # figure out how time is encoded?? \n",
    "        blurb_len = lambda x:x['blurb'].str.len()\n",
    "    )\n",
    "    # split up category \n",
    "    cat_cols_to_keep = [\"id\", \"position\", \"parent_id\", \"color\"]\n",
    "    tmp = df['category'].apply(json.loads).apply(pd.Series)[cat_cols_to_keep]\n",
    "    tmp.columns = \"cat_\" + tmp.columns \n",
    "    cat_cols_to_keep = [\"cat_\" + w for w in cat_cols_to_keep]\n",
    "    df = pd.concat((df, tmp), axis = 1)\n",
    "    # split up location \n",
    "    loc_cols_to_keep = [\"id\", \"type\", \"state\"]\n",
    "    tmp = df['location'].fillna('{}').apply(json.loads).apply(pd.Series)[loc_cols_to_keep]\n",
    "    tmp.columns = \"loc_\" + tmp.columns \n",
    "    loc_cols_to_keep = [\"loc_\" + w for w in loc_cols_to_keep]\n",
    "    df = pd.concat((df, tmp), axis=1)\n",
    "    #### \n",
    "    df_cols_to_keep = [\n",
    "         \"state\", \"usd_goal\", \"available_time\", \"blurb_len\", \"launched_at\", \"deadline\", \"blurb\", \n",
    "        \"name\", \"currency\", \"country\", \"is_starred\", \"is_starrable\", \"spotlight\", \"staff_pick\", \"photo\"\n",
    "    ]\n",
    "    return df[df_cols_to_keep + cat_cols_to_keep + loc_cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffc9ada3-528e-48d5-932c-f8bc20113c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [06:41<00:00,  7.16s/it]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for f in tqdm(files):\n",
    "    dfs.append( process_df(file_loc + f) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05d7f102-e2ab-454d-986b-8ba702ac6537",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9259b56-96ae-4116-8865-38ecf470b493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191849, 22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a57b5a9-e424-40b7-81aa-ab2f886d8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv(\"2020_04_processed_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9808c017-19d2-448b-a480-0296e34152ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208508, 22)\n",
      "(249102, 22)\n",
      "(309354, 22)\n",
      "(363119, 22)\n",
      "(422842, 22)\n"
     ]
    }
   ],
   "source": [
    "#### --> DROP DUPLICATE PROJECTS HERE <--- #### \n",
    "# note: it seems that the dataframes are cumulative, thus we need to identify duplicate projects and remove them. \n",
    "# To identify a duplicate project, I'm checking the: \n",
    "#        blurb and name, funding goal, date of launch, and deadline\n",
    "# Hopefully, this should be sufficient to catch any duplicate projects \n",
    "\n",
    "main_file = \"2021_04_processed_df.csv\"\n",
    "processed_files = [\n",
    "    \"2020_04_processed_df.csv\", \"2020_12_processed_df.csv\", \"2021_03_processed_df.csv\", \"2021_02_processed_df.csv\"\n",
    "]\n",
    "main = pd.read_csv(main_file).drop(columns=[\"Unnamed: 0\"])\n",
    "print(\"Initial file:\", main.shape)\n",
    "for f in processed_files: \n",
    "    dat = pd.read_csv(f).drop(columns=[\"Unnamed: 0\"])\n",
    "    # combine and drop duplicates \n",
    "    tmp = pd.concat((dat, main)).drop_duplicates(subset=[\"blurb\", \"name\", \"usd_goal\", \"launched_at\", \"deadline\"])\n",
    "    main = tmp\n",
    "    del dat, tmp # let's keep our memory as low as possible as we go \n",
    "    print(\"Adding\", f, main.shape)\n",
    "main.to_csv(\"all_processed_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fc6c68a-dd67-4215-87a2-8519ab09e755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2da86-cacc-4df6-968d-ebd33f6c641a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
