{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e8ec6e-07c7-48eb-85be-49ff12e6597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import logging \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e75836-8c95-479a-84f5-8a41fca5df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4956dc-df12-4233-8cdd-a121676c01de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"/Users/benji/Downloads/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d35d9d-831b-40b6-8a1f-4fc4afe157cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/all_processed_df.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994f7ce0-6d6d-4f5a-b91c-4210298e817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_replace_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "RE_symbols_to_drop = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(txt):\n",
    "    if txt is None: return ''\n",
    "    txt = txt.lower()\n",
    "    txt = RE_replace_space.sub(' ', txt)\n",
    "    txt = RE_symbols_to_drop.sub('', txt)\n",
    "    txt = ' '.join(word for word in txt.split() if word not in STOPWORDS)\n",
    "    return txt \n",
    "\n",
    "df['blurb_cln'] = df['blurb'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214c7a5a-659c-447d-9337-f354f000267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rseed = 229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3dc83ab-3007-4352-97b5-558a2ec9b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(df['state']=='successful', 1, 0)\n",
    "# use same dfs as we use in the other model\n",
    "X_train, X_lnom, y_train, y_lnom = train_test_split(df, y, test_size=0.3, random_state=rseed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=rseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c770f82f-8747-4393-badb-da4582e8f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6957049510576203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.40      0.51     15514\n",
      "           1       0.69      0.90      0.78     23205\n",
      "\n",
      "    accuracy                           0.70     38719\n",
      "   macro avg       0.70      0.65      0.65     38719\n",
      "weighted avg       0.70      0.70      0.67     38719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## try out naive bayes\n",
    "nb = Pipeline([\n",
    "    ('vect', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "nb.fit(X_train['blurb_cln'], y_train)\n",
    "y_pred = nb.predict(X_test['blurb_cln'])\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e492abf7-9e0f-42fe-bcca-bc6bac8c12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/res/multi_nb_preds_test.npy\", nb.predict_proba(X_test['blurb_cln']))\n",
    "np.save(\"data/res/multi_nb_preds_train.npy\", nb.predict_proba(X_train['blurb_cln']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c134fb0-8a53-4cc8-81f3-6a2cdcc536f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    #all_words = set()\n",
    "    mean = []\n",
    "    \n",
    "    for wrd in words: \n",
    "        if isinstance(wrd, np.ndarray):\n",
    "            mean.append(wrd)\n",
    "        elif wrd in wv.key_to_index:\n",
    "            mean.append(wv.get_vector(wrd, norm=True))\n",
    "            #all_words.add(wv.key_to_index[wrd])\n",
    "    \n",
    "    if not mean: \n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.vector_size, )\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def word_averaging_list(wv, text_list):\n",
    "    return np.vstack( [word_averaging(wv, post) for post in text_list ])\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28526b11-8944-48d6-a2db-e6ed0cbf5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = X_test.apply( lambda r: w2v_tokenize_text(r['blurb_cln']), axis=1).values\n",
    "train_tokenized = X_train.apply( lambda r: w2v_tokenize_text(r['blurb_cln']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c2cb7-35c3-4ff3-862a-c55b0f13dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word_average = word_averaging_list(wv, train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv, test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51047b3f-e336-45c1-b1bf-57537d676eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6854774141894161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56     15514\n",
      "           1       0.71      0.81      0.76     23205\n",
      "\n",
      "    accuracy                           0.69     38719\n",
      "   macro avg       0.67      0.65      0.66     38719\n",
      "weighted avg       0.68      0.69      0.68     38719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train_word_average, y_train)\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68e1444b-1238-4ac2-878a-f63f4b173c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/res/w2v_Xtrain_avg.npy\", X_train_word_average)\n",
    "np.save(\"data/res/w2v_Xtest_avg.npy\", X_test_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce9cd2-eed9-407a-a161-0a8fecb9079b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
