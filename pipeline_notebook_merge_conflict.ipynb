{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import json\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "#from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "from model_metrics import format_results\n",
    "import data_clean_for_model\n",
    "import PipelineHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level = logging.INFO, \n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Load Data\n",
    "df = pd.read_parquet(\"data/all_processed_df.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "rseed = 229\n",
    "df[\"outcome\"] = np.where( df[\"state\"]==\"successful\", 1, 0, )\n",
    "df[\"un_id\"] = np.arange(0, df.shape[0], 1 )\n",
    "df[\"name_len\"] = df[\"name\"].str.len()\n",
    "df[\"cv_group\"] = np.random.choice( np.arange(0, k), size=df.shape[0] )\n",
    "df[\"binned_usd_goal\"] = pd.qcut( np.log(df[\"usd_goal\"]+1), 20 )\n",
    "\n",
    "with open(\"model_config.json\", 'r') as j:\n",
    "     model_params = json.loads(j.read())\n",
    "model_params['naive_bayes']['ngram_range'] = tuple(model_params['naive_bayes']['ngram_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:48:27 INFO     Loading features\n"
     ]
    }
   ],
   "source": [
    "## load project metadata\n",
    "logger.info(\"Loading features\")\n",
    "_refresh = False\n",
    "try:\n",
    "    if _refresh: raise Exception(\"Reloading\")\n",
    "    f = open(\"data/features.pkl\", \"rb\")\n",
    "    ft_dict = pickle.load(f)\n",
    "    f.close()\n",
    "    X_train, y_train, X_test, y_test = ft_dict.values()\n",
    "except:\n",
    "    X_train, X_test, y_train, y_test = data_clean_for_model.data_clean_for_model(df, \"outcome\", model_params, cv=model_params[\"cv\"])\n",
    "    f = open(\"data/features.pkl\", \"wb\")\n",
    "    pickle.dump({\n",
    "        'X_train':X_train, 'y_train':y_train, 'X_test':X_test, 'y_test':y_test\n",
    "    }, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:48:27 INFO     Processing text data\n"
     ]
    }
   ],
   "source": [
    "# load text\n",
    "logger.info(\"Processing text data\")\n",
    "blurb_train, blurb_test, _, _    = data_clean_for_model.process_blurb(df, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221248/221248 [1:19:40<00:00, 46.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "0       1.0\n",
      "1       2.0\n",
      "2       1.5\n",
      "3       1.5\n",
      "4       2.0\n",
      "       ... \n",
      "1628    3.0\n",
      "1633    2.5\n",
      "1640    3.0\n",
      "1662    1.0\n",
      "1736    2.0\n",
      "Name: sentiment, Length: 221248, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'] = np.empty(df.shape[0])\n",
    "for i in tqdm(range(len(df.blurb.index))):\n",
    "    if not isinstance(df.blurb.iloc[i], str):\n",
    "        df.sentiment.iloc[i] = 2\n",
    "        continue\n",
    "    result = nlp.annotate(df.blurb.iloc[i],\n",
    "                       properties={\n",
    "                           'annotators': 'sentiment,',\n",
    "                           'outputFormat': 'json',\n",
    "                       })\n",
    "    total = 0\n",
    "    numSentences = 0\n",
    "    for s in result['sentences']:\n",
    "        total += int(s['sentimentValue'])\n",
    "        numSentences += 1\n",
    "    df.sentiment.iloc[i] = total/numSentences\n",
    "print(df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"sentiment\"]\n",
    "df.to_csv('sentiment_col.csv', columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Run text models\n",
    "\n",
    "try: \n",
    "    f = open(\"data/res/text_models.pkl\", \"rb\")\n",
    "    text_models = pickle.load(f)\n",
    "    f.close()\n",
    "except:\n",
    "    raise Warning(\"Text models do not exist. Will load from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 17:48:30 INFO     Loading Naive Bayes predictions\n",
      "2021-06-02 17:48:30 INFO     Loading LDA topic predictions\n",
      "2021-06-02 17:48:30 INFO     Loading Word2Vec dimension predictions\n"
     ]
    }
   ],
   "source": [
    "## 2. Run text models\n",
    "\n",
    "try: \n",
    "    f = open(\"data/res/text_models.pkl\", \"rb\")\n",
    "    text_models = pickle.load(f)\n",
    "    f.close()\n",
    "except:\n",
    "    raise Warning(\"Text models do not exist. Will load from scratch\")\n",
=======
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
    "# get naive bayes predictions\n",
    "logger.info(\"Loading Naive Bayes predictions\")\n",
    "try:\n",
    "    #nb_proba_train = np.load(\"data/res/multi_nb_preds_train.npy\")\n",
    "    #nb_proba_test = np.load(\"data/res/multi_nb_preds_test.npy\")\n",
    "    nb_proba_train, nb_proba_test = text_models['nb_train'], text_models['nb_test']\n",
    "except:\n",
    "    logger.info(\"Running Naive Bayes model\")\n",
    "    nb_params = model_params['naive_bayes']\n",
    "    nb_train_pred, nb_proba_train, nb_test_pred, nb_proba_test = PipelineHelper.naive_bayes_predictions(\n",
    "        blurb_train, y_train, blurb_test,\n",
    "        tfidf=nb_params['tf-idf'], ngram_range=nb_params['ngram_range']\n",
    "    )\n",
    "    np.save(\"data/res/multi_nb_preds_train.npy\", nb_proba_train)\n",
    "    np.save(\"data/res/multi_nb_preds_test.npy\", nb_proba_test)\n",
    "\n",
    "# get LDA topic model\n",
    "logger.info(\"Loading LDA topic predictions\")\n",
    "try:\n",
    "    lda_train, lda_test = text_models['lda_train'], text_models['lda_test']\n",
    "    #lda_train = pd.read_csv(\"data/res/lda_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "    #lda_test = pd.read_csv(\"data/res/lda_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "except:\n",
    "    logger.info(\"Running LDA topic model\")\n",
    "    lda_params = model_params['lda']\n",
    "    tokenized_train = blurb_train.apply(data_clean_for_model.tokenize_text)\n",
    "    tokenized_test = blurb_test.apply(data_clean_for_model.tokenize_text)\n",
    "    lda_train, lda_test = PipelineHelper.train_lda_model(tokenized_train, tokenized_test, params['lda'])\n",
    "    lda_train.to_csv(\"data/res/lda_train.csv\")\n",
    "    lda_test.to_csv(\"data/res/lda_test.csv\")\n",
    "\n",
    "# get Word2Vec model predictions\n",
    "logger.info(\"Loading Word2Vec dimension predictions\")\n",
    "try:\n",
    "    #f = open(\"data/res/w2v_dict.pkl\", \"rb\")\n",
    "    #w2v_dict = pickle.load(f)\n",
    "    #f.close()\n",
    "    #w2v_train, w2v_test = w2v_dict.values()\n",
    "    w2v_train, w2v_test = text_models['w2v_train'], text_models['w2v_test']\n",
    "except:\n",
    "    raise Warning(\"Word2Vec function not implemented. Running without it -- likely will crash.\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "id": "3f0ac7a0-ef90-4c62-a8d8-09408523f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ignore=True\n",
    "if not _ignore: \n",
    "    text_models = {\n",
    "        'nb_train':nb_proba_train, \n",
    "        'nb_test':nb_proba_test,\n",
    "        'lda_train':lda_train, \n",
    "        'lda_test':lda_test,\n",
    "        'w2v_train':w2v_train, \n",
    "        'w2v_test':w2v_test\n",
    "    }\n",
    "    f = open(\"data/res/text_models.pkl\", \"wb\")\n",
    "    pickle.dump(text_models, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7058106-3172-4f7b-9190-f21ddef0ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_increment_rseed = False\n",
    "if _increment_rseed: \n",
    "    model_params['rseed'] += 1\n",
    "    model_params['rseed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7379ae-2b64-4649-b2c8-2ce0cf735501",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = [\"un_id\", \"cv_group\"]\n",
    "id_train = X_train[id_vars]\n",
    "id_test = X_test[id_vars]\n",
    "X_train = X_train.drop(columns=id_vars)\n",
    "X_test = X_test.drop(columns=id_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b714e22f-f94b-4d2d-9d68-901c8dfcc64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': True,\n",
       " 'test_frac': 0.3,\n",
       " 'lnom_usdgoal': True,\n",
       " 'dummies': True,\n",
       " 'rseed': 229,\n",
       " 'naive_bayes': {'tf-idf': True, 'ngram_range': (1, 1)},\n",
       " 'lda': {'corpus': {'no_below': 10, 'no_above': 0.35},\n",
       "  'n_topics': 20,\n",
       "  'chunksize': 100,\n",
       "  'passes': 50,\n",
       "  'rseed': 229},\n",
       " 'linear_models': {'lasso_alpha': 0.75,\n",
       "  'ridge_alpha': 0.75,\n",
       "  'logreg_C': 1000,\n",
       "  'logreg_penalty': 'none'},\n",
       " 'lightgbm': {'bagging_fraction': 0.75,\n",
       "  'feature_fraction': 0.2,\n",
       "  'max_depth': 55,\n",
       "  'max_bin': 500,\n",
       "  'num_leaves': 400,\n",
       "  'lambda_l1': 0,\n",
       "  'lambda_l2': 0},\n",
       " 'random_forest': {'bootstrap': False,\n",
       "  'max_depth': 55,\n",
       "  'max_features': 'auto',\n",
       "  'min_samples_leaf': 10,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 200}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d1d3ddc-7b69-449d-8f6a-61bd8f6da47a",
=======
   "execution_count": 9,
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 17:48:33 INFO     Getting metadata results\n",
      "2021-06-02 17:48:33 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "2021-06-02 17:48:51 INFO     Fitting lightgbm\n"
=======
      "INFO:__main__:Getting metadata results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.10488e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 17:48:57 INFO     Fitting random forest\n"
=======
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    }
   ],
   "source": [
    "### a. Just on metadata\n",
    "logger.info(\"Getting metadata results\")\n",
    "stat_df, pred_df, models = PipelineHelper.run_analyses(X_train, y_train, X_test, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "id": "a9570004-2d59-459a-88cc-b74b3fdd31f9",
=======
   "execution_count": 10,
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 17:50:59 INFO     Getting metadata - binned_usd_goal_outcome_mean results\n",
      "2021-06-02 17:50:59 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2021-06-02 17:51:14 INFO     Fitting lightgbm\n"
=======
      "INFO:__main__:Getting metadata - binned_usd_goal_outcome_mean results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.10488e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 17:51:19 INFO     Fitting random forest\n"
=======
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    }
   ],
   "source": [
    "### b. Just on metadata, - binned_usd_goal_outcome_mean\n",
    "logger.info(\"Getting metadata - binned_usd_goal_outcome_mean results\")\n",
    "stat_df_nobinusd, pred_df_nobinusd, models_nobinusd = PipelineHelper.run_analyses(\n",
    "    X_train.drop(columns=['binned_usd_goal_outcome_mean']), y_train, \n",
    "    X_test.drop(columns=['binned_usd_goal_outcome_mean']), y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "id": "e1ed8457-3631-427f-9b5b-d12f6b172edd",
=======
   "execution_count": 11,
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 17:53:30 INFO     Getting metadata + naive bayes results\n",
      "2021-06-02 17:53:30 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "2021-06-02 17:53:46 INFO     Fitting lightgbm\n"
=======
      "INFO:__main__:Getting metadata + naive bayes results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.10488e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 17:53:51 INFO     Fitting random forest\n"
=======
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    }
   ],
   "source": [
    "### c. Just on metadata + nb \n",
    "logger.info(\"Getting metadata + naive bayes results\")\n",
    "X_train_nb = X_train.copy()\n",
    "X_test_nb = X_test.copy()\n",
    "# NB \n",
    "X_train_nb['nb_proba'] = nb_proba_train[:, 1]\n",
    "X_test_nb['nb_proba'] = nb_proba_test[:, 1]\n",
    "stat_df_nb, pred_df_nb, models_nb = PipelineHelper.run_analyses(X_train_nb, y_train, X_test_nb, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "id": "ac6deaee-9d02-4911-8d4a-917afa73e59a",
=======
   "execution_count": 12,
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 17:56:12 INFO     Getting metadata + naive bayes + LDA results\n",
      "2021-06-02 17:56:12 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "2021-06-02 17:56:28 INFO     Fitting lightgbm\n"
=======
      "INFO:__main__:Getting metadata + naive bayes + LDA results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.10487e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 17:56:34 INFO     Fitting random forest\n"
=======
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    }
   ],
   "source": [
    "### d. Just on metadata + nb + lda\n",
    "logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "X_train_nb_lda = pd.concat((X_train_nb, lda_train), axis=1)\n",
    "X_test_nb_lda = pd.concat((X_test_nb, lda_test), axis=1)\n",
    "stat_df_nb_lda, pred_df_nb_lda, models_nb_lda = PipelineHelper.run_analyses(X_train_nb_lda, y_train, X_test_nb_lda, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "id": "26a48024-a6d9-4cdb-a359-0d216a04b89e",
   "metadata": {
    "tags": []
   },
=======
   "execution_count": 13,
   "metadata": {},
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 17:59:49 INFO     Getting metadata + naive bayes + w2v results\n",
      "2021-06-02 17:59:51 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.25151e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "2021-06-02 18:00:25 INFO     Fitting lightgbm\n"
=======
      "INFO:__main__:Getting metadata + naive bayes + w2v results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.1047e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 18:00:57 INFO     Fitting random forest\n"
=======
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    }
   ],
   "source": [
    "### e. Just on metadata + nb + w2v\n",
    "logger.info(\"Getting metadata + naive bayes + w2v results\")\n",
    "X_train_nb_w2v = pd.concat((X_train_nb, pd.DataFrame(w2v_train)), axis=1)\n",
    "X_test_nb_w2v = pd.concat((X_test_nb, pd.DataFrame(w2v_test)), axis=1)\n",
    "stat_df_nb_w2v, pred_df_nb_w2v, models_nb_w2v = PipelineHelper.run_analyses(X_train_nb_w2v, y_train, X_test_nb_w2v, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "id": "b86aad82-17d9-49f3-b8a6-2e988b5139d9",
=======
   "execution_count": 14,
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 18:17:07 INFO     Getting metadata + naive bayes + LDA results\n",
      "2021-06-02 18:17:07 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2021-06-02 18:17:28 INFO     Fitting lightgbm\n"
=======
      "INFO:__main__:Getting metadata + naive bayes + LDA results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.83344e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "2021-06-02 18:17:35 INFO     Fitting random forest\n"
=======
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     ]
    }
   ],
   "source": [
    "### f. Just on metadata + nb + lda - cols to drop \n",
    "logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "cols_to_drop = [\n",
    "    'dummy_cat_id_290', 'dummy_cat_id_300', 'dummy_cat_id_317','dummy_cat_id_386', 'dummy_cat_id_352', #'dummy_cat_id_1',\n",
    "    'dummy_cat_id_355', 'dummy_cat_id_354', 'dummy_cat_id_321', 'dummy_cat_id_12', 'dummy_cat_id_340', 'dummy_cat_id_268', 'binned_usd_goal_outcome_mean'\n",
    "]\n",
    "stat_df_nb_lda_drop, pred_df_nb_lda_drop, models_nb_lda_drop = PipelineHelper.run_analyses(\n",
    "    X_train_nb_lda.drop(columns=cols_to_drop), y_train, \n",
    "    X_test_nb_lda.drop(columns=cols_to_drop), y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
   "id": "84dfd3c9-0200-4275-addf-d951959fa26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:21:20 INFO     Getting metadata + naive bayes w/ scaled vars\n",
      "2021-06-02 18:21:20 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-06-02 18:21:33 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:21:38 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### g. Just on metadata + nb, scaled vars \n",
    "model_params['linear_models']['logreg_penalty'] = 'l2'\n",
    "model_params['linear_models']['logreg_C'] = 0.75\n",
    "model_params['linear_models']['ridge_alpha'] = 0.5\n",
    "model_params['linear_models']['lasso_alpha'] = 1\n",
    "\n",
    "X_train_nb_scale, X_test_nb_scale = PipelineHelper.scale_data(X_train_nb, X_test_nb)\n",
    "logger.info(\"Getting metadata + naive bayes w/ scaled vars\")\n",
    "stat_df_nb_scale, pred_df_nb_scale, models_nb_scale = PipelineHelper.run_analyses(\n",
    "    X_train_nb_scale, y_train, \n",
    "    X_test_nb_scale, y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80aafdf4-4b9a-4bc9-bb47-361e555e8d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:24:03 INFO     Getting metadata + naive bayes w/ scaled vars\n",
      "2021-06-02 18:24:03 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-06-02 18:24:16 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:24:20 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### g. Just on metadata, scaled vars \n",
    "#X_train_nb_scale, X_test_nb_scale = PipelineHelper.scale_data(X_train_nb, X_test_nb)\n",
    "logger.info(\"Getting metadata + naive bayes w/ scaled vars\")\n",
    "stat_df_scale, pred_df_scale, models_scale = PipelineHelper.run_analyses(\n",
    "    X_train_nb_scale.drop(columns=['nb_proba']), y_train, \n",
    "    X_test_nb_scale.drop(columns=['nb_proba']), y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a59c6571-d8e8-4f36-a1e1-2ba51e5157a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:26:43 INFO     Getting metadata + naive bayes + lda w/ scaled vars\n",
      "2021-06-02 18:26:43 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-06-02 18:26:56 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:27:04 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### h. Metadata + nb + lda, scaled vars \n",
    "X_train_nb_lda_scale, X_test_nb_lda_scale = PipelineHelper.scale_data(X_train_nb_lda, X_test_nb_lda, addtl_cols=lda_train.columns)\n",
    "logger.info(\"Getting metadata + naive bayes + lda w/ scaled vars\")\n",
    "stat_df_nb_lda_scale, pred_df_nb_lda_scale, models_nb_lda_scale = PipelineHelper.run_analyses(\n",
    "    X_train_nb_lda_scale, y_train, \n",
    "    X_test_nb_lda_scale, y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbd0c0bb-b5f0-4b0d-b5c3-7f841b519193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:30:57 INFO     Getting metadata + naive bayes + w2v w/ scaled vars\n",
      "2021-06-02 18:30:57 INFO     Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2021-06-02 18:31:26 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:32:18 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### i. Metadata + nb + w2v, scaled vars \n",
    "X_train_nb_w2v_scale, X_test_nb_w2v_scale = PipelineHelper.scale_data(X_train_nb_w2v, X_test_nb_w2v, addtl_cols=w2v_train.columns)\n",
    "logger.info(\"Getting metadata + naive bayes + w2v w/ scaled vars\")\n",
    "stat_df_nb_w2v_scale, pred_df_nb_w2v_scale, models_nb_w2v_scale = PipelineHelper.run_analyses(\n",
    "    X_train_nb_w2v_scale, y_train, \n",
    "    X_test_nb_w2v_scale, y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "602f3b6a-1720-4863-903d-c2435fb46420",
=======
   "execution_count": 15,
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
   "metadata": {},
   "outputs": [],
   "source": [
    "core_nlp_sentiment = pd.read_csv(\"data/res/sentiment_col.csv\")\n",
    "core_nlp_sentiment['un_id'] = np.arange(0, core_nlp_sentiment.shape[0], 1 )\n",
    "core_nlp_train = id_train.merge(core_nlp_sentiment, on=\"un_id\", how=\"left\")\n",
    "core_nlp_test = id_test.merge(core_nlp_sentiment, on=\"un_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
   "id": "7bc94e74-c9eb-4f42-b386-03a5c4ad726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:48:18 INFO     Getting metadata + naive bayes + w2v w/ scaled vars\n",
      "2021-06-02 18:48:18 INFO     Fitting linear models\n",
      "2021-06-02 18:48:33 INFO     Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 18:48:38 INFO     Fitting random forest\n"
     ]
    }
   ],
   "source": [
    "### i. Metadata + nb + w2v, scaled vars \n",
    "X_train_nb_nlp = X_train_nb.copy()\n",
    "X_test_nb_nlp = X_test_nb.copy()\n",
    "X_train_nb_nlp['sentiment'] = core_nlp_train['sentiment']\n",
    "X_test_nb_nlp['sentiment'] = core_nlp_test['sentiment']\n",
    "logger.info(\"Getting metadata + naive bayes + w2v w/ scaled vars\")\n",
    "stat_df_nb_nlp, pred_df_nb_nlp, models_nb_nlp = PipelineHelper.run_analyses(\n",
    "    X_train_nb_nlp, y_train, \n",
    "    X_test_nb_nlp, y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f1db5d9-aafe-4a02-a85a-c44176456804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j. neural net (takes FOREVER so am just loading in one model on X_train_nb) \n",
    "load_nn=True\n",
    "if load_nn:\n",
    "    import tensorflow as tf \n",
    "    from model_metrics import calculate_performance\n",
    "    nn = tf.keras.models.load_model(\"data/nns/nn_batch5_epochs30_dim_25.tf\")\n",
    "    ypred = nn.predict(X_test_nb_scale)\n",
    "    ypred = np.round(ypred.ravel())\n",
    "    res = calculate_performance(y_test, ypred)\n",
    "    res = [\"KerasClassifier\"] + res\n",
    "    res = [\"metadata_nb_scale\"] + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f57bdeb-6585-4867-aa0d-39221b619548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.81, 0.85, 0.83, 0.78, 0.86, 0.74, 0.8, 0.19]"
      ]
     },
     "execution_count": 42,
=======
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>accuracy_rank</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.825431</td>\n",
       "      <td>0.848953</td>\n",
       "      <td>0.885703</td>\n",
       "      <td>0.750599</td>\n",
       "      <td>0.815130</td>\n",
       "      <td>0.841002</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.174569</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda_drop</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.823443</td>\n",
       "      <td>0.847502</td>\n",
       "      <td>0.882493</td>\n",
       "      <td>0.749517</td>\n",
       "      <td>0.815180</td>\n",
       "      <td>0.835932</td>\n",
       "      <td>0.825556</td>\n",
       "      <td>0.176557</td>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_w2v</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.823292</td>\n",
       "      <td>0.849325</td>\n",
       "      <td>0.872308</td>\n",
       "      <td>0.758067</td>\n",
       "      <td>0.827521</td>\n",
       "      <td>0.816899</td>\n",
       "      <td>0.822210</td>\n",
       "      <td>0.176708</td>\n",
       "      <td>3</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.822885</td>\n",
       "      <td>0.846587</td>\n",
       "      <td>0.884252</td>\n",
       "      <td>0.747070</td>\n",
       "      <td>0.812001</td>\n",
       "      <td>0.839337</td>\n",
       "      <td>0.825669</td>\n",
       "      <td>0.177115</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metadata_nb</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.814945</td>\n",
       "      <td>0.838926</td>\n",
       "      <td>0.880942</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.800736</td>\n",
       "      <td>0.836423</td>\n",
       "      <td>0.818580</td>\n",
       "      <td>0.185055</td>\n",
       "      <td>5</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data                   model  accuracy  f1_score  \\\n",
       "0           metadata_nb          LGBMClassifier  0.825431  0.848953   \n",
       "0  metadata_nb_lda_drop          LGBMClassifier  0.823443  0.847502   \n",
       "0       metadata_nb_w2v          LGBMClassifier  0.823292  0.849325   \n",
       "0       metadata_nb_lda          LGBMClassifier  0.822885  0.846587   \n",
       "1           metadata_nb  RandomForestClassifier  0.814945  0.838926   \n",
       "\n",
       "   precision_1  precision_0  recall_1  recall_0   roc_auc     brier  \\\n",
       "0     0.885703     0.750599  0.815130  0.841002  0.828066  0.174569   \n",
       "0     0.882493     0.749517  0.815180  0.835932  0.825556  0.176557   \n",
       "0     0.872308     0.758067  0.827521  0.816899  0.822210  0.176708   \n",
       "0     0.884252     0.747070  0.812001  0.839337  0.825669  0.177115   \n",
       "1     0.880942     0.735240  0.800736  0.836423  0.818580  0.185055   \n",
       "\n",
       "   accuracy_rank  random_state  \n",
       "0              1           229  \n",
       "0              2           229  \n",
       "0              3           229  \n",
       "0              4           229  \n",
       "1              5           229  "
      ]
     },
     "execution_count": 16,
>>>>>>> 84141bda08fba66a0d683a4836e8d880874465c7
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.round(i, 2) for i in res if type(i)!=str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5127c872-f8ac-4692-a7ec-430cb4831875",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df.insert(0, \"data\", \"metadata\"), \n",
    "stat_df_nobinusd.insert(0, \"data\", \"metadata_nobin\"), \n",
    "stat_df_nb.insert(0, \"data\", \"metadata_nb\"),\n",
    "stat_df_nb_lda.insert(0, \"data\", \"metadata_nb_lda\"),\n",
    "stat_df_nb_w2v.insert(0, \"data\", \"metadata_nb_w2v\"),\n",
    "stat_df_nb_lda_drop.insert(0, \"data\", \"metadata_nb_lda_drop\")\n",
    "stat_df_nb_scale.insert(0, \"data\", \"metadata_nb_scale\")\n",
    "stat_df_nb_lda_scale.insert(0, \"data\", \"metadata_nb_lda_scale\")\n",
    "stat_df_nb_w2v_scale.insert(0, \"data\", \"metadata_nb_w2v_scale\")\n",
    "stat_df_nb_nlp.insert(0, \"data\", \"metadata_nb_nlp\")\n",
    "stat_df_scale.insert(0, \"data\", \"metadata_scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32f76b58-a22d-4360-9379-b0fa8530efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = (pd.concat((stat_df, stat_df_scale, stat_df_nobinusd, stat_df_nb, stat_df_nb_lda, stat_df_nb_w2v, stat_df_nb_lda_drop, stat_df_nb_scale, stat_df_nb_lda_scale, stat_df_nb_w2v_scale, stat_df_nb_nlp))\n",
    "       .sort_values('accuracy', ascending=False)\n",
    "       .assign(\n",
    "           accuracy_rank = lambda x:np.arange(1, x.shape[0]+1, 1), \n",
    "           random_state = model_params['rseed']\n",
    "       )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abb8bd35-08e1-4bbd-ab96-a5947bd13837",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin.to_csv(\"model_exports/test_size30/model_statistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>accuracy_rank</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.798825</td>\n",
       "      <td>0.827674</td>\n",
       "      <td>0.854209</td>\n",
       "      <td>0.726721</td>\n",
       "      <td>0.802739</td>\n",
       "      <td>0.792909</td>\n",
       "      <td>0.797824</td>\n",
       "      <td>0.201175</td>\n",
       "      <td>14</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.798644</td>\n",
       "      <td>0.827746</td>\n",
       "      <td>0.853090</td>\n",
       "      <td>0.727317</td>\n",
       "      <td>0.803865</td>\n",
       "      <td>0.790752</td>\n",
       "      <td>0.797309</td>\n",
       "      <td>0.201356</td>\n",
       "      <td>16</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda_drop</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.798478</td>\n",
       "      <td>0.827917</td>\n",
       "      <td>0.851626</td>\n",
       "      <td>0.728246</td>\n",
       "      <td>0.805492</td>\n",
       "      <td>0.787876</td>\n",
       "      <td>0.796684</td>\n",
       "      <td>0.201522</td>\n",
       "      <td>17</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_w2v</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.796640</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.836493</td>\n",
       "      <td>0.738790</td>\n",
       "      <td>0.822965</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>0.789907</td>\n",
       "      <td>0.203360</td>\n",
       "      <td>22</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nobin</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.783473</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.866331</td>\n",
       "      <td>0.691560</td>\n",
       "      <td>0.757028</td>\n",
       "      <td>0.823445</td>\n",
       "      <td>0.790236</td>\n",
       "      <td>0.216527</td>\n",
       "      <td>28</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.783292</td>\n",
       "      <td>0.807014</td>\n",
       "      <td>0.869546</td>\n",
       "      <td>0.689443</td>\n",
       "      <td>0.752873</td>\n",
       "      <td>0.829272</td>\n",
       "      <td>0.791072</td>\n",
       "      <td>0.216708</td>\n",
       "      <td>30</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data          model  accuracy  f1_score  precision_1  \\\n",
       "0       metadata_nb_lda  SVMClassifier  0.798825  0.827674     0.854209   \n",
       "0           metadata_nb  SVMClassifier  0.798644  0.827746     0.853090   \n",
       "0  metadata_nb_lda_drop  SVMClassifier  0.798478  0.827917     0.851626   \n",
       "0       metadata_nb_w2v  SVMClassifier  0.796640  0.829674     0.836493   \n",
       "0        metadata_nobin  SVMClassifier  0.783473  0.808000     0.866331   \n",
       "0              metadata  SVMClassifier  0.783292  0.807014     0.869546   \n",
       "\n",
       "   precision_0  recall_1  recall_0   roc_auc     brier  accuracy_rank  \\\n",
       "0     0.726721  0.802739  0.792909  0.797824  0.201175             14   \n",
       "0     0.727317  0.803865  0.790752  0.797309  0.201356             16   \n",
       "0     0.728246  0.805492  0.787876  0.796684  0.201522             17   \n",
       "0     0.738790  0.822965  0.756849  0.789907  0.203360             22   \n",
       "0     0.691560  0.757028  0.823445  0.790236  0.216527             28   \n",
       "0     0.689443  0.752873  0.829272  0.791072  0.216708             30   \n",
       "\n",
       "   random_state  \n",
       "0           229  \n",
       "0           229  \n",
       "0           229  \n",
       "0           229  \n",
       "0           229  \n",
       "0           229  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin.loc[fin['model'] == \"SVMClassifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata_metadata_LinearRegression_pred</th>\n",
       "      <th>metadata_metadata_Lasso_pred</th>\n",
       "      <th>metadata_metadata_Ridge_pred</th>\n",
       "      <th>metadata_metadata_LogisticRegression_pred</th>\n",
       "      <th>metadata_metadata_LGBMClassifier_pred</th>\n",
       "      <th>metadata_metadata_RandomForestClassifier_pred</th>\n",
       "      <th>metadata_nobin_LinearRegression_pred</th>\n",
       "      <th>metadata_nobin_Lasso_pred</th>\n",
       "      <th>metadata_nobin_Ridge_pred</th>\n",
       "      <th>metadata_nobin_LogisticRegression_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>metadata_nb_w2v_Ridge_pred</th>\n",
       "      <th>metadata_nb_w2v_LogisticRegression_pred</th>\n",
       "      <th>metadata_nb_w2v_LGBMClassifier_pred</th>\n",
       "      <th>metadata_nb_w2v_RandomForestClassifier_pred</th>\n",
       "      <th>metadata_nb_lda_drop_LinearRegression_pred</th>\n",
       "      <th>metadata_nb_lda_drop_Lasso_pred</th>\n",
       "      <th>metadata_nb_lda_drop_Ridge_pred</th>\n",
       "      <th>metadata_nb_lda_drop_LogisticRegression_pred</th>\n",
       "      <th>metadata_nb_lda_drop_LGBMClassifier_pred</th>\n",
       "      <th>metadata_nb_lda_drop_RandomForestClassifier_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.832675</td>\n",
       "      <td>0.651824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.655646</td>\n",
       "      <td>0.832675</td>\n",
       "      <td>0.652055</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800469</td>\n",
       "      <td>0.832675</td>\n",
       "      <td>0.803503</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144957</td>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.144069</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138541</td>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.137552</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136281</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072070</td>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.079891</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488107</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.488423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479006</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.479338</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577682</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.581687</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.579625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.036096</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.037228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.027969</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.028984</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.201803</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.107628</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.102822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.154730</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.154283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192137</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.191644</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278180</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.279277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   metadata_metadata_LinearRegression_pred  metadata_metadata_Lasso_pred  \\\n",
       "0                                 0.655400                      0.832675   \n",
       "1                                 0.144957                      0.473552   \n",
       "2                                 0.488107                      0.425906   \n",
       "3                                 1.036096                      0.832221   \n",
       "4                                 0.154730                      0.290907   \n",
       "\n",
       "   metadata_metadata_Ridge_pred  metadata_metadata_LogisticRegression_pred  \\\n",
       "0                      0.651824                                          1   \n",
       "1                      0.144069                                          1   \n",
       "2                      0.488423                                          1   \n",
       "3                      1.037228                                          1   \n",
       "4                      0.154283                                          0   \n",
       "\n",
       "   metadata_metadata_LGBMClassifier_pred  \\\n",
       "0                                      1   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      1   \n",
       "4                                      0   \n",
       "\n",
       "   metadata_metadata_RandomForestClassifier_pred  \\\n",
       "0                                              1   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              1   \n",
       "4                                              0   \n",
       "\n",
       "   metadata_nobin_LinearRegression_pred  metadata_nobin_Lasso_pred  \\\n",
       "0                              0.655646                   0.832675   \n",
       "1                              0.138541                   0.473552   \n",
       "2                              0.479006                   0.425906   \n",
       "3                              1.027969                   0.832221   \n",
       "4                              0.192137                   0.290907   \n",
       "\n",
       "   metadata_nobin_Ridge_pred  metadata_nobin_LogisticRegression_pred  ...  \\\n",
       "0                   0.652055                                       1  ...   \n",
       "1                   0.137552                                       1  ...   \n",
       "2                   0.479338                                       1  ...   \n",
       "3                   1.028984                                       1  ...   \n",
       "4                   0.191644                                       0  ...   \n",
       "\n",
       "   metadata_nb_w2v_Ridge_pred  metadata_nb_w2v_LogisticRegression_pred  \\\n",
       "0                    0.761006                                        1   \n",
       "1                    0.136281                                        1   \n",
       "2                    0.577682                                        1   \n",
       "3                    1.201803                                        1   \n",
       "4                    0.140261                                        0   \n",
       "\n",
       "   metadata_nb_w2v_LGBMClassifier_pred  \\\n",
       "0                                    1   \n",
       "1                                    0   \n",
       "2                                    1   \n",
       "3                                    1   \n",
       "4                                    0   \n",
       "\n",
       "   metadata_nb_w2v_RandomForestClassifier_pred  \\\n",
       "0                                            1   \n",
       "1                                            0   \n",
       "2                                            1   \n",
       "3                                            1   \n",
       "4                                            0   \n",
       "\n",
       "   metadata_nb_lda_drop_LinearRegression_pred  \\\n",
       "0                                    0.800469   \n",
       "1                                    0.072070   \n",
       "2                                    0.581687   \n",
       "3                                    1.107628   \n",
       "4                                    0.278180   \n",
       "\n",
       "   metadata_nb_lda_drop_Lasso_pred  metadata_nb_lda_drop_Ridge_pred  \\\n",
       "0                         0.832675                         0.803503   \n",
       "1                         0.473552                         0.079891   \n",
       "2                         0.425906                         0.579625   \n",
       "3                         0.832221                         1.102822   \n",
       "4                         0.290907                         0.279277   \n",
       "\n",
       "   metadata_nb_lda_drop_LogisticRegression_pred  \\\n",
       "0                                             1   \n",
       "1                                             1   \n",
       "2                                             1   \n",
       "3                                             1   \n",
       "4                                             0   \n",
       "\n",
       "   metadata_nb_lda_drop_LGBMClassifier_pred  \\\n",
       "0                                         1   \n",
       "1                                         0   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         0   \n",
       "\n",
       "   metadata_nb_lda_drop_RandomForestClassifier_pred  \n",
       "0                                                 1  \n",
       "1                                                 0  \n",
       "2                                                 0  \n",
       "3                                                 1  \n",
       "4                                                 0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.columns = \"metadata_\" + pred_df.columns\n",
    "pred_df_nobinusd.columns = \"metadata_nobin_\" + pred_df_nobinusd.columns\n",
    "pred_df_nb.columns = \"metadata_nb_\" + pred_df_nb.columns\n",
    "pred_df_nb_lda.columns = \"metadata_nb_lda_\" + pred_df_nb_lda.columns\n",
    "pred_df_nb_w2v.columns = \"metadata_nb_w2v_\" + pred_df_nb_w2v.columns\n",
    "pred_df_nb_lda_drop.columns = \"metadata_nb_lda_drop_\" + pred_df_nb_lda_drop.columns\n",
    "pred_fin = pd.concat((pred_df, pred_df_nobinusd, pred_df_nb, pred_df_nb_lda, pred_df_nb_w2v, pred_df_nb_lda_drop), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5a35d82-f034-4ccb-a234-9d25efcd79e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "             data &                  model &  accuracy &  f1\\_score &  precision\\_1 &  precision\\_0 &  recall\\_1 &  recall\\_0 \\\\\n",
      "\\midrule\n",
      "      metadata\\_nb &         LGBMClassifier &      0.83 &      0.85 &         0.89 &         0.75 &      0.81 &      0.84 \\\\\n",
      "metadata\\_nb\\_scale &         LGBMClassifier &      0.83 &      0.85 &         0.89 &         0.75 &      0.81 &      0.84 \\\\\n",
      "      metadata\\_nb & RandomForestClassifier &      0.82 &      0.84 &         0.88 &         0.74 &      0.80 &      0.84 \\\\\n",
      "metadata\\_nb\\_scale & RandomForestClassifier &      0.81 &      0.84 &         0.88 &         0.74 &      0.80 &      0.84 \\\\\n",
      "metadata\\_nb\\_scale &     LogisticRegression &      0.80 &      0.83 &         0.86 &         0.72 &      0.79 &      0.80 \\\\\n",
      "      metadata\\_nb &                  Ridge &      0.80 &      0.82 &         0.87 &         0.71 &      0.78 &      0.83 \\\\\n",
      "metadata\\_nb\\_scale &                  Ridge &      0.80 &      0.82 &         0.87 &         0.71 &      0.77 &      0.83 \\\\\n",
      "      metadata\\_nb &       LinearRegression &      0.80 &      0.82 &         0.87 &         0.71 &      0.77 &      0.83 \\\\\n",
      "metadata\\_nb\\_scale &       LinearRegression &      0.80 &      0.82 &         0.87 &         0.71 &      0.77 &      0.83 \\\\\n",
      "      metadata\\_nb &                  Lasso &      0.70 &      0.74 &         0.78 &         0.61 &      0.70 &      0.71 \\\\\n",
      "      metadata\\_nb &     LogisticRegression &      0.67 &      0.73 &         0.72 &         0.59 &      0.74 &      0.57 \\\\\n",
      "metadata\\_nb\\_scale &                  Lasso &      0.40 &      0.00 &         0.00 &         0.40 &      0.00 &      1.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.round(fin[np.logical_or(fin.data==\"metadata_nb\", fin.data==\"metadata_nb_scale\")][['data', 'model', 'accuracy', 'f1_score', 'precision_1', 'precision_0','recall_1', 'recall_0']],2).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91f6066c-dd71-4db8-9f2a-ebd3ad7f8a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrrrr}\n",
      "\\toprule\n",
      "{} &               data &                   model &  accuracy &  f1\\_score &  precision\\_1 &  precision\\_0 &  recall\\_1 &  recall\\_0 \\\\\n",
      "\\midrule\n",
      "0 &        metadata\\_nb &          LGBMClassifier &      0.83 &      0.85 &         0.89 &         0.75 &      0.81 &      0.84 \\\\\n",
      "0 &  metadata\\_nb\\_scale &          LGBMClassifier &      0.83 &      0.85 &         0.89 &         0.75 &      0.81 &      0.84 \\\\\n",
      "1 &  metadata\\_nb\\_scale &  RandomForestClassifier &      0.81 &      0.84 &         0.88 &         0.73 &      0.80 &      0.84 \\\\\n",
      "1 &        metadata\\_nb &  RandomForestClassifier &      0.81 &      0.84 &         0.88 &         0.73 &      0.80 &      0.84 \\\\\n",
      "3 &  metadata\\_nb\\_scale &      LogisticRegression &      0.80 &      0.83 &         0.86 &         0.72 &      0.79 &      0.80 \\\\\n",
      "2 &  metadata\\_nb\\_scale &                   Ridge &      0.80 &      0.82 &         0.87 &         0.71 &      0.77 &      0.83 \\\\\n",
      "2 &        metadata\\_nb &                   Ridge &      0.80 &      0.82 &         0.87 &         0.71 &      0.77 &      0.83 \\\\\n",
      "0 &        metadata\\_nb &        LinearRegression &      0.80 &      0.82 &         0.87 &         0.71 &      0.77 &      0.83 \\\\\n",
      "0 &  metadata\\_nb\\_scale &        LinearRegression &      0.80 &      0.82 &         0.87 &         0.71 &      0.77 &      0.83 \\\\\n",
      "1 &        metadata\\_nb &                   Lasso &      0.70 &      0.74 &         0.78 &         0.61 &      0.70 &      0.71 \\\\\n",
      "3 &        metadata\\_nb &      LogisticRegression &      0.67 &      0.73 &         0.72 &         0.59 &      0.73 &      0.58 \\\\\n",
      "1 &  metadata\\_nb\\_scale &                   Lasso &      0.40 &      0.00 &         0.00 &         0.40 &      0.00 &      1.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.round(fin[np.logical_or(fin.data==\"metadata_nb\", fin.data==\"metadata_nb_scale\")][['data', 'model', 'accuracy', 'f1_score', 'precision_1', 'precision_0','recall_1', 'recall_0']],2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5db56f1-a6bc-4ae9-868e-62b32cc9e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "lgb_pred = models_nb[4].predict(X_test_nb)\n",
    "lgb_pred_proba = models_nb[4].predict_proba(X_test_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "963489a3-c648-4048-bc40-10dcd3e416c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(1,1, figsize=(8,6))\n",
    "ax=sns.heatmap(pd.crosstab(y_test, lgb_pred), annot=True,cmap='Blues', fmt='g', annot_kws={\"fontsize\":14})\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "ax.set_ylabel(\"True Outcome\", size=14)\n",
    "ax.set_xlabel(\"Predicted Outcome (gradient boosting)\", size=14)\n",
    "plt.savefig(\"plots/lgb_preds_nb_heatmap.png\", figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dafeb735-7cf7-49c9-ab09-e3cdc8eeafa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8254011299435028,\n",
       " 0.8487450893381537,\n",
       " 0.8866437609075044,\n",
       " 0.7497895835437498,\n",
       " 0.813953488372093,\n",
       " 0.8427047071288027,\n",
       " 0.8283290977504479,\n",
       " 0.17459887005649719]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_metrics import calculate_performance\n",
    "calculate_performance(y_test, lgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c03d092c-4882-4c37-9dad-c8bc07167d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(1,1, figsize=(8,6))\n",
    "sns.histplot(x=lgb_pred_proba[:, 1], hue=y_test)\n",
    "plt.xlabel(\"Predicted Outcome Probability (gradient boosting)\", size=14)\n",
    "plt.savefig(\"plots/lgb_preds_nb_hist.png\", figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bf472e2c-dcce-4afb-9a98-abb8ff491a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exps(rseed):\n",
    "    model_params['rseed'] = rseed\n",
    "    ### a. Just on metadata\n",
    "    logger.info(\"Getting metadata results\")\n",
    "    stat_df, pred_df, models = PipelineHelper.run_analyses(X_train, y_train, X_test, y_test, model_params)\n",
    "    ### b. Just on metadata, - binned_usd_goal_outcome_mean\n",
    "    logger.info(\"Getting metadata - binned_usd_goal_outcome_mean results\")\n",
    "    stat_df_nobinusd, pred_df_nobinusd, models_nobinusd = PipelineHelper.run_analyses(\n",
    "        X_train.drop(columns=['binned_usd_goal_outcome_mean']), y_train, \n",
    "        X_test.drop(columns=['binned_usd_goal_outcome_mean']), y_test, model_params)\n",
    "    ### c. Just on metadata + nb \n",
    "    logger.info(\"Getting metadata + naive bayes results\")\n",
    "    #X_train_nb = X_train.copy()\n",
    "    #X_test_nb = X_test.copy()\n",
    "    # NB \n",
    "    #X_train_nb['nb_proba'] = nb_proba_train[:, 1]\n",
    "    #X_test_nb['nb_proba'] = nb_proba_test[:, 1]\n",
    "    stat_df_nb, pred_df_nb, models_nb = PipelineHelper.run_analyses(X_train_nb, y_train, X_test_nb, y_test, model_params)\n",
    "    ### d. Just on metadata + nb + lda\n",
    "    logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "    #X_train_nb_lda = pd.concat((X_train_nb, lda_train), axis=1)\n",
    "    #X_test_nb_lda = pd.concat((X_test_nb, lda_test), axis=1)\n",
    "    stat_df_nb_lda, pred_df_nb_lda, models_nb_lda = PipelineHelper.run_analyses(X_train_nb_lda, y_train, X_test_nb_lda, y_test, model_params)\n",
    "    ### e. Just on metadata + nb + w2v\n",
    "    logger.info(\"Getting metadata + naive bayes + w2v results\")\n",
    "    #X_train_nb_w2v = pd.concat((X_train_nb, pd.DataFrame(w2v_train)), axis=1)\n",
    "    #X_test_nb_w2v = pd.concat((X_test_nb, pd.DataFrame(w2v_test)), axis=1)\n",
    "    stat_df_nb_w2v, pred_df_nb_w2v, models_nb_w2v = PipelineHelper.run_analyses(X_train_nb_w2v, y_train, X_test_nb_w2v, y_test, model_params)\n",
    "    ### f. Just on metadata + nb + lda - cols to drop \n",
    "    logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "    cols_to_drop = [\n",
    "        'dummy_cat_id_290', 'dummy_cat_id_300', 'dummy_cat_id_317','dummy_cat_id_386', 'dummy_cat_id_352', #'dummy_cat_id_1',\n",
    "        'dummy_cat_id_355', 'dummy_cat_id_354', 'dummy_cat_id_321', 'dummy_cat_id_12', 'dummy_cat_id_340', 'dummy_cat_id_268', 'binned_usd_goal_outcome_mean'\n",
    "    ]\n",
    "    stat_df_nb_lda_drop, pred_df_nb_lda_drop, models_nb_lda_drop = PipelineHelper.run_analyses(\n",
    "        X_train_nb_lda.drop(columns=cols_to_drop), y_train, \n",
    "        X_test_nb_lda.drop(columns=cols_to_drop), y_test, model_params\n",
    "    )\n",
    "    ### g. Just on metadata + nb, scaled vars \n",
    "    model_params['linear_models']['logreg_penalty'] = 'l2'\n",
    "    model_params['linear_models']['logreg_C'] = 0.75\n",
    "    model_params['linear_models']['ridge_alpha'] = 0.5\n",
    "    model_params['linear_models']['lasso_alpha'] = 1\n",
    "\n",
    "    #X_train_nb_scale, X_test_nb_scale = PipelineHelper.scale_data(X_train_nb, X_test_nb)\n",
    "    logger.info(\"Getting metadata + naive bayes w/ scaled vars\")\n",
    "    stat_df_nb_scale, pred_df_nb_scale, models_nb_scale = PipelineHelper.run_analyses(\n",
    "        X_train_nb_scale, y_train, \n",
    "        X_test_nb_scale, y_test, model_params\n",
    "    )\n",
    "    logger.info(\"Getting metadata + naive bayes + nlp\")\n",
    "    stat_df_nb_nlp, pred_df_nb_nlp, models_nb_nlp = PipelineHelper.run_analyses(\n",
    "        X_train_nb_nlp, y_train, \n",
    "        X_test_nb_nlp, y_test, model_params\n",
    "    )\n",
    "    ### i. Metadata + nb + lda, scaled vars \n",
    "    #X_train_nb_lda_scale, X_test_nb_lda_scale = PipelineHelper.scale_data(X_train_nb_lda, X_test_nb_lda, addtl_cols=lda_train.columns)\n",
    "    #logger.info(\"Getting metadata + naive bayes + lda w/ scaled vars\")\n",
    "    #stat_df_nb_lda_scale, pred_df_nb_lda_scale, models_nb_lda_scale = PipelineHelper.run_analyses(\n",
    "    #    X_train_nb_lda_scale, y_train, \n",
    "    #    X_test_nb_lda_scale, y_test, model_params\n",
    "    #)\n",
    "    ### i. Metadata + nb + w2v, scaled vars \n",
    "    #X_train_nb_w2v_scale, X_test_nb_w2v_scale = PipelineHelper.scale_data(X_train_nb_w2v, X_test_nb_w2v, addtl_cols=w2v_train.columns)\n",
    "    #logger.info(\"Getting metadata + naive bayes + w2v w/ scaled vars\")\n",
    "    #stat_df_nb_w2v_scale, pred_df_nb_w2v_scale, models_nb_w2v_scale = PipelineHelper.run_analyses(\n",
    "    #    X_train_nb_w2v_scale, y_train, \n",
    "    #    X_test_nb_w2v_scale, y_test, model_params\n",
    "    #)\n",
    "    stat_df.insert(0, \"data\", \"metadata\"), \n",
    "    stat_df_nobinusd.insert(0, \"data\", \"metadata_nobin\"), \n",
    "    stat_df_nb.insert(0, \"data\", \"metadata_nb\"),\n",
    "    stat_df_nb_lda.insert(0, \"data\", \"metadata_nb_lda\"),\n",
    "    stat_df_nb_w2v.insert(0, \"data\", \"metadata_nb_w2v\"),\n",
    "    stat_df_nb_lda_drop.insert(0, \"data\", \"metadata_nb_lda_drop\")\n",
    "    stat_df_nb_scale.insert(0, \"data\", \"metadata_nb_scale\")\n",
    "    stat_df_nb_nlp.insert(0, \"data\", \"metadata_nb_nlp\")\n",
    "    #stat_df_nb_lda_scale.insert(0, \"data\", \"metadata_nb_lda_scale\")\n",
    "    #stat_df_nb_w2v_scale.insert(0, \"data\", \"metadata_nb_w2v_scale\")\n",
    "    \n",
    "    fin = (pd.concat((stat_df, stat_df_nobinusd, stat_df_nb, stat_df_nb_lda, stat_df_nb_w2v, stat_df_nb_lda_drop, stat_df_nb_scale, stat_df_nb_nlp))\n",
    "       .sort_values('accuracy', ascending=False)\n",
    "       .assign(\n",
    "           accuracy_rank = lambda x:np.arange(1, x.shape[0]+1, 1), \n",
    "           random_state = model_params['rseed']\n",
    "       )\n",
    "      )\n",
    "    fin_path = \"model_exports/test_size30/rseeds/mod\" + str(rseed) + \".csv\"\n",
    "    fin.to_csv(fin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7ce7c8ec-a4cc-4321-9453-4644a7793131",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata results\n",
      "INFO:PipelineHelper:Fitting linear models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating seed 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:__main__:Getting metadata - binned_usd_goal_outcome_mean results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:__main__:Getting metadata + naive bayes results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:__main__:Getting metadata + naive bayes + LDA results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:__main__:Getting metadata + naive bayes + w2v results\n",
      "INFO:PipelineHelper:Fitting linear models\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-65410560b402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnew_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m229\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating seed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrun_exps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-290ab365eb03>\u001b[0m in \u001b[0;36mrun_exps\u001b[0;34m(rseed)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#X_train_nb_w2v = pd.concat((X_train_nb, pd.DataFrame(w2v_train)), axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#X_test_nb_w2v = pd.concat((X_test_nb, pd.DataFrame(w2v_test)), axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mstat_df_nb_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_df_nb_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_nb_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipelineHelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_analyses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nb_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_nb_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m### f. Just on metadata + nb + lda - cols to drop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Getting metadata + naive bayes + LDA results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Stanford/Academic/Senior/Spring2021/CS229/cs229_kickstarter/PipelineHelper.py\u001b[0m in \u001b[0;36mrun_analyses\u001b[0;34m(X_train, y_train, X_test, y_test, params)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# fit linear models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting linear models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mlinear_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_linear_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linear_models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rseed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mstat_df_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_df_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# fit ensemble methods -- lgbm + random forest right now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Stanford/Academic/Senior/Spring2021/CS229/cs229_kickstarter/PipelineHelper.py\u001b[0m in \u001b[0;36mrun_linear_models\u001b[0;34m(X_train, y_train, train_weights, params, rseed)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# drop cols below to avoid perfect colinearity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mperf_col_dummies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dummy_cat_id_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dummy_cat_parent_id_1.0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperf_col_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;31m### b. Lasso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mclf_lasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lasso_alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4307\u001b[0m         \"\"\"\n\u001b[0;32m-> 4308\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4153\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4188\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4189\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4191\u001b[0m         \u001b[0;31m# Case for non-unique axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4174\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4175\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4178\u001b[0m     def drop(\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4810\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4811\u001b[0;31m         return self._reindex_axes(\n\u001b[0m\u001b[1;32m   4812\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4813\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4014\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4016\u001b[0;31m             frame = frame._reindex_columns(\n\u001b[0m\u001b[1;32m   4017\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4018\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_columns\u001b[0;34m(self, new_columns, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   4059\u001b[0m             \u001b[0mnew_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m         )\n\u001b[0;32m-> 4061\u001b[0;31m         return self._reindex_with_indexers(\n\u001b[0m\u001b[1;32m   4062\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4876\u001b[0m             \u001b[0;31m# TODO: speed up on homogeneous DataFrame objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4877\u001b[0;31m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[1;32m   4878\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4879\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m             new_blocks = self._slice_take_blocks_ax0(\n\u001b[0m\u001b[1;32m   1308\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_slice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice)\u001b[0m\n\u001b[1;32m   1435\u001b[0m                             \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m                         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m                         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1393\u001b[0m             \u001b[0mallow_fill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m   1757\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     )\n\u001b[0;32m-> 1759\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "for i in np.arange(3, 200):\n",
    "    new_seed = 229 + i\n",
    "    print(\"Calculating seed\", i)\n",
    "    run_exps(new_seed)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e23b98-af45-4f21-8904-4c135303d3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
