{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe534b5-5c35-4bf6-b542-6c033a5f9501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "from model_metrics import format_results\n",
    "import data_clean_for_model\n",
    "import PipelineHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d861f1-b211-4b97-8c9f-56ffe5f327c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae2605f-f0ee-4069-8887-4f7647dd8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Load Data\n",
    "df = pd.read_parquet(\"data/all_processed_df.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea58d9b5-5b77-495e-a7a1-be4c42603385",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "rseed = 229\n",
    "df[\"outcome\"] = np.where( df[\"state\"]==\"successful\", 1, 0, )\n",
    "df[\"un_id\"] = np.arange(0, df.shape[0], 1 )\n",
    "df[\"name_len\"] = df[\"name\"].str.len()\n",
    "df[\"cv_group\"] = np.random.choice( np.arange(0, k), size=df.shape[0] )\n",
    "df[\"binned_usd_goal\"] = pd.qcut( np.log(df[\"usd_goal\"]+1), 20 )\n",
    "\n",
    "with open(\"model_config.json\", 'r') as j:\n",
    "     model_params = json.loads(j.read())\n",
    "model_params['naive_bayes']['ngram_range'] = tuple(model_params['naive_bayes']['ngram_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46faff32-1d32-41d8-984f-6a9860f068a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading features\n"
     ]
    }
   ],
   "source": [
    "## load project metadata\n",
    "logger.info(\"Loading features\")\n",
    "try:\n",
    "    f = open(\"data/features.pkl\", \"rb\")\n",
    "    ft_dict = pickle.load(f)\n",
    "    f.close()\n",
    "    X_train, y_train, X_test, y_test = ft_dict.values()\n",
    "except:\n",
    "    X_train, X_test, y_train, y_test = data_clean_for_model.data_clean_for_model(df, \"outcome\", model_params, cv=model_params[\"cv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca905c0-29c3-4e06-bd52-7285c8291b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing text data\n"
     ]
    }
   ],
   "source": [
    "# load text\n",
    "logger.info(\"Processing text data\")\n",
    "blurb_train, blurb_test, _, _    = data_clean_for_model.process_blurb(df, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740672ed-c048-4bb1-a497-825a786d11f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading Naive Bayes predictions\n",
      "INFO:__main__:Loading LDA topic predictions\n",
      "INFO:__main__:Loading Word2Vec dimension predictions\n"
     ]
    }
   ],
   "source": [
    "## 2. Run text models\n",
    "\n",
    "# get naive bayes predictions\n",
    "logger.info(\"Loading Naive Bayes predictions\")\n",
    "try:\n",
    "    nb_proba_train = np.load(\"data/res/multi_nb_preds_train.npy\")\n",
    "    nb_proba_test = np.load(\"data/res/multi_nb_preds_test.npy\")\n",
    "except:\n",
    "    logger.info(\"Running Naive Bayes model\")\n",
    "    nb_params = model_params['naive_bayes']\n",
    "    nb_train_pred, nb_proba_train, nb_test_pred, nb_proba_test = PipelineHelper.naive_bayes_predictions(\n",
    "        blurb_train, y_train, blurb_test,\n",
    "        tfidf=nb_params['tf-idf'], ngram_range=nb_params['ngram_range']\n",
    "    )\n",
    "    np.save(\"data/res/multi_nb_preds_train.npy\", nb_proba_train)\n",
    "    np.save(\"data/res/multi_nb_preds_test.npy\", nb_proba_test)\n",
    "\n",
    "# get LDA topic model\n",
    "logger.info(\"Loading LDA topic predictions\")\n",
    "try:\n",
    "    lda_train = pd.read_csv(\"data/res/lda_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "    lda_test = pd.read_csv(\"data/res/lda_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "except:\n",
    "    logger.info(\"Running LDA topic model\")\n",
    "    lda_params = model_params['lda_params']\n",
    "    tokenized_train = blurb_train.apply(data_clean_for_model.tokenize_text)\n",
    "    tokenized_test = blurb_test.apply(data_clean_for_model.tokenize_text)\n",
    "    lda_train, lda_test = PipelineHelper.train_lda_model(tokenized_train, tokenized_test, params['lda'])\n",
    "    lda_train.to_csv(\"data/res/lda_train.csv\")\n",
    "    lda_test.to_csv(\"data/res/lda_test.csv\")\n",
    "\n",
    "# get Word2Vec model predictions\n",
    "logger.info(\"Loading Word2Vec dimension predictions\")\n",
    "try:\n",
    "    f = open(\"data/res/w2v_dict.pkl\", \"rb\")\n",
    "    w2v_dict = pickle.load(f)\n",
    "    f.close()\n",
    "    w2v_train, w2v_test = w2v_dict.values()\n",
    "except:\n",
    "    raise Warning(\"Word2Vec function not implemented. Running without it -- likely will crash.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d1d3ddc-7b69-449d-8f6a-61bd8f6da47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "INFO:PipelineHelper:Fitting ensemble models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    }
   ],
   "source": [
    "### a. Just on metadata\n",
    "logger.info(\"Getting metadata results\")\n",
    "stat_df, pred_df, models = PipelineHelper.run_analyses(X_train, y_train, X_test, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9570004-2d59-459a-88cc-b74b3fdd31f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata - binned_usd_goal_outcome_mean results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "INFO:PipelineHelper:Fitting ensemble models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    }
   ],
   "source": [
    "### b. Just on metadata, - binned_usd_goal_outcome_mean\n",
    "logger.info(\"Getting metadata - binned_usd_goal_outcome_mean results\")\n",
    "stat_df_nobinusd, pred_df_nobinusd, models_nobinusd = PipelineHelper.run_analyses(\n",
    "    X_train.drop(columns=['binned_usd_goal_outcome_mean']), y_train, \n",
    "    X_test.drop(columns=['binned_usd_goal_outcome_mean']), y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ed8457-3631-427f-9b5b-d12f6b172edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata + naive bayes results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "INFO:PipelineHelper:Fitting ensemble models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    }
   ],
   "source": [
    "### c. Just on metadata + nb \n",
    "logger.info(\"Getting metadata + naive bayes results\")\n",
    "X_train_nb = X_train.copy()\n",
    "X_test_nb = X_test.copy()\n",
    "# NB \n",
    "X_train_nb['nb_proba'] = nb_proba_train[:, 1]\n",
    "X_test_nb['nb_proba'] = nb_proba_test[:, 1]\n",
    "stat_df_nb, pred_df_nb, models_nb = PipelineHelper.run_analyses(X_train_nb, y_train, X_test_nb, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac6deaee-9d02-4911-8d4a-917afa73e59a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata + naive bayes + LDA results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "INFO:PipelineHelper:Fitting ensemble models\n"
     ]
    }
   ],
   "source": [
    "### d. Just on metadata + nb + lda\n",
    "logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "X_train_nb_lda = pd.concat((X_train_nb, lda_train), axis=1)\n",
    "X_test_nb_lda = pd.concat((X_test_nb, lda_test), axis=1)\n",
    "stat_df_nb_lda, pred_df_nb_lda, models_nb_lda = PipelineHelper.run_analyses(X_train_nb_lda, y_train, X_test_nb_lda, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26a48024-a6d9-4cdb-a359-0d216a04b89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata + naive bayes + w2v results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.15867e-23): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "INFO:PipelineHelper:Fitting ensemble models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    }
   ],
   "source": [
    "### e. Just on metadata + nb + w2v\n",
    "logger.info(\"Getting metadata + naive bayes + w2v results\")\n",
    "X_train_nb_w2v = pd.concat((X_train_nb, pd.DataFrame(w2v_train)), axis=1)\n",
    "X_test_nb_w2v = pd.concat((X_test_nb, pd.DataFrame(w2v_test)), axis=1)\n",
    "stat_df_nb_w2v, pred_df_nb_w2v, models_nb_w2v = PipelineHelper.run_analyses(X_train_nb_w2v, y_train, X_test_nb_w2v, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b86aad82-17d9-49f3-b8a6-2e988b5139d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata + naive bayes + LDA results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "INFO:PipelineHelper:Fitting ensemble models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    }
   ],
   "source": [
    "### f. Just on metadata + nb + lda - cols to drop \n",
    "logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "cols_to_drop = [\n",
    "    'dummy_cat_id_290', 'dummy_cat_id_300', 'dummy_cat_id_317','dummy_cat_id_386', 'dummy_cat_id_352', #'dummy_cat_id_1',\n",
    "    'dummy_cat_id_355', 'dummy_cat_id_354', 'dummy_cat_id_321', 'dummy_cat_id_12', 'dummy_cat_id_340', 'dummy_cat_id_268', 'binned_usd_goal_outcome_mean'\n",
    "]\n",
    "stat_df_nb_lda_drop, pred_df_nb_lda_drop, models_nb_lda_drop = PipelineHelper.run_analyses(\n",
    "    X_train_nb_lda.drop(columns=cols_to_drop), y_train, \n",
    "    X_test_nb_lda.drop(columns=cols_to_drop), y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127c872-f8ac-4692-a7ec-430cb4831875",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df.insert(0, \"data\", \"metadata\"), \n",
    "stat_df_nobinusd.insert(0, \"data\", \"metadata_nobin\"), \n",
    "stat_df_nb.insert(0, \"data\", \"metadata_nb\"),\n",
    "stat_df_nb_lda.insert(0, \"data\", \"metadata_nb_lda\"),\n",
    "stat_df_nb_w2v.insert(0, \"data\", \"metadata_nb_w2v\"),\n",
    "stat_df_nb_lda_drop.insert(0, \"data\", \"metadata_nb_lda_drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32f76b58-a22d-4360-9379-b0fa8530efc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>accuracy_rank</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.825431</td>\n",
       "      <td>0.848953</td>\n",
       "      <td>0.885703</td>\n",
       "      <td>0.750599</td>\n",
       "      <td>0.815130</td>\n",
       "      <td>0.841002</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.174569</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda_drop</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.823443</td>\n",
       "      <td>0.847502</td>\n",
       "      <td>0.882493</td>\n",
       "      <td>0.749517</td>\n",
       "      <td>0.815180</td>\n",
       "      <td>0.835932</td>\n",
       "      <td>0.825556</td>\n",
       "      <td>0.176557</td>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_w2v</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.823292</td>\n",
       "      <td>0.849325</td>\n",
       "      <td>0.872308</td>\n",
       "      <td>0.758067</td>\n",
       "      <td>0.827521</td>\n",
       "      <td>0.816899</td>\n",
       "      <td>0.822210</td>\n",
       "      <td>0.176708</td>\n",
       "      <td>3</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.822885</td>\n",
       "      <td>0.846587</td>\n",
       "      <td>0.884252</td>\n",
       "      <td>0.747070</td>\n",
       "      <td>0.812001</td>\n",
       "      <td>0.839337</td>\n",
       "      <td>0.825669</td>\n",
       "      <td>0.177115</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metadata_nb_lda</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.814192</td>\n",
       "      <td>0.838309</td>\n",
       "      <td>0.880065</td>\n",
       "      <td>0.734549</td>\n",
       "      <td>0.800335</td>\n",
       "      <td>0.835137</td>\n",
       "      <td>0.817736</td>\n",
       "      <td>0.185808</td>\n",
       "      <td>5</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data                   model  accuracy  f1_score  \\\n",
       "0           metadata_nb          LGBMClassifier  0.825431  0.848953   \n",
       "0  metadata_nb_lda_drop          LGBMClassifier  0.823443  0.847502   \n",
       "0       metadata_nb_w2v          LGBMClassifier  0.823292  0.849325   \n",
       "0       metadata_nb_lda          LGBMClassifier  0.822885  0.846587   \n",
       "1       metadata_nb_lda  RandomForestClassifier  0.814192  0.838309   \n",
       "\n",
       "   precision_1  precision_0  recall_1  recall_0   roc_auc     brier  \\\n",
       "0     0.885703     0.750599  0.815130  0.841002  0.828066  0.174569   \n",
       "0     0.882493     0.749517  0.815180  0.835932  0.825556  0.176557   \n",
       "0     0.872308     0.758067  0.827521  0.816899  0.822210  0.176708   \n",
       "0     0.884252     0.747070  0.812001  0.839337  0.825669  0.177115   \n",
       "1     0.880065     0.734549  0.800335  0.835137  0.817736  0.185808   \n",
       "\n",
       "   accuracy_rank  random_state  \n",
       "0              1           229  \n",
       "0              2           229  \n",
       "0              3           229  \n",
       "0              4           229  \n",
       "1              5           229  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin = (pd.concat((stat_df, stat_df_nobinusd, stat_df_nb, stat_df_nb_lda, stat_df_nb_w2v, stat_df_nb_lda_drop))\n",
    "       .sort_values('accuracy', ascending=False)\n",
    "       .assign(\n",
    "           accuracy_rank = lambda x:np.arange(1, x.shape[0]+1, 1), \n",
    "           random_state = model_params['rseed']\n",
    "       )\n",
    "      )\n",
    "fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adba2f63-183f-45e0-8926-29d542344d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata_metadata_LinearRegression_pred</th>\n",
       "      <th>metadata_metadata_Lasso_pred</th>\n",
       "      <th>metadata_metadata_Ridge_pred</th>\n",
       "      <th>metadata_metadata_LogisticRegression_pred</th>\n",
       "      <th>metadata_metadata_LGBMClassifier_pred</th>\n",
       "      <th>metadata_metadata_RandomForestClassifier_pred</th>\n",
       "      <th>metadata_nobin_LinearRegression_pred</th>\n",
       "      <th>metadata_nobin_Lasso_pred</th>\n",
       "      <th>metadata_nobin_Ridge_pred</th>\n",
       "      <th>metadata_nobin_LogisticRegression_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>metadata_nb_w2v_Ridge_pred</th>\n",
       "      <th>metadata_nb_w2v_LogisticRegression_pred</th>\n",
       "      <th>metadata_nb_w2v_LGBMClassifier_pred</th>\n",
       "      <th>metadata_nb_w2v_RandomForestClassifier_pred</th>\n",
       "      <th>metadata_nb_lda_drop_LinearRegression_pred</th>\n",
       "      <th>metadata_nb_lda_drop_Lasso_pred</th>\n",
       "      <th>metadata_nb_lda_drop_Ridge_pred</th>\n",
       "      <th>metadata_nb_lda_drop_LogisticRegression_pred</th>\n",
       "      <th>metadata_nb_lda_drop_LGBMClassifier_pred</th>\n",
       "      <th>metadata_nb_lda_drop_RandomForestClassifier_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.832675</td>\n",
       "      <td>0.651824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.655646</td>\n",
       "      <td>0.832675</td>\n",
       "      <td>0.652055</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800469</td>\n",
       "      <td>0.832675</td>\n",
       "      <td>0.803503</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144957</td>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.144069</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138541</td>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.137552</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136281</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072070</td>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.079891</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488107</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.488423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479006</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.479338</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577682</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.581687</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.579625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.036096</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.037228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.027969</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.028984</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.201803</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.107628</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.102822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.154730</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.154283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192137</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.191644</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278180</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.279277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   metadata_metadata_LinearRegression_pred  metadata_metadata_Lasso_pred  \\\n",
       "0                                 0.655400                      0.832675   \n",
       "1                                 0.144957                      0.473552   \n",
       "2                                 0.488107                      0.425906   \n",
       "3                                 1.036096                      0.832221   \n",
       "4                                 0.154730                      0.290907   \n",
       "\n",
       "   metadata_metadata_Ridge_pred  metadata_metadata_LogisticRegression_pred  \\\n",
       "0                      0.651824                                          1   \n",
       "1                      0.144069                                          1   \n",
       "2                      0.488423                                          1   \n",
       "3                      1.037228                                          1   \n",
       "4                      0.154283                                          0   \n",
       "\n",
       "   metadata_metadata_LGBMClassifier_pred  \\\n",
       "0                                      1   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      1   \n",
       "4                                      0   \n",
       "\n",
       "   metadata_metadata_RandomForestClassifier_pred  \\\n",
       "0                                              1   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              1   \n",
       "4                                              0   \n",
       "\n",
       "   metadata_nobin_LinearRegression_pred  metadata_nobin_Lasso_pred  \\\n",
       "0                              0.655646                   0.832675   \n",
       "1                              0.138541                   0.473552   \n",
       "2                              0.479006                   0.425906   \n",
       "3                              1.027969                   0.832221   \n",
       "4                              0.192137                   0.290907   \n",
       "\n",
       "   metadata_nobin_Ridge_pred  metadata_nobin_LogisticRegression_pred  ...  \\\n",
       "0                   0.652055                                       1  ...   \n",
       "1                   0.137552                                       1  ...   \n",
       "2                   0.479338                                       1  ...   \n",
       "3                   1.028984                                       1  ...   \n",
       "4                   0.191644                                       0  ...   \n",
       "\n",
       "   metadata_nb_w2v_Ridge_pred  metadata_nb_w2v_LogisticRegression_pred  \\\n",
       "0                    0.761006                                        1   \n",
       "1                    0.136281                                        1   \n",
       "2                    0.577682                                        1   \n",
       "3                    1.201803                                        1   \n",
       "4                    0.140261                                        0   \n",
       "\n",
       "   metadata_nb_w2v_LGBMClassifier_pred  \\\n",
       "0                                    1   \n",
       "1                                    0   \n",
       "2                                    1   \n",
       "3                                    1   \n",
       "4                                    0   \n",
       "\n",
       "   metadata_nb_w2v_RandomForestClassifier_pred  \\\n",
       "0                                            1   \n",
       "1                                            0   \n",
       "2                                            1   \n",
       "3                                            1   \n",
       "4                                            0   \n",
       "\n",
       "   metadata_nb_lda_drop_LinearRegression_pred  \\\n",
       "0                                    0.800469   \n",
       "1                                    0.072070   \n",
       "2                                    0.581687   \n",
       "3                                    1.107628   \n",
       "4                                    0.278180   \n",
       "\n",
       "   metadata_nb_lda_drop_Lasso_pred  metadata_nb_lda_drop_Ridge_pred  \\\n",
       "0                         0.832675                         0.803503   \n",
       "1                         0.473552                         0.079891   \n",
       "2                         0.425906                         0.579625   \n",
       "3                         0.832221                         1.102822   \n",
       "4                         0.290907                         0.279277   \n",
       "\n",
       "   metadata_nb_lda_drop_LogisticRegression_pred  \\\n",
       "0                                             1   \n",
       "1                                             1   \n",
       "2                                             1   \n",
       "3                                             1   \n",
       "4                                             0   \n",
       "\n",
       "   metadata_nb_lda_drop_LGBMClassifier_pred  \\\n",
       "0                                         1   \n",
       "1                                         0   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         0   \n",
       "\n",
       "   metadata_nb_lda_drop_RandomForestClassifier_pred  \n",
       "0                                                 1  \n",
       "1                                                 0  \n",
       "2                                                 0  \n",
       "3                                                 1  \n",
       "4                                                 0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.columns = \"metadata_\" + pred_df.columns\n",
    "pred_df_nobinusd.columns = \"metadata_nobin_\" + pred_df_nobinusd.columns\n",
    "pred_df_nb.columns = \"metadata_nb_\" + pred_df_nb.columns\n",
    "pred_df_nb_lda.columns = \"metadata_nb_lda_\" + pred_df_nb_lda.columns\n",
    "pred_df_nb_w2v.columns = \"metadata_nb_w2v_\" + pred_df_nb_w2v.columns\n",
    "pred_df_nb_lda_drop.columns = \"metadata_nb_lda_drop_\" + pred_df_nb_lda_drop.columns\n",
    "pred_fin = pd.concat((pred_df, pred_df_nobinusd, pred_df_nb, pred_df_nb_lda, pred_df_nb_w2v, pred_df_nb_lda_drop), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
