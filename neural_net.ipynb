{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9168d7-4afc-42a9-80da-5c9001867e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import json\n",
    "\n",
    "from model_metrics import format_results\n",
    "import data_clean_for_model\n",
    "import PipelineHelper\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511e3920-3b0d-4e22-8e3e-6268e03d9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5460441-712f-4546-9dbd-6a6b79caea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Load Data\n",
    "df = pd.read_parquet(\"data/all_processed_df.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac49239-d2b7-4a63-a874-2f0e7b902ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "rseed = 229\n",
    "df[\"outcome\"] = np.where( df[\"state\"]==\"successful\", 1, 0, )\n",
    "df[\"un_id\"] = np.arange(0, df.shape[0], 1 )\n",
    "df[\"name_len\"] = df[\"name\"].str.len()\n",
    "df[\"cv_group\"] = np.random.choice( np.arange(0, k), size=df.shape[0] )\n",
    "df[\"binned_usd_goal\"] = pd.qcut( np.log(df[\"usd_goal\"]+1), 20 )\n",
    "\n",
    "with open(\"model_config.json\", 'r') as j:\n",
    "     model_params = json.loads(j.read())\n",
    "model_params['naive_bayes']['ngram_range'] = tuple(model_params['naive_bayes']['ngram_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690c25c7-7e31-4d6e-b075-dd90c26307b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading features\n"
     ]
    }
   ],
   "source": [
    "## load project metadata\n",
    "logger.info(\"Loading features\")\n",
    "try:\n",
    "    f = open(\"data/features.pkl\", \"rb\")\n",
    "    ft_dict = pickle.load(f)\n",
    "    f.close()\n",
    "    X_train, y_train, X_test, y_test = ft_dict.values()\n",
    "except:\n",
    "    X_train, X_test, y_train, y_test = data_clean_for_model.data_clean_for_model(df, \"outcome\", model_params, cv=model_params[\"cv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d3468c2-836f-401e-a94f-6d6d8cf60c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing text data\n"
     ]
    }
   ],
   "source": [
    "# load text\n",
    "logger.info(\"Processing text data\")\n",
    "blurb_train, blurb_test, _, _    = data_clean_for_model.process_blurb(df, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3c4b28-0d69-4d23-b992-26e7a5031ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading Naive Bayes predictions\n",
      "INFO:__main__:Loading LDA topic predictions\n",
      "INFO:__main__:Loading Word2Vec dimension predictions\n"
     ]
    }
   ],
   "source": [
    "## 2. Run text models\n",
    "\n",
    "try: \n",
    "    f = open(\"data/res/text_models.pkl\", \"rb\")\n",
    "    text_models = pickle.load(f)\n",
    "    f.close()\n",
    "except:\n",
    "    raise Warning(\"Text models do not exist. Will load from scratch\")\n",
    "# get naive bayes predictions\n",
    "logger.info(\"Loading Naive Bayes predictions\")\n",
    "try:\n",
    "    #nb_proba_train = np.load(\"data/res/multi_nb_preds_train.npy\")\n",
    "    #nb_proba_test = np.load(\"data/res/multi_nb_preds_test.npy\")\n",
    "    nb_proba_train, nb_proba_test = text_models['nb_train'], text_models['nb_test']\n",
    "except:\n",
    "    logger.info(\"Running Naive Bayes model\")\n",
    "    nb_params = model_params['naive_bayes']\n",
    "    nb_train_pred, nb_proba_train, nb_test_pred, nb_proba_test = PipelineHelper.naive_bayes_predictions(\n",
    "        blurb_train, y_train, blurb_test,\n",
    "        tfidf=nb_params['tf-idf'], ngram_range=nb_params['ngram_range']\n",
    "    )\n",
    "    np.save(\"data/res/multi_nb_preds_train.npy\", nb_proba_train)\n",
    "    np.save(\"data/res/multi_nb_preds_test.npy\", nb_proba_test)\n",
    "\n",
    "# get LDA topic model\n",
    "logger.info(\"Loading LDA topic predictions\")\n",
    "try:\n",
    "    lda_train, lda_test = text_models['lda_train'], text_models['lda_test']\n",
    "    #lda_train = pd.read_csv(\"data/res/lda_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "    #lda_test = pd.read_csv(\"data/res/lda_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "except:\n",
    "    logger.info(\"Running LDA topic model\")\n",
    "    lda_params = model_params['lda']\n",
    "    tokenized_train = blurb_train.apply(data_clean_for_model.tokenize_text)\n",
    "    tokenized_test = blurb_test.apply(data_clean_for_model.tokenize_text)\n",
    "    lda_train, lda_test = PipelineHelper.train_lda_model(tokenized_train, tokenized_test, params['lda'])\n",
    "    lda_train.to_csv(\"data/res/lda_train.csv\")\n",
    "    lda_test.to_csv(\"data/res/lda_test.csv\")\n",
    "\n",
    "# get Word2Vec model predictions\n",
    "logger.info(\"Loading Word2Vec dimension predictions\")\n",
    "try:\n",
    "    #f = open(\"data/res/w2v_dict.pkl\", \"rb\")\n",
    "    #w2v_dict = pickle.load(f)\n",
    "    #f.close()\n",
    "    #w2v_train, w2v_test = w2v_dict.values()\n",
    "    w2v_train, w2v_test = text_models['w2v_train'], text_models['w2v_test']\n",
    "except:\n",
    "    raise Warning(\"Word2Vec function not implemented. Running without it -- likely will crash.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf49833-3b8a-4ff4-9ab1-58213b2045f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## HACK: change train size (only downside here is that we are not also updating our NB/LDA/W2V performance)\n",
    "new_train_ind = int(X_test.shape[0]/3)\n",
    "X_train = pd.concat((X_train, X_test[0:new_train_ind])).reset_index(drop=True)\n",
    "X_test = X_test[new_train_ind:].reset_index(drop=True)\n",
    "\n",
    "nb_proba_train = np.vstack((nb_proba_train, nb_proba_test[0:new_train_ind, :]))\n",
    "nb_proba_test = nb_proba_test[new_train_ind:, :]\n",
    "\n",
    "lda_train = pd.concat((lda_train, lda_test[0:new_train_ind])).reset_index(drop=True)\n",
    "lda_test = lda_test[new_train_ind:].reset_index(drop=True)\n",
    "\n",
    "w2v_train = pd.concat((pd.DataFrame(w2v_train), pd.DataFrame(w2v_test)[0:new_train_ind] )).reset_index(drop=True)\n",
    "w2v_test = pd.DataFrame(w2v_test)[new_train_ind:].reset_index(drop=True)\n",
    "\n",
    "y_train = pd.concat((y_train, y_test[0:new_train_ind])).reset_index(drop=True)\n",
    "y_test = y_test[new_train_ind:].reset_index(drop=True)\n",
    "\n",
    "assert X_train.shape[0] == nb_proba_train.shape[0] == lda_train.shape[0] == w2v_train.shape[0]\n",
    "assert X_test.shape[0] == nb_proba_test.shape[0] == lda_test.shape[0] == w2v_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3438346f-8c89-44fd-a1d8-2b17f5a9dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f825ea4-7995-4047-917b-2feabe37949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8607ce-7810-45df-bad6-8c3012ee2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afdc850c-dd6c-4cff-ae1c-2d6136756758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84fd4cf-c0e4-42f7-9d58-4575f2ceda74",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = [\"un_id\", \"cv_group\"]\n",
    "id_train = X_train[id_vars]\n",
    "id_test = X_test[id_vars]\n",
    "X_train = X_train.drop(columns=id_vars)\n",
    "X_test = X_test.drop(columns=id_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff8de117-b523-468d-aa90-8382382bbefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nb = X_train.copy()\n",
    "X_test_nb = X_test.copy()\n",
    "# NB \n",
    "X_train_nb['nb_proba'] = nb_proba_train[:, 1]\n",
    "X_test_nb['nb_proba'] = nb_proba_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a9bb1de-75c9-4a52-ac29-ab3b0492a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "time_vars = [\"deadline\", \"launched_at\", \"time_diff\"]\n",
    "scale_vars = [\"blurb_len\", \"name_len\"] + time_vars\n",
    "X_train_nb_scale = X_train_nb.copy()\n",
    "X_test_nb_scale = X_test_nb.copy()\n",
    "X_train_nb_scale[ scale_vars ] = scaler.fit_transform(X_train_nb[ scale_vars ])\n",
    "X_test_nb_scale[ scale_vars ] = scaler.transform(X_test_nb[ scale_vars ])\n",
    "X_train_nb_scale2 = X_train_nb_scale.copy()\n",
    "X_test_nb_scale2 = X_test_nb_scale.copy()\n",
    "usd_goal_cols = X_train_nb_scale2.columns[X_train_nb_scale2.columns.str.contains(\"usd_goal\")]\n",
    "X_train_nb_scale2[ usd_goal_cols ] = scaler.fit_transform(X_train_nb_scale2[ usd_goal_cols ])\n",
    "X_test_nb_scale2[ usd_goal_cols ] = scaler.transform(X_test_nb_scale2[ usd_goal_cols ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d65e6f92-0e6c-4ec4-8b48-0abb5f13ef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  2.1min remaining:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 83.02% (1.09%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=X_train_nb_scale2.shape[1], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model \n",
    "\n",
    "est = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=10, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=229)\n",
    "results = cross_val_score(est, X_train_nb_scale2.iloc[0:10000], y_train[0:10000], cv=kfold, verbose=5, n_jobs=4)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da784d0b-78d1-4944-87f8-f3efd568333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed: 24.7min remaining: 37.0min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed: 36.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 84.82% (0.55%)\n"
     ]
    }
   ],
   "source": [
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=X_train_nb_scale2.shape[1], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model \n",
    "est = KerasClassifier(build_fn=create_baseline, epochs=30, batch_size=5, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=229)\n",
    "results = cross_val_score(est, X_train_nb_scale2, y_train, cv=kfold, verbose=5, n_jobs=4)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68227c90-432e-440c-9b3c-c174cf6c6b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85101694, 0.84870058, 0.85384178, 0.8495155 , 0.83782029])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "160fd5ef-5b20-4909-a200-51ad6eeaa20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline(input_layer=25):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_layer, input_dim=X_train_nb_scale2.shape[1], activation='selu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61274a84-98f0-4ac7-8a96-159805a5e092",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30975/30975 [==============================] - 45s 1ms/step - loss: 0.3459 - accuracy: 0.8290 - val_loss: 0.3890 - val_accuracy: 0.8078\n",
      "Epoch 2/20\n",
      "30975/30975 [==============================] - 39s 1ms/step - loss: 0.3211 - accuracy: 0.8432 - val_loss: 0.3872 - val_accuracy: 0.8050\n",
      "Epoch 3/20\n",
      "30975/30975 [==============================] - 44s 1ms/step - loss: 0.3158 - accuracy: 0.8466 - val_loss: 0.3993 - val_accuracy: 0.8040\n",
      "Epoch 4/20\n",
      "30975/30975 [==============================] - 43s 1ms/step - loss: 0.3128 - accuracy: 0.8483 - val_loss: 0.3747 - val_accuracy: 0.8114\n",
      "Epoch 5/20\n",
      "30975/30975 [==============================] - 43s 1ms/step - loss: 0.3109 - accuracy: 0.8486 - val_loss: 0.3737 - val_accuracy: 0.8131\n",
      "Epoch 6/20\n",
      "30975/30975 [==============================] - 49s 2ms/step - loss: 0.3095 - accuracy: 0.8497 - val_loss: 0.3875 - val_accuracy: 0.8102\n",
      "Epoch 7/20\n",
      "30975/30975 [==============================] - 45s 1ms/step - loss: 0.3082 - accuracy: 0.8502 - val_loss: 0.3706 - val_accuracy: 0.8167\n",
      "Epoch 8/20\n",
      "30975/30975 [==============================] - 47s 2ms/step - loss: 0.3072 - accuracy: 0.8509 - val_loss: 0.3739 - val_accuracy: 0.8159\n",
      "Epoch 9/20\n",
      "30975/30975 [==============================] - 48s 2ms/step - loss: 0.3061 - accuracy: 0.8518 - val_loss: 0.3737 - val_accuracy: 0.8150\n",
      "Epoch 10/20\n",
      "30975/30975 [==============================] - 48s 2ms/step - loss: 0.3053 - accuracy: 0.8516 - val_loss: 0.3785 - val_accuracy: 0.8113\n",
      "Epoch 11/20\n",
      "30975/30975 [==============================] - 45s 1ms/step - loss: 0.3048 - accuracy: 0.8523 - val_loss: 0.3699 - val_accuracy: 0.8151\n",
      "Epoch 12/20\n",
      "30975/30975 [==============================] - 46s 1ms/step - loss: 0.3041 - accuracy: 0.8521 - val_loss: 0.3689 - val_accuracy: 0.8178\n",
      "Epoch 13/20\n",
      "30975/30975 [==============================] - 41s 1ms/step - loss: 0.3034 - accuracy: 0.8533 - val_loss: 0.3773 - val_accuracy: 0.8152\n",
      "Epoch 14/20\n",
      "30975/30975 [==============================] - 40s 1ms/step - loss: 0.3029 - accuracy: 0.8534 - val_loss: 0.3739 - val_accuracy: 0.8163\n",
      "Epoch 15/20\n",
      "30975/30975 [==============================] - 41s 1ms/step - loss: 0.3024 - accuracy: 0.8531 - val_loss: 0.3720 - val_accuracy: 0.8171\n",
      "Epoch 16/20\n",
      "30975/30975 [==============================] - 39s 1ms/step - loss: 0.3018 - accuracy: 0.8539 - val_loss: 0.3693 - val_accuracy: 0.8179\n",
      "Epoch 17/20\n",
      "30975/30975 [==============================] - 44s 1ms/step - loss: 0.3014 - accuracy: 0.8541 - val_loss: 0.3694 - val_accuracy: 0.8176\n",
      "Epoch 18/20\n",
      "30975/30975 [==============================] - 39s 1ms/step - loss: 0.3012 - accuracy: 0.8539 - val_loss: 0.3759 - val_accuracy: 0.8164\n",
      "Epoch 19/20\n",
      "30975/30975 [==============================] - 37s 1ms/step - loss: 0.3007 - accuracy: 0.8544 - val_loss: 0.3702 - val_accuracy: 0.8168\n",
      "Epoch 20/20\n",
      "30975/30975 [==============================] - 39s 1ms/step - loss: 0.3004 - accuracy: 0.8539 - val_loss: 0.3771 - val_accuracy: 0.8157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.815683615819209"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = create_baseline()\n",
    "mod.fit(X_train_nb_scale2, y_train, validation_data=(X_test_nb_scale2,y_test), batch_size = 5, epochs = 20, class_weight = {0:1.24764767, 1:0.8343821})\n",
    "y_pred = mod.predict(X_test_nb_scale2)\n",
    "y_pred\n",
    "(np.round(y_pred).flatten()==y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc898a05-3748-4fc8-92bc-cd5ef6299e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82, 0.84, 0.88, 0.74, 0.8 , 0.84, 0.82, 0.18])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(calculate_performance(y_test, np.round(y_pred.ravel())),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed8a09-0598-4e5c-8632-c3437b241299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54557354-16ee-4312-b860-9ad1cbe2f7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/nns/metadata_nb_nn_batch5_epochs30_dim_25.tf/assets\n"
     ]
    }
   ],
   "source": [
    "mod.save(\"data/nns/metadata_nb_nn_batch5_epochs30_dim_25.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b801b5b0-11a7-448d-b969-5541936754ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51625/51625 [==============================] - 64s 1ms/step - loss: 0.3410 - accuracy: 0.8359 - val_loss: 0.3771 - val_accuracy: 0.8091\n",
      "Epoch 2/10\n",
      "51625/51625 [==============================] - 56s 1ms/step - loss: 0.3169 - accuracy: 0.8492 - val_loss: 0.3815 - val_accuracy: 0.8079\n",
      "Epoch 3/10\n",
      "51625/51625 [==============================] - 62s 1ms/step - loss: 0.3118 - accuracy: 0.8518 - val_loss: 0.3752 - val_accuracy: 0.8124\n",
      "Epoch 4/10\n",
      "51625/51625 [==============================] - 57s 1ms/step - loss: 0.3091 - accuracy: 0.8531 - val_loss: 0.3758 - val_accuracy: 0.8083\n",
      "Epoch 5/10\n",
      "51625/51625 [==============================] - 57s 1ms/step - loss: 0.3073 - accuracy: 0.8542 - val_loss: 0.3711 - val_accuracy: 0.8115\n",
      "Epoch 6/10\n",
      "51625/51625 [==============================] - 60s 1ms/step - loss: 0.3058 - accuracy: 0.8540 - val_loss: 0.3774 - val_accuracy: 0.8122\n",
      "Epoch 7/10\n",
      "51625/51625 [==============================] - 57s 1ms/step - loss: 0.3048 - accuracy: 0.8553 - val_loss: 0.3721 - val_accuracy: 0.8114s - los\n",
      "Epoch 8/10\n",
      "51625/51625 [==============================] - 56s 1ms/step - loss: 0.3036 - accuracy: 0.8559 - val_loss: 0.3735 - val_accuracy: 0.8110s - l - ETA: 3s - los - ETA: 2s - loss: 0.3 - ETA\n",
      "Epoch 9/10\n",
      "51625/51625 [==============================] - 58s 1ms/step - loss: 0.3028 - accuracy: 0.8566 - val_loss: 0.3721 - val_accuracy: 0.8149\n",
      "Epoch 10/10\n",
      "51625/51625 [==============================] - 58s 1ms/step - loss: 0.3023 - accuracy: 0.8563 - val_loss: 0.3725 - val_accuracy: 0.8115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8114500941619586"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = create_baseline(50)\n",
    "mod.fit(X_train_nb_scale2, y_train, validation_data=(X_test_nb_scale2,y_test), batch_size = 3, epochs = 10)\n",
    "y_pred = mod.predict(X_test_nb_scale2)\n",
    "y_pred\n",
    "(np.round(y_pred).flatten()==y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fbbf6-32ec-49fa-9429-efbb2117bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.save(\"data/nns/nn_batch5_epochs7_dim50.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb159fbf-17da-4e62-8405-015313fae516",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "13417/30975 [===========>..................] - ETA: 18s - loss: 23.5298 - accuracy: 0.5795 ETA: 19s - loss: 23.8"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6052f2391964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nb_scale2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nb_scale2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nb_scale2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_baseline(input_layer=25):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_layer, input_dim=X_train_nb_scale2.shape[1], activation='selu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model \n",
    "mod = create_baseline(25)\n",
    "mod.fit(X_train_nb_scale2, y_train, validation_data=(X_test_nb_scale2,y_test), batch_size = 5, epochs = 15)\n",
    "y_pred = mod.predict(X_test_nb_scale2)\n",
    "y_pred\n",
    "(np.round(y_pred).flatten()==y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7b7c143-ac80-472d-b89e-2b5272cf8229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=0         1\n",
      "1         0\n",
      "2         1\n",
      "3         0\n",
      "4         1\n",
      "         ..\n",
      "154868    1\n",
      "154869    1\n",
      "154870    1\n",
      "154871    1\n",
      "154872    1\n",
      "Name: outcome, Length: 154873, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.24764767, 0.8343821 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train.reset_index(drop=True))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efd5682d-645f-4f88-bc6c-71ce37c90354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.4089 - accuracy: 0.7789 - val_loss: 0.3958 - val_accuracy: 0.7915\n",
      "Epoch 2/15\n",
      "30975/30975 [==============================] - 39s 1ms/step - loss: 0.3859 - accuracy: 0.7918 - val_loss: 0.3841 - val_accuracy: 0.7973\n",
      "Epoch 3/15\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.3789 - accuracy: 0.7955 - val_loss: 0.3871 - val_accuracy: 0.7966\n",
      "Epoch 4/15\n",
      "30975/30975 [==============================] - 39s 1ms/step - loss: 0.3745 - accuracy: 0.7975 - val_loss: 0.3907 - val_accuracy: 0.7900\n",
      "Epoch 5/15\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.3724 - accuracy: 0.7983 - val_loss: 0.3782 - val_accuracy: 0.7988\n",
      "Epoch 6/15\n",
      "30975/30975 [==============================] - 40s 1ms/step - loss: 0.3705 - accuracy: 0.7992 - val_loss: 0.3851 - val_accuracy: 0.7943\n",
      "Epoch 7/15\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.3693 - accuracy: 0.7992 - val_loss: 0.3808 - val_accuracy: 0.7997\n",
      "Epoch 8/15\n",
      "30975/30975 [==============================] - 49s 2ms/step - loss: 0.3682 - accuracy: 0.8009 - val_loss: 0.3745 - val_accuracy: 0.8002\n",
      "Epoch 9/15\n",
      "30975/30975 [==============================] - 37s 1ms/step - loss: 0.3673 - accuracy: 0.8015 - val_loss: 0.3758 - val_accuracy: 0.8019\n",
      "Epoch 10/15\n",
      "30975/30975 [==============================] - 36s 1ms/step - loss: 0.3662 - accuracy: 0.8017 - val_loss: 0.3778 - val_accuracy: 0.8000\n",
      "Epoch 11/15\n",
      "30975/30975 [==============================] - 37s 1ms/step - loss: 0.3659 - accuracy: 0.8019 - val_loss: 0.3793 - val_accuracy: 0.7986\n",
      "Epoch 12/15\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.3652 - accuracy: 0.8029 - val_loss: 0.3827 - val_accuracy: 0.7955y\n",
      "Epoch 13/15\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.3649 - accuracy: 0.8026 - val_loss: 0.3696 - val_accuracy: 0.8053\n",
      "Epoch 14/15\n",
      "30975/30975 [==============================] - 41s 1ms/step - loss: 0.3646 - accuracy: 0.8025 - val_loss: 0.3794 - val_accuracy: 0.8000\n",
      "Epoch 15/15\n",
      "30975/30975 [==============================] - 37s 1ms/step - loss: 0.3640 - accuracy: 0.8030 - val_loss: 0.3771 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.799984934086629"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_baseline(input_layer=25):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_layer, input_dim=X_train_nb_scale2.drop(columns=\"nb_proba\").shape[1], activation='selu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model \n",
    "mod = create_baseline(25)\n",
    "mod.fit(X_train_nb_scale2.drop(columns=\"nb_proba\"), y_train, validation_data=(X_test_nb_scale2.drop(columns=\"nb_proba\"),y_test), batch_size = 5, epochs = 15, \n",
    "       class_weight = {0:1.24764767, 1:0.8343821}\n",
    "       )\n",
    "y_pred = mod.predict(X_test_nb_scale2.drop(columns=\"nb_proba\"))\n",
    "y_pred\n",
    "(np.round(y_pred).flatten()==y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69e8e194-0751-4389-b032-dae5f75cf431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/nns/metadata_nn_batch5_epoch15_dim25.tf/assets\n"
     ]
    }
   ],
   "source": [
    "mod.save(\"data/nns/metadata_nn_batch5_epoch15_dim25.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddf87f21-d7c7-406c-8d6a-6f90fa0fd8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_metrics import calculate_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f07aeb64-2864-4def-aba4-0138a1f7670f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8 , 0.82, 0.9 , 0.7 , 0.75, 0.88, 0.81, 0.2 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(calculate_performance(y_test, np.round(y_pred.ravel())),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0c916-5ad8-40b4-8a63-67b931e92fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22388828-f55d-4fc2-b43e-1b2c243e1442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89caa6c2-5257-4b91-8de6-bd1181e27ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/nns/nn_batch5_epochs7_dim50.tf/assets\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "680fe40f-d8de-489d-b5a6-8f1cd81f68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nb_lda_scale = pd.concat((X_train_nb_scale2, lda_train), axis=1).copy() \n",
    "X_test_nb_lda_scale =pd.concat((X_test_nb_scale2, lda_test), axis=1).copy() \n",
    "X_train_nb_lda_scale[ lda_train.columns ] = scaler.fit_transform(X_train_nb_lda_scale[ lda_train.columns ])\n",
    "X_test_nb_lda_scale[ lda_train.columns ] = scaler.transform(X_test_nb_lda_scale[ lda_train.columns ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3bac4c2-b281-406e-9b0c-5821e0fa3026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "30975/30975 [==============================] - 44s 1ms/step - loss: 0.3411 - accuracy: 0.8342 - val_loss: 0.3798 - val_accuracy: 0.8090\n",
      "Epoch 2/7\n",
      "30975/30975 [==============================] - 37s 1ms/step - loss: 0.3126 - accuracy: 0.8503 - val_loss: 0.3701 - val_accuracy: 0.8124\n",
      "Epoch 3/7\n",
      "30975/30975 [==============================] - 78s 3ms/step - loss: 0.3051 - accuracy: 0.8550 - val_loss: 0.3763 - val_accuracy: 0.8112\n",
      "Epoch 4/7\n",
      "30975/30975 [==============================] - 66s 2ms/step - loss: 0.3002 - accuracy: 0.8572 - val_loss: 0.3681 - val_accuracy: 0.8152\n",
      "Epoch 5/7\n",
      "30975/30975 [==============================] - 53s 2ms/step - loss: 0.2973 - accuracy: 0.8596 - val_loss: 0.3697 - val_accuracy: 0.8133\n",
      "Epoch 6/7\n",
      "30975/30975 [==============================] - 44s 1ms/step - loss: 0.2949 - accuracy: 0.8610 - val_loss: 0.3686 - val_accuracy: 0.8149\n",
      "Epoch 7/7\n",
      "30975/30975 [==============================] - 46s 1ms/step - loss: 0.2931 - accuracy: 0.8620 - val_loss: 0.3772 - val_accuracy: 0.8121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8121431261770244"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_baseline(input_layer=25):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_layer, input_dim=X_train_nb_lda_scale.shape[1], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model \n",
    "mod = create_baseline(50)\n",
    "mod.fit(X_train_nb_lda_scale, y_train, validation_data=(X_test_nb_lda_scale,y_test), batch_size = 5, epochs = 7)\n",
    "y_pred = mod.predict(X_test_nb_lda_scale)\n",
    "y_pred\n",
    "(np.round(y_pred).flatten()==y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a6a28b8-d07c-4627-b599-eab4a83136cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.3490 - accuracy: 0.8312 - val_loss: 0.3885 - val_accuracy: 0.8044\n",
      "Epoch 2/7\n",
      "30975/30975 [==============================] - 35s 1ms/step - loss: 0.3201 - accuracy: 0.8474 - val_loss: 0.3864 - val_accuracy: 0.8059\n",
      "Epoch 3/7\n",
      "30975/30975 [==============================] - 35s 1ms/step - loss: 0.3126 - accuracy: 0.8509 - val_loss: 0.3764 - val_accuracy: 0.8079\n",
      "Epoch 4/7\n",
      "30975/30975 [==============================] - 33s 1ms/step - loss: 0.3086 - accuracy: 0.8539 - val_loss: 0.3705 - val_accuracy: 0.8126\n",
      "Epoch 5/7\n",
      "30975/30975 [==============================] - 33s 1ms/step - loss: 0.3058 - accuracy: 0.8546 - val_loss: 0.3665 - val_accuracy: 0.8138\n",
      "Epoch 6/7\n",
      "30975/30975 [==============================] - 33s 1ms/step - loss: 0.3041 - accuracy: 0.8553 - val_loss: 0.3701 - val_accuracy: 0.8121\n",
      "Epoch 7/7\n",
      "30975/30975 [==============================] - 35s 1ms/step - loss: 0.3023 - accuracy: 0.8571 - val_loss: 0.3660 - val_accuracy: 0.8138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8138154425612053"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2 = create_baseline(25)\n",
    "mod2.fit(X_train_nb_lda_scale, y_train, validation_data=(X_test_nb_lda_scale,y_test), batch_size = 5, epochs = 7)\n",
    "y_pred = mod2.predict(X_test_nb_lda_scale)\n",
    "y_pred\n",
    "(np.round(y_pred).flatten()==y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51e3f6a8-106d-44a7-a69c-e4fc30fdc377",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nb_w2v_scale = pd.concat((X_train_nb_scale2, w2v_train), axis=1).copy() \n",
    "X_test_nb_w2v_scale =pd.concat((X_test_nb_scale2, w2v_test), axis=1).copy() \n",
    "X_train_nb_w2v_scale[ w2v_train.columns ] = scaler.fit_transform(X_train_nb_w2v_scale[ w2v_train.columns ])\n",
    "X_test_nb_w2v_scale[ w2v_train.columns ] = scaler.transform(X_test_nb_w2v_scale[ w2v_train.columns ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f35fcf22-0af8-4121-bca9-ba75aae895c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30975/30975 [==============================] - 49s 2ms/step - loss: 0.3863 - accuracy: 0.8079 - val_loss: 0.3821 - val_accuracy: 0.8070\n",
      "Epoch 2/10\n",
      "30975/30975 [==============================] - 40s 1ms/step - loss: 0.3267 - accuracy: 0.8425 - val_loss: 0.3796 - val_accuracy: 0.8087\n",
      "Epoch 3/10\n",
      "30975/30975 [==============================] - 41s 1ms/step - loss: 0.3063 - accuracy: 0.8547 - val_loss: 0.3841 - val_accuracy: 0.8103\n",
      "Epoch 4/10\n",
      "30975/30975 [==============================] - 39s 1ms/step - loss: 0.2957 - accuracy: 0.8616 - val_loss: 0.4027 - val_accuracy: 0.8022\n",
      "Epoch 5/10\n",
      "30975/30975 [==============================] - 39s 1ms/step - loss: 0.2876 - accuracy: 0.8663 - val_loss: 0.3859 - val_accuracy: 0.8080\n",
      "Epoch 6/10\n",
      "30975/30975 [==============================] - 39s 1ms/step - loss: 0.2819 - accuracy: 0.8694 - val_loss: 0.3937 - val_accuracy: 0.8065\n",
      "Epoch 7/10\n",
      "30975/30975 [==============================] - 35s 1ms/step - loss: 0.2769 - accuracy: 0.8716 - val_loss: 0.4032 - val_accuracy: 0.8049\n",
      "Epoch 8/10\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.2724 - accuracy: 0.8754 - val_loss: 0.4275 - val_accuracy: 0.7969\n",
      "Epoch 9/10\n",
      "30975/30975 [==============================] - 36s 1ms/step - loss: 0.2696 - accuracy: 0.8755 - val_loss: 0.4034 - val_accuracy: 0.8069\n",
      "Epoch 10/10\n",
      "30975/30975 [==============================] - 36s 1ms/step - loss: 0.2671 - accuracy: 0.8770 - val_loss: 0.4052 - val_accuracy: 0.8066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8066290018832392"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_baseline(input_layer=25):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_layer, input_dim=X_train_nb_w2v_scale.shape[1], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model \n",
    "mod3 = create_baseline(25)\n",
    "mod3.fit(X_train_nb_w2v_scale, y_train, validation_data=(X_test_nb_w2v_scale,y_test), batch_size = 5, epochs = 10)\n",
    "y_pred = mod3.predict(X_test_nb_w2v_scale)\n",
    "y_pred\n",
    "(np.round(y_pred).flatten()==y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12501363-9ec3-45b7-bec0-a346601fba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30975/30975 [==============================] - 36s 1ms/step - loss: 0.3291 - accuracy: 0.8435 - val_loss: 0.3744 - val_accuracy: 0.8120\n",
      "Epoch 2/10\n",
      "30975/30975 [==============================] - 34s 1ms/step - loss: 0.3087 - accuracy: 0.8543 - val_loss: 0.3735 - val_accuracy: 0.8136\n",
      "Epoch 3/10\n",
      "30975/30975 [==============================] - 36s 1ms/step - loss: 0.3044 - accuracy: 0.8559 - val_loss: 0.3780 - val_accuracy: 0.8137\n",
      "Epoch 4/10\n",
      "30975/30975 [==============================] - 40s 1ms/step - loss: 0.3017 - accuracy: 0.8579 - val_loss: 0.3716 - val_accuracy: 0.8155\n",
      "Epoch 5/10\n",
      "30975/30975 [==============================] - 34s 1ms/step - loss: 0.3006 - accuracy: 0.8586 - val_loss: 0.3689 - val_accuracy: 0.8171\n",
      "Epoch 6/10\n",
      "30975/30975 [==============================] - 34s 1ms/step - loss: 0.2996 - accuracy: 0.8589 - val_loss: 0.3666 - val_accuracy: 0.8147\n",
      "Epoch 7/10\n",
      "30975/30975 [==============================] - 33s 1ms/step - loss: 0.2990 - accuracy: 0.8593 - val_loss: 0.3649 - val_accuracy: 0.8172\n",
      "Epoch 8/10\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.2983 - accuracy: 0.8593 - val_loss: 0.3693 - val_accuracy: 0.8165\n",
      "Epoch 9/10\n",
      "30975/30975 [==============================] - 33s 1ms/step - loss: 0.2975 - accuracy: 0.8607 - val_loss: 0.3619 - val_accuracy: 0.8154\n",
      "Epoch 10/10\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.2975 - accuracy: 0.8604 - val_loss: 0.3661 - val_accuracy: 0.8178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8178229755178907"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_baseline(input_layer=25):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_layer, input_dim=tmp_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model \n",
    "tmp_train = scaler.fit_transform(X_train_nb)\n",
    "tmp_test = scaler.transform(X_test_nb)\n",
    "tmp_mod = create_baseline(25)\n",
    "tmp_mod.fit(tmp_train, y_train, validation_data=(tmp_test,y_test), batch_size = 5, epochs = 10)\n",
    "y_pred = tmp_mod.predict(tmp_test)\n",
    "y_pred\n",
    "(np.round(y_pred).flatten()==y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "924346b6-ccca-4a71-9f11-0c03c642cb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "30975/30975 [==============================] - 42s 1ms/step - loss: 0.3304 - accuracy: 0.8427 - val_loss: 0.3765 - val_accuracy: 0.8123\n",
      "Epoch 2/14\n",
      "30975/30975 [==============================] - 34s 1ms/step - loss: 0.3086 - accuracy: 0.8541 - val_loss: 0.3739 - val_accuracy: 0.8126\n",
      "Epoch 3/14\n",
      "30975/30975 [==============================] - 44s 1ms/step - loss: 0.3039 - accuracy: 0.8562 - val_loss: 0.3750 - val_accuracy: 0.8123\n",
      "Epoch 4/14\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.3026 - accuracy: 0.8582 - val_loss: 0.3695 - val_accuracy: 0.8146\n",
      "Epoch 5/14\n",
      "30975/30975 [==============================] - 36s 1ms/step - loss: 0.3007 - accuracy: 0.8583 - val_loss: 0.3674 - val_accuracy: 0.8166\n",
      "Epoch 6/14\n",
      "30975/30975 [==============================] - 38s 1ms/step - loss: 0.3001 - accuracy: 0.8591 - val_loss: 0.3758 - val_accuracy: 0.8142\n",
      "Epoch 7/14\n",
      "30975/30975 [==============================] - 34s 1ms/step - loss: 0.2990 - accuracy: 0.8594 - val_loss: 0.3738 - val_accuracy: 0.8145\n",
      "Epoch 8/14\n",
      "30975/30975 [==============================] - 53s 2ms/step - loss: 0.2992 - accuracy: 0.8599 - val_loss: 0.3735 - val_accuracy: 0.8167\n",
      "Epoch 9/14\n",
      "30975/30975 [==============================] - 41s 1ms/step - loss: 0.2984 - accuracy: 0.8599 - val_loss: 0.3711 - val_accuracy: 0.8159\n",
      "Epoch 10/14\n",
      "30975/30975 [==============================] - 35s 1ms/step - loss: 0.2975 - accuracy: 0.8610 - val_loss: 0.3664 - val_accuracy: 0.8155\n",
      "Epoch 11/14\n",
      "30975/30975 [==============================] - 36s 1ms/step - loss: 0.2970 - accuracy: 0.8609 - val_loss: 0.3791 - val_accuracy: 0.8145\n",
      "Epoch 12/14\n",
      "30975/30975 [==============================] - 35s 1ms/step - loss: 0.2964 - accuracy: 0.8607 - val_loss: 0.3744 - val_accuracy: 0.8138\n",
      "Epoch 13/14\n",
      "30975/30975 [==============================] - 35s 1ms/step - loss: 0.2966 - accuracy: 0.8608 - val_loss: 0.3691 - val_accuracy: 0.8177\n",
      "Epoch 14/14\n",
      "30975/30975 [==============================] - 32s 1ms/step - loss: 0.2968 - accuracy: 0.8611 - val_loss: 0.3683 - val_accuracy: 0.8168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8167532956685499"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_mod2 = create_baseline(35)\n",
    "tmp_mod2.fit(tmp_train, y_train, validation_data=(tmp_test,y_test), batch_size = 5, epochs = 14)\n",
    "y_pred = tmp_mod2.predict(tmp_test)\n",
    "y_pred\n",
    "(np.round(y_pred).flatten()==y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30abac0-74d8-4dfe-aeea-934fa6924157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f220487b-fae7-4efc-9e01-81d48f5cb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "58f2a41b-e7ba-4312-ae8e-829834a1b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline(layer=1, output_dim=3, init_activation='sigmoid', final_activation=\"sigmoid\", optimizer='adam'):\n",
    "    np.random.seed(229)\n",
    "    tf.random.set_seed(229)\n",
    "    model = Sequential()\n",
    "    if layer==1:\n",
    "        model.add(Dense(output_dim, input_dim=X_train_nb_scale2.shape[1], activation=init_activation))\n",
    "    if layer==2: \n",
    "        model.add(Dense(output_dim, input_dim=X_train_nb_scale2.shape[1], activation=init_activation))\n",
    "        model.add(Dense(3, activation='relu'))\n",
    "    if layer==3: \n",
    "        model.add(Dense(output_dim, input_dim=X_train_nb_scale2.shape[1], activation=init_activation))\n",
    "        model.add(Dense(5, activation='relu'))\n",
    "        model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation=final_activation))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "60f32791-9190-4944-9c8a-d45d933d5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = KerasClassifier(build_fn=create_baseline, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c873250f-f047-412b-b7e0-6122cd3eabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [75, 100, 150]\n",
    "batches = [3]\n",
    "layers = [1]\n",
    "output_dims = [30]\n",
    "activations = ['selu']\n",
    "fin_activations=['sigmoid', 'tanh']\n",
    "param_grid = dict(epochs=epochs, batch_size=batches, layer=layers, output_dim=output_dims, init_activation=activations, final_activation=fin_activations)\n",
    "ggrid = GridSearchCV(estimator=model_grid, param_grid=param_grid, cv=2, verbose=3, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a773ca2e-dbb6-4863-93e6-8c11b333ca37",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "Epoch 1/150\n",
      "59000/59000 [==============================] - 62s 1ms/step - loss: 0.3485 - accuracy: 0.8309 - val_loss: 0.3854 - val_accuracy: 0.8053\n",
      "Epoch 2/150\n",
      "59000/59000 [==============================] - 58s 986us/step - loss: 0.3278 - accuracy: 0.8421 - val_loss: 0.3727 - val_accuracy: 0.8126\n",
      "Epoch 3/150\n",
      "59000/59000 [==============================] - 56s 945us/step - loss: 0.3220 - accuracy: 0.8452 - val_loss: 0.3722 - val_accuracy: 0.8153\n",
      "Epoch 4/150\n",
      "59000/59000 [==============================] - 54s 920us/step - loss: 0.3184 - accuracy: 0.8467 - val_loss: 0.3714 - val_accuracy: 0.8129\n",
      "Epoch 5/150\n",
      "59000/59000 [==============================] - 54s 921us/step - loss: 0.3159 - accuracy: 0.8485 - val_loss: 0.3623 - val_accuracy: 0.8164\n",
      "Epoch 6/150\n",
      "59000/59000 [==============================] - 56s 943us/step - loss: 0.3143 - accuracy: 0.8489 - val_loss: 0.3621 - val_accuracy: 0.8184\n",
      "Epoch 7/150\n",
      "59000/59000 [==============================] - 54s 918us/step - loss: 0.3127 - accuracy: 0.8504 - val_loss: 0.3648 - val_accuracy: 0.8188\n",
      "Epoch 8/150\n",
      "59000/59000 [==============================] - 55s 929us/step - loss: 0.3118 - accuracy: 0.8502 - val_loss: 0.3640 - val_accuracy: 0.8171\n",
      "Epoch 9/150\n",
      "59000/59000 [==============================] - 55s 934us/step - loss: 0.3108 - accuracy: 0.8504 - val_loss: 0.3641 - val_accuracy: 0.8197\n",
      "Epoch 10/150\n",
      "59000/59000 [==============================] - 56s 957us/step - loss: 0.3101 - accuracy: 0.8515 - val_loss: 0.3643 - val_accuracy: 0.8181\n",
      "Epoch 11/150\n",
      "59000/59000 [==============================] - 80s 1ms/step - loss: 0.3096 - accuracy: 0.8519 - val_loss: 0.3644 - val_accuracy: 0.8188\n",
      "Epoch 12/150\n",
      "59000/59000 [==============================] - 69s 1ms/step - loss: 0.3092 - accuracy: 0.8518 - val_loss: 0.3584 - val_accuracy: 0.8192\n",
      "Epoch 13/150\n",
      "59000/59000 [==============================] - 68s 1ms/step - loss: 0.3086 - accuracy: 0.8521 - val_loss: 0.3621 - val_accuracy: 0.8165\n",
      "Epoch 14/150\n",
      "59000/59000 [==============================] - 68s 1ms/step - loss: 0.3081 - accuracy: 0.8529 - val_loss: 0.3612 - val_accuracy: 0.8194\n",
      "Epoch 15/150\n",
      "59000/59000 [==============================] - 67s 1ms/step - loss: 0.3078 - accuracy: 0.8525 - val_loss: 0.3646 - val_accuracy: 0.8175\n",
      "Epoch 16/150\n",
      "59000/59000 [==============================] - 66s 1ms/step - loss: 0.3076 - accuracy: 0.8525 - val_loss: 0.3631 - val_accuracy: 0.8182\n",
      "Epoch 17/150\n",
      "59000/59000 [==============================] - 71s 1ms/step - loss: 0.3073 - accuracy: 0.8526 - val_loss: 0.3603 - val_accuracy: 0.8179\n",
      "Epoch 18/150\n",
      "59000/59000 [==============================] - 71s 1ms/step - loss: 0.3070 - accuracy: 0.8531 - val_loss: 0.3622 - val_accuracy: 0.8177\n",
      "Epoch 19/150\n",
      "59000/59000 [==============================] - 72s 1ms/step - loss: 0.3069 - accuracy: 0.8534 - val_loss: 0.3694 - val_accuracy: 0.8168\n",
      "Epoch 20/150\n",
      "59000/59000 [==============================] - 69s 1ms/step - loss: 0.3065 - accuracy: 0.8529 - val_loss: 0.3636 - val_accuracy: 0.8201\n",
      "Epoch 21/150\n",
      "59000/59000 [==============================] - 68s 1ms/step - loss: 0.3062 - accuracy: 0.8530 - val_loss: 0.3643 - val_accuracy: 0.8192\n",
      "Epoch 22/150\n",
      "59000/59000 [==============================] - 75s 1ms/step - loss: 0.3063 - accuracy: 0.8533 - val_loss: 0.3615 - val_accuracy: 0.8180\n",
      "Epoch 23/150\n",
      "59000/59000 [==============================] - 73s 1ms/step - loss: 0.3058 - accuracy: 0.8539 - val_loss: 0.3625 - val_accuracy: 0.8211\n",
      "Epoch 24/150\n",
      "59000/59000 [==============================] - 88s 1ms/step - loss: 0.3059 - accuracy: 0.8537 - val_loss: 0.3606 - val_accuracy: 0.8192\n",
      "Epoch 25/150\n",
      "59000/59000 [==============================] - 77s 1ms/step - loss: 0.3057 - accuracy: 0.8543 - val_loss: 0.3619 - val_accuracy: 0.8190\n",
      "Epoch 26/150\n",
      "59000/59000 [==============================] - 70s 1ms/step - loss: 0.3053 - accuracy: 0.8544 - val_loss: 0.3610 - val_accuracy: 0.8191\n",
      "Epoch 27/150\n",
      "59000/59000 [==============================] - 69s 1ms/step - loss: 0.3053 - accuracy: 0.8542 - val_loss: 0.3569 - val_accuracy: 0.8202\n",
      "Epoch 28/150\n",
      "59000/59000 [==============================] - 70s 1ms/step - loss: 0.3051 - accuracy: 0.8542 - val_loss: 0.3715 - val_accuracy: 0.8166\n",
      "Epoch 29/150\n",
      "59000/59000 [==============================] - 70s 1ms/step - loss: 0.3051 - accuracy: 0.8542 - val_loss: 0.3624 - val_accuracy: 0.8199\n",
      "Epoch 30/150\n",
      "59000/59000 [==============================] - 70s 1ms/step - loss: 0.3050 - accuracy: 0.8545 - val_loss: 0.3676 - val_accuracy: 0.8152\n",
      "Epoch 31/150\n",
      "59000/59000 [==============================] - 67s 1ms/step - loss: 0.3048 - accuracy: 0.8545 - val_loss: 0.3693 - val_accuracy: 0.8152\n",
      "Epoch 32/150\n",
      "59000/59000 [==============================] - 72s 1ms/step - loss: 0.3045 - accuracy: 0.8544 - val_loss: 0.3623 - val_accuracy: 0.8203\n",
      "Epoch 33/150\n",
      "59000/59000 [==============================] - 68s 1ms/step - loss: 0.3045 - accuracy: 0.8545 - val_loss: 0.3611 - val_accuracy: 0.8201\n",
      "Epoch 34/150\n",
      "59000/59000 [==============================] - 73s 1ms/step - loss: 0.3046 - accuracy: 0.8550 - val_loss: 0.3580 - val_accuracy: 0.8206\n",
      "Epoch 35/150\n",
      "59000/59000 [==============================] - 75s 1ms/step - loss: 0.3045 - accuracy: 0.8546 - val_loss: 0.3598 - val_accuracy: 0.8199\n",
      "Epoch 36/150\n",
      "59000/59000 [==============================] - 73s 1ms/step - loss: 0.3042 - accuracy: 0.8548 - val_loss: 0.3572 - val_accuracy: 0.8210\n",
      "Epoch 37/150\n",
      "59000/59000 [==============================] - 71s 1ms/step - loss: 0.3043 - accuracy: 0.8549 - val_loss: 0.3635 - val_accuracy: 0.8153\n",
      "Epoch 38/150\n",
      "59000/59000 [==============================] - 70s 1ms/step - loss: 0.3043 - accuracy: 0.8547 - val_loss: 0.3659 - val_accuracy: 0.8201\n",
      "Epoch 39/150\n",
      "59000/59000 [==============================] - 70s 1ms/step - loss: 0.3042 - accuracy: 0.8550 - val_loss: 0.3633 - val_accuracy: 0.8192\n",
      "Epoch 40/150\n",
      "59000/59000 [==============================] - 72s 1ms/step - loss: 0.3041 - accuracy: 0.8548 - val_loss: 0.3672 - val_accuracy: 0.8166\n",
      "Epoch 41/150\n",
      "59000/59000 [==============================] - 70s 1ms/step - loss: 0.3040 - accuracy: 0.8548 - val_loss: 0.3605 - val_accuracy: 0.8203\n",
      "Epoch 42/150\n",
      "59000/59000 [==============================] - 77s 1ms/step - loss: 0.3038 - accuracy: 0.8550 - val_loss: 0.3557 - val_accuracy: 0.8200\n",
      "Epoch 43/150\n",
      "59000/59000 [==============================] - 113s 2ms/step - loss: 0.3038 - accuracy: 0.8547 - val_loss: 0.3662 - val_accuracy: 0.8185\n",
      "Epoch 44/150\n",
      "59000/59000 [==============================] - 58s 990us/step - loss: 0.3039 - accuracy: 0.8547 - val_loss: 0.3617 - val_accuracy: 0.8187\n",
      "Epoch 45/150\n",
      "59000/59000 [==============================] - 57s 958us/step - loss: 0.3039 - accuracy: 0.8550 - val_loss: 0.3618 - val_accuracy: 0.8202\n",
      "Epoch 46/150\n",
      "59000/59000 [==============================] - 57s 960us/step - loss: 0.3037 - accuracy: 0.8552 - val_loss: 0.3586 - val_accuracy: 0.8184\n",
      "Epoch 47/150\n",
      "59000/59000 [==============================] - 56s 954us/step - loss: 0.3037 - accuracy: 0.8546 - val_loss: 0.3645 - val_accuracy: 0.8206\n",
      "Epoch 48/150\n",
      "59000/59000 [==============================] - 56s 951us/step - loss: 0.3036 - accuracy: 0.8553 - val_loss: 0.3631 - val_accuracy: 0.8214\n",
      "Epoch 49/150\n",
      "59000/59000 [==============================] - 57s 973us/step - loss: 0.3036 - accuracy: 0.8549 - val_loss: 0.3613 - val_accuracy: 0.8207\n",
      "Epoch 50/150\n",
      "59000/59000 [==============================] - 57s 963us/step - loss: 0.3036 - accuracy: 0.8549 - val_loss: 0.3570 - val_accuracy: 0.8207\n",
      "Epoch 51/150\n",
      "59000/59000 [==============================] - 59s 994us/step - loss: 0.3035 - accuracy: 0.8547 - val_loss: 0.3594 - val_accuracy: 0.8178\n",
      "Epoch 52/150\n",
      "59000/59000 [==============================] - 66s 1ms/step - loss: 0.3035 - accuracy: 0.8546 - val_loss: 0.3614 - val_accuracy: 0.8190\n",
      "Epoch 53/150\n",
      "59000/59000 [==============================] - 58s 991us/step - loss: 0.3033 - accuracy: 0.8553 - val_loss: 0.3590 - val_accuracy: 0.8180\n",
      "Epoch 54/150\n",
      "59000/59000 [==============================] - 57s 961us/step - loss: 0.3034 - accuracy: 0.8549 - val_loss: 0.3602 - val_accuracy: 0.8176\n",
      "Epoch 55/150\n",
      "59000/59000 [==============================] - 57s 959us/step - loss: 0.3033 - accuracy: 0.8551 - val_loss: 0.3681 - val_accuracy: 0.8164\n",
      "Epoch 56/150\n",
      "59000/59000 [==============================] - 55s 938us/step - loss: 0.3034 - accuracy: 0.8557 - val_loss: 0.3657 - val_accuracy: 0.8194\n",
      "Epoch 57/150\n",
      "59000/59000 [==============================] - 57s 963us/step - loss: 0.3034 - accuracy: 0.8554 - val_loss: 0.3593 - val_accuracy: 0.8223\n",
      "Epoch 58/150\n",
      "59000/59000 [==============================] - 55s 939us/step - loss: 0.3033 - accuracy: 0.8554 - val_loss: 0.3569 - val_accuracy: 0.8199\n",
      "Epoch 59/150\n",
      "59000/59000 [==============================] - 57s 965us/step - loss: 0.3031 - accuracy: 0.8548 - val_loss: 0.3613 - val_accuracy: 0.8191\n",
      "Epoch 60/150\n",
      "59000/59000 [==============================] - 60s 1ms/step - loss: 0.3032 - accuracy: 0.8551 - val_loss: 0.3591 - val_accuracy: 0.8210\n",
      "Epoch 61/150\n",
      "59000/59000 [==============================] - 64s 1ms/step - loss: 0.3031 - accuracy: 0.8548 - val_loss: 0.3619 - val_accuracy: 0.8203\n",
      "Epoch 62/150\n",
      "59000/59000 [==============================] - 57s 967us/step - loss: 0.3033 - accuracy: 0.8551 - val_loss: 0.3602 - val_accuracy: 0.8170\n",
      "Epoch 63/150\n",
      "59000/59000 [==============================] - 58s 980us/step - loss: 0.3030 - accuracy: 0.8550 - val_loss: 0.3621 - val_accuracy: 0.8190\n",
      "Epoch 64/150\n",
      "59000/59000 [==============================] - 56s 944us/step - loss: 0.3031 - accuracy: 0.8549 - val_loss: 0.3640 - val_accuracy: 0.8188\n",
      "Epoch 65/150\n",
      "59000/59000 [==============================] - 55s 939us/step - loss: 0.3032 - accuracy: 0.8555 - val_loss: 0.3643 - val_accuracy: 0.8186\n",
      "Epoch 66/150\n",
      "59000/59000 [==============================] - 56s 957us/step - loss: 0.3029 - accuracy: 0.8554 - val_loss: 0.3572 - val_accuracy: 0.8194\n",
      "Epoch 67/150\n",
      "59000/59000 [==============================] - 56s 948us/step - loss: 0.3032 - accuracy: 0.8548 - val_loss: 0.3602 - val_accuracy: 0.8214\n",
      "Epoch 68/150\n",
      "59000/59000 [==============================] - 57s 962us/step - loss: 0.3031 - accuracy: 0.8553 - val_loss: 0.3603 - val_accuracy: 0.8197\n",
      "Epoch 69/150\n",
      "59000/59000 [==============================] - 56s 945us/step - loss: 0.3031 - accuracy: 0.8552 - val_loss: 0.3635 - val_accuracy: 0.8181\n",
      "Epoch 70/150\n",
      "59000/59000 [==============================] - 59s 1ms/step - loss: 0.3031 - accuracy: 0.8547 - val_loss: 0.3601 - val_accuracy: 0.8178\n",
      "Epoch 71/150\n",
      "59000/59000 [==============================] - 56s 951us/step - loss: 0.3028 - accuracy: 0.8555 - val_loss: 0.3613 - val_accuracy: 0.8182\n",
      "Epoch 72/150\n",
      "59000/59000 [==============================] - 56s 948us/step - loss: 0.3030 - accuracy: 0.8554 - val_loss: 0.3622 - val_accuracy: 0.8190\n",
      "Epoch 73/150\n",
      "59000/59000 [==============================] - 57s 969us/step - loss: 0.3031 - accuracy: 0.8555 - val_loss: 0.3632 - val_accuracy: 0.8191\n",
      "Epoch 74/150\n",
      "59000/59000 [==============================] - 56s 943us/step - loss: 0.3030 - accuracy: 0.8553 - val_loss: 0.3597 - val_accuracy: 0.8200\n",
      "Epoch 75/150\n",
      "59000/59000 [==============================] - 57s 973us/step - loss: 0.3031 - accuracy: 0.8553 - val_loss: 0.3640 - val_accuracy: 0.8196\n",
      "Epoch 76/150\n",
      "59000/59000 [==============================] - 56s 953us/step - loss: 0.3028 - accuracy: 0.8558 - val_loss: 0.3663 - val_accuracy: 0.8182\n",
      "Epoch 77/150\n",
      "59000/59000 [==============================] - 56s 952us/step - loss: 0.3029 - accuracy: 0.8559 - val_loss: 0.3597 - val_accuracy: 0.8187\n",
      "Epoch 78/150\n",
      "59000/59000 [==============================] - 56s 948us/step - loss: 0.3027 - accuracy: 0.8557 - val_loss: 0.3725 - val_accuracy: 0.8161\n",
      "Epoch 79/150\n",
      "59000/59000 [==============================] - 59s 1ms/step - loss: 0.3029 - accuracy: 0.8554 - val_loss: 0.3628 - val_accuracy: 0.8202\n",
      "Epoch 80/150\n",
      "59000/59000 [==============================] - 57s 958us/step - loss: 0.3026 - accuracy: 0.8556 - val_loss: 0.3619 - val_accuracy: 0.8214\n",
      "Epoch 81/150\n",
      "59000/59000 [==============================] - 55s 940us/step - loss: 0.3029 - accuracy: 0.8552 - val_loss: 0.3616 - val_accuracy: 0.8197\n",
      "Epoch 82/150\n",
      "59000/59000 [==============================] - 60s 1ms/step - loss: 0.3026 - accuracy: 0.8553 - val_loss: 0.3671 - val_accuracy: 0.8173\n",
      "Epoch 83/150\n",
      "59000/59000 [==============================] - 57s 967us/step - loss: 0.3027 - accuracy: 0.8557 - val_loss: 0.3627 - val_accuracy: 0.8194\n",
      "Epoch 84/150\n",
      "59000/59000 [==============================] - 58s 980us/step - loss: 0.3026 - accuracy: 0.8561 - val_loss: 0.3644 - val_accuracy: 0.8176\n",
      "Epoch 85/150\n",
      "59000/59000 [==============================] - 56s 946us/step - loss: 0.3028 - accuracy: 0.8552 - val_loss: 0.3608 - val_accuracy: 0.8194\n",
      "Epoch 86/150\n",
      "59000/59000 [==============================] - 121s 2ms/step - loss: 0.3027 - accuracy: 0.8557 - val_loss: 0.3612 - val_accuracy: 0.8192\n",
      "Epoch 87/150\n",
      "59000/59000 [==============================] - 110s 2ms/step - loss: 0.3027 - accuracy: 0.8551 - val_loss: 0.3609 - val_accuracy: 0.8209\n",
      "Epoch 88/150\n",
      "59000/59000 [==============================] - 108s 2ms/step - loss: 0.3026 - accuracy: 0.8558 - val_loss: 0.3640 - val_accuracy: 0.8207\n",
      "Epoch 89/150\n",
      "59000/59000 [==============================] - 118s 2ms/step - loss: 0.3028 - accuracy: 0.8553 - val_loss: 0.3635 - val_accuracy: 0.8204\n",
      "Epoch 90/150\n",
      "59000/59000 [==============================] - 127s 2ms/step - loss: 0.3024 - accuracy: 0.8554 - val_loss: 0.3581 - val_accuracy: 0.8203\n",
      "Epoch 91/150\n",
      "59000/59000 [==============================] - 111s 2ms/step - loss: 0.3027 - accuracy: 0.8562 - val_loss: 0.3575 - val_accuracy: 0.8188\n",
      "Epoch 92/150\n",
      "59000/59000 [==============================] - 95s 2ms/step - loss: 0.3027 - accuracy: 0.8554 - val_loss: 0.3604 - val_accuracy: 0.8196\n",
      "Epoch 93/150\n",
      "59000/59000 [==============================] - 73s 1ms/step - loss: 0.3025 - accuracy: 0.8564 - val_loss: 0.3749 - val_accuracy: 0.8174\n",
      "Epoch 94/150\n",
      "59000/59000 [==============================] - 68s 1ms/step - loss: 0.3026 - accuracy: 0.8556 - val_loss: 0.3623 - val_accuracy: 0.8206\n",
      "Epoch 95/150\n",
      "59000/59000 [==============================] - 68s 1ms/step - loss: 0.3029 - accuracy: 0.8553 - val_loss: 0.3614 - val_accuracy: 0.8200\n",
      "Epoch 96/150\n",
      "59000/59000 [==============================] - 79s 1ms/step - loss: 0.3025 - accuracy: 0.8552 - val_loss: 0.3661 - val_accuracy: 0.8188\n",
      "Epoch 97/150\n",
      "59000/59000 [==============================] - 59s 1ms/step - loss: 0.3024 - accuracy: 0.8554 - val_loss: 0.3589 - val_accuracy: 0.8201\n",
      "Epoch 98/150\n",
      "59000/59000 [==============================] - 60s 1ms/step - loss: 0.3025 - accuracy: 0.8557 - val_loss: 0.3659 - val_accuracy: 0.8190\n",
      "Epoch 99/150\n",
      "59000/59000 [==============================] - 59s 1ms/step - loss: 0.3024 - accuracy: 0.8553 - val_loss: 0.3571 - val_accuracy: 0.8214\n",
      "Epoch 100/150\n",
      "59000/59000 [==============================] - 60s 1ms/step - loss: 0.3027 - accuracy: 0.8557 - val_loss: 0.3641 - val_accuracy: 0.8206\n",
      "Epoch 101/150\n",
      "59000/59000 [==============================] - 60s 1ms/step - loss: 0.3025 - accuracy: 0.8561 - val_loss: 0.3628 - val_accuracy: 0.8180\n",
      "Epoch 102/150\n",
      "59000/59000 [==============================] - 61s 1ms/step - loss: 0.3025 - accuracy: 0.8562 - val_loss: 0.3628 - val_accuracy: 0.8198\n",
      "Epoch 103/150\n",
      "59000/59000 [==============================] - 61s 1ms/step - loss: 0.3025 - accuracy: 0.8556 - val_loss: 0.3679 - val_accuracy: 0.8177\n",
      "Epoch 104/150\n",
      "59000/59000 [==============================] - 55s 924us/step - loss: 0.3026 - accuracy: 0.8555 - val_loss: 0.3605 - val_accuracy: 0.8191\n",
      "Epoch 105/150\n",
      "59000/59000 [==============================] - 54s 922us/step - loss: 0.3026 - accuracy: 0.8553 - val_loss: 0.3618 - val_accuracy: 0.8201\n",
      "Epoch 106/150\n",
      "59000/59000 [==============================] - 53s 906us/step - loss: 0.3027 - accuracy: 0.8557 - val_loss: 0.3617 - val_accuracy: 0.8209\n",
      "Epoch 107/150\n",
      "59000/59000 [==============================] - 54s 913us/step - loss: 0.3024 - accuracy: 0.8554 - val_loss: 0.3652 - val_accuracy: 0.8201\n",
      "Epoch 108/150\n",
      "59000/59000 [==============================] - 62s 1ms/step - loss: 0.3024 - accuracy: 0.8556 - val_loss: 0.3646 - val_accuracy: 0.8195\n",
      "Epoch 109/150\n",
      "59000/59000 [==============================] - 58s 980us/step - loss: 0.3023 - accuracy: 0.8558 - val_loss: 0.3624 - val_accuracy: 0.8207\n",
      "Epoch 110/150\n",
      "59000/59000 [==============================] - 59s 1ms/step - loss: 0.3023 - accuracy: 0.8563 - val_loss: 0.3695 - val_accuracy: 0.8191\n",
      "Epoch 111/150\n",
      "59000/59000 [==============================] - 54s 923us/step - loss: 0.3023 - accuracy: 0.8556 - val_loss: 0.3629 - val_accuracy: 0.8198\n",
      "Epoch 112/150\n",
      "59000/59000 [==============================] - 55s 926us/step - loss: 0.3024 - accuracy: 0.8562 - val_loss: 0.3610 - val_accuracy: 0.8212\n",
      "Epoch 113/150\n",
      "59000/59000 [==============================] - 54s 917us/step - loss: 0.3027 - accuracy: 0.8556 - val_loss: 0.3608 - val_accuracy: 0.8205\n",
      "Epoch 114/150\n",
      "59000/59000 [==============================] - 53s 906us/step - loss: 0.3024 - accuracy: 0.8558 - val_loss: 0.3591 - val_accuracy: 0.8188\n",
      "Epoch 115/150\n",
      "59000/59000 [==============================] - 54s 907us/step - loss: 0.3022 - accuracy: 0.8558 - val_loss: 0.3572 - val_accuracy: 0.8202\n",
      "Epoch 116/150\n",
      "59000/59000 [==============================] - 54s 919us/step - loss: 0.3022 - accuracy: 0.8558 - val_loss: 0.3647 - val_accuracy: 0.8198\n",
      "Epoch 117/150\n",
      "59000/59000 [==============================] - 55s 933us/step - loss: 0.3024 - accuracy: 0.8560 - val_loss: 0.3669 - val_accuracy: 0.8174\n",
      "Epoch 118/150\n",
      "59000/59000 [==============================] - 59s 1ms/step - loss: 0.3025 - accuracy: 0.8561 - val_loss: 0.3604 - val_accuracy: 0.8208\n",
      "Epoch 119/150\n",
      "59000/59000 [==============================] - 57s 974us/step - loss: 0.3024 - accuracy: 0.8556 - val_loss: 0.3547 - val_accuracy: 0.8198\n",
      "Epoch 120/150\n",
      "59000/59000 [==============================] - 55s 935us/step - loss: 0.3026 - accuracy: 0.8560 - val_loss: 0.3630 - val_accuracy: 0.8207\n",
      "Epoch 121/150\n",
      "59000/59000 [==============================] - 54s 910us/step - loss: 0.3022 - accuracy: 0.8557 - val_loss: 0.3661 - val_accuracy: 0.8190\n",
      "Epoch 122/150\n",
      "59000/59000 [==============================] - 54s 907us/step - loss: 0.3023 - accuracy: 0.8555 - val_loss: 0.3615 - val_accuracy: 0.8199\n",
      "Epoch 123/150\n",
      "59000/59000 [==============================] - 53s 899us/step - loss: 0.3025 - accuracy: 0.8555 - val_loss: 0.3623 - val_accuracy: 0.8200\n",
      "Epoch 124/150\n",
      "59000/59000 [==============================] - 53s 896us/step - loss: 0.3024 - accuracy: 0.8557 - val_loss: 0.3630 - val_accuracy: 0.8196\n",
      "Epoch 125/150\n",
      "59000/59000 [==============================] - 53s 902us/step - loss: 0.3024 - accuracy: 0.8558 - val_loss: 0.3566 - val_accuracy: 0.8207\n",
      "Epoch 126/150\n",
      "59000/59000 [==============================] - 54s 917us/step - loss: 0.3023 - accuracy: 0.8553 - val_loss: 0.3625 - val_accuracy: 0.8199\n",
      "Epoch 127/150\n",
      "59000/59000 [==============================] - 57s 967us/step - loss: 0.3024 - accuracy: 0.8560 - val_loss: 0.3596 - val_accuracy: 0.8202\n",
      "Epoch 128/150\n",
      "59000/59000 [==============================] - 55s 940us/step - loss: 0.3023 - accuracy: 0.8554 - val_loss: 0.3605 - val_accuracy: 0.8186\n",
      "Epoch 129/150\n",
      "59000/59000 [==============================] - 60s 1ms/step - loss: 0.3022 - accuracy: 0.8559 - val_loss: 0.3633 - val_accuracy: 0.8188\n",
      "Epoch 130/150\n",
      "59000/59000 [==============================] - 55s 925us/step - loss: 0.3022 - accuracy: 0.8553 - val_loss: 0.3698 - val_accuracy: 0.8169\n",
      "Epoch 131/150\n",
      "59000/59000 [==============================] - 55s 930us/step - loss: 0.3023 - accuracy: 0.8560 - val_loss: 0.3621 - val_accuracy: 0.8192\n",
      "Epoch 132/150\n",
      "59000/59000 [==============================] - 62s 1ms/step - loss: 0.3023 - accuracy: 0.8556 - val_loss: 0.3628 - val_accuracy: 0.8213\n",
      "Epoch 133/150\n",
      "59000/59000 [==============================] - 55s 937us/step - loss: 0.3021 - accuracy: 0.8562 - val_loss: 0.3639 - val_accuracy: 0.8186\n",
      "Epoch 134/150\n",
      "59000/59000 [==============================] - 55s 931us/step - loss: 0.3022 - accuracy: 0.8561 - val_loss: 0.3648 - val_accuracy: 0.8208\n",
      "Epoch 135/150\n",
      "59000/59000 [==============================] - 54s 923us/step - loss: 0.3022 - accuracy: 0.8562 - val_loss: 0.3728 - val_accuracy: 0.8182\n",
      "Epoch 136/150\n",
      "59000/59000 [==============================] - 55s 926us/step - loss: 0.3024 - accuracy: 0.8561 - val_loss: 0.3660 - val_accuracy: 0.8175\n",
      "Epoch 137/150\n",
      "59000/59000 [==============================] - 53s 906us/step - loss: 0.3024 - accuracy: 0.8557 - val_loss: 0.3584 - val_accuracy: 0.8190\n",
      "Epoch 138/150\n",
      "59000/59000 [==============================] - 57s 968us/step - loss: 0.3024 - accuracy: 0.8554 - val_loss: 0.3601 - val_accuracy: 0.8198\n",
      "Epoch 139/150\n",
      "59000/59000 [==============================] - 55s 927us/step - loss: 0.3023 - accuracy: 0.8558 - val_loss: 0.3721 - val_accuracy: 0.8198\n",
      "Epoch 140/150\n",
      "59000/59000 [==============================] - 56s 952us/step - loss: 0.3023 - accuracy: 0.8557 - val_loss: 0.3562 - val_accuracy: 0.8208\n",
      "Epoch 141/150\n",
      "59000/59000 [==============================] - 53s 898us/step - loss: 0.3022 - accuracy: 0.8554 - val_loss: 0.3609 - val_accuracy: 0.8213\n",
      "Epoch 142/150\n",
      "59000/59000 [==============================] - 55s 936us/step - loss: 0.3022 - accuracy: 0.8560 - val_loss: 0.3588 - val_accuracy: 0.8195\n",
      "Epoch 143/150\n",
      "59000/59000 [==============================] - 53s 904us/step - loss: 0.3022 - accuracy: 0.8557 - val_loss: 0.3638 - val_accuracy: 0.8193\n",
      "Epoch 144/150\n",
      "59000/59000 [==============================] - 53s 902us/step - loss: 0.3022 - accuracy: 0.8556 - val_loss: 0.3571 - val_accuracy: 0.8216\n",
      "Epoch 145/150\n",
      "59000/59000 [==============================] - 54s 911us/step - loss: 0.3022 - accuracy: 0.8561 - val_loss: 0.3757 - val_accuracy: 0.8130\n",
      "Epoch 146/150\n",
      "59000/59000 [==============================] - 55s 924us/step - loss: 0.3022 - accuracy: 0.8555 - val_loss: 0.3601 - val_accuracy: 0.8204\n",
      "Epoch 147/150\n",
      "59000/59000 [==============================] - 55s 933us/step - loss: 0.3022 - accuracy: 0.8556 - val_loss: 0.3745 - val_accuracy: 0.8163\n",
      "Epoch 148/150\n",
      "59000/59000 [==============================] - 57s 968us/step - loss: 0.3023 - accuracy: 0.8560 - val_loss: 0.3628 - val_accuracy: 0.8195\n",
      "Epoch 149/150\n",
      "59000/59000 [==============================] - 55s 935us/step - loss: 0.3023 - accuracy: 0.8554 - val_loss: 0.3585 - val_accuracy: 0.8210\n",
      "Epoch 150/150\n",
      "59000/59000 [==============================] - 53s 895us/step - loss: 0.3023 - accuracy: 0.8566 - val_loss: 0.3699 - val_accuracy: 0.8196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd664fdb220>,\n",
       "             n_jobs=6,\n",
       "             param_grid={'batch_size': [3], 'epochs': [75, 100, 150],\n",
       "                         'final_activation': ['sigmoid', 'tanh'],\n",
       "                         'init_activation': ['selu'], 'layer': [1],\n",
       "                         'output_dim': [30]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ggrid.fit(X_train_nb_scale2, y_train, validation_data=(X_test_nb_scale2,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2d2fc0b8-df69-457f-b556-dcbf91c96f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14750/14750 [==============================] - 8s 556us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8195932203389831"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_pred = ggrid.predict(X_test_nb_scale2).flatten()\n",
    "(np.round(nn_pred) == y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "94481428-2bf5-49e3-a2fc-87a1205430d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn.tf/assets\n"
     ]
    }
   ],
   "source": [
    "# params --> acc 0.820\n",
    "{'batch_size': 3,\n",
    " 'epochs': 150,\n",
    " 'final_activation': 'sigmoid',\n",
    " 'init_activation': 'selu',\n",
    " 'layer': 1,\n",
    " 'output_dim': 30}\n",
    "ggrid.best_estimator_.model.save(\"nn.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2cd0eae6-0833-4531-ba4d-af2f14f902ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nb_lda = pd.concat((X_train_nb_scale2, lda_train), axis=1)\n",
    "X_test_nb_lda = pd.concat((X_test_nb_scale2, lda_test), axis=1)\n",
    "X_train_nb_lda[ lda_train.columns ] = scaler.fit_transform( X_train_nb_lda[ lda_train.columns ] )\n",
    "X_test_nb_lda[ lda_train.columns ] = scaler.transform( X_test_nb_lda[ lda_train.columns ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "43f70abc-ca8c-4bb2-8ce2-44a883a137f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline(layer=1, output_dim=3, init_activation='sigmoid', final_activation=\"sigmoid\", optimizer='adam'):\n",
    "    np.random.seed(229)\n",
    "    tf.random.set_seed(229)\n",
    "    model = Sequential()\n",
    "    if layer==1:\n",
    "        model.add(Dense(output_dim, input_dim=X_train_nb_lda.shape[1], activation=init_activation))\n",
    "    if layer==2: \n",
    "        model.add(Dense(output_dim, input_dim=X_train_nb_lda.shape[1], activation=init_activation))\n",
    "        model.add(Dense(output_dim / 2, activation='relu'))\n",
    "    if layer==3: \n",
    "        model.add(Dense(output_dim, input_dim=X_train_nb_lda.shape[1], activation=init_activation))\n",
    "        model.add(Dense(5, activation='relu'))\n",
    "        model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation=final_activation))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c568472e-fb2a-416b-af86-8e9d4ed46228",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [30]\n",
    "batches = [5]\n",
    "layers = [1]\n",
    "output_dims = [25]\n",
    "activations = ['selu']\n",
    "fin_activations=['sigmoid']\n",
    "model_grid = KerasClassifier(build_fn=create_baseline, verbose=1)\n",
    "param_grid = dict(epochs=epochs, batch_size=batches, layer=layers, output_dim=output_dims, init_activation=activations, final_activation=fin_activations)\n",
    "ggrid = GridSearchCV(estimator=model_grid, param_grid=param_grid, cv=3, verbose=3, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "702ec9c0-4354-4c76-b17a-2c2f92b0103c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Epoch 1/30\n",
      "35400/35400 [==============================] - 45s 1ms/step - loss: 0.3569 - accuracy: 0.8255 - val_loss: 0.3831 - val_accuracy: 0.8042\n",
      "Epoch 2/30\n",
      "35400/35400 [==============================] - 43s 1ms/step - loss: 0.3274 - accuracy: 0.8416 - val_loss: 0.3715 - val_accuracy: 0.8115\n",
      "Epoch 3/30\n",
      "35400/35400 [==============================] - 37s 1ms/step - loss: 0.3194 - accuracy: 0.8463 - val_loss: 0.3712 - val_accuracy: 0.8153\n",
      "Epoch 4/30\n",
      "35400/35400 [==============================] - 38s 1ms/step - loss: 0.3155 - accuracy: 0.8486 - val_loss: 0.3687 - val_accuracy: 0.8138\n",
      "Epoch 5/30\n",
      "35400/35400 [==============================] - 61s 2ms/step - loss: 0.3132 - accuracy: 0.8493 - val_loss: 0.3619 - val_accuracy: 0.8159\n",
      "Epoch 6/30\n",
      "35400/35400 [==============================] - 76s 2ms/step - loss: 0.3116 - accuracy: 0.8507 - val_loss: 0.3649 - val_accuracy: 0.8158\n",
      "Epoch 7/30\n",
      "35400/35400 [==============================] - 52s 1ms/step - loss: 0.3101 - accuracy: 0.8513 - val_loss: 0.3669 - val_accuracy: 0.8155\n",
      "Epoch 8/30\n",
      "35400/35400 [==============================] - 43s 1ms/step - loss: 0.3092 - accuracy: 0.8517 - val_loss: 0.3680 - val_accuracy: 0.8163\n",
      "Epoch 9/30\n",
      "35400/35400 [==============================] - 43s 1ms/step - loss: 0.3082 - accuracy: 0.8521 - val_loss: 0.3647 - val_accuracy: 0.8178\n",
      "Epoch 10/30\n",
      "35400/35400 [==============================] - 42s 1ms/step - loss: 0.3077 - accuracy: 0.8530 - val_loss: 0.3642 - val_accuracy: 0.8184\n",
      "Epoch 11/30\n",
      "35400/35400 [==============================] - 39s 1ms/step - loss: 0.3069 - accuracy: 0.8536 - val_loss: 0.3639 - val_accuracy: 0.8186\n",
      "Epoch 12/30\n",
      "35400/35400 [==============================] - 41s 1ms/step - loss: 0.3065 - accuracy: 0.8531 - val_loss: 0.3635 - val_accuracy: 0.8169\n",
      "Epoch 13/30\n",
      "35400/35400 [==============================] - 41s 1ms/step - loss: 0.3058 - accuracy: 0.8538 - val_loss: 0.3639 - val_accuracy: 0.8171\n",
      "Epoch 14/30\n",
      "35400/35400 [==============================] - 42s 1ms/step - loss: 0.3053 - accuracy: 0.8540 - val_loss: 0.3650 - val_accuracy: 0.8179\n",
      "Epoch 15/30\n",
      "35400/35400 [==============================] - 43s 1ms/step - loss: 0.3050 - accuracy: 0.8540 - val_loss: 0.3621 - val_accuracy: 0.8184\n",
      "Epoch 16/30\n",
      "35400/35400 [==============================] - 47s 1ms/step - loss: 0.3046 - accuracy: 0.8544 - val_loss: 0.3651 - val_accuracy: 0.8167\n",
      "Epoch 17/30\n",
      "35400/35400 [==============================] - 47s 1ms/step - loss: 0.3043 - accuracy: 0.8537 - val_loss: 0.3638 - val_accuracy: 0.8168\n",
      "Epoch 18/30\n",
      "35400/35400 [==============================] - 44s 1ms/step - loss: 0.3038 - accuracy: 0.8548 - val_loss: 0.3634 - val_accuracy: 0.8179\n",
      "Epoch 19/30\n",
      "35400/35400 [==============================] - 47s 1ms/step - loss: 0.3035 - accuracy: 0.8550 - val_loss: 0.3668 - val_accuracy: 0.8163\n",
      "Epoch 20/30\n",
      "35400/35400 [==============================] - 72s 2ms/step - loss: 0.3033 - accuracy: 0.8546 - val_loss: 0.3620 - val_accuracy: 0.8198\n",
      "Epoch 21/30\n",
      "35400/35400 [==============================] - 44s 1ms/step - loss: 0.3029 - accuracy: 0.8551 - val_loss: 0.3635 - val_accuracy: 0.8189\n",
      "Epoch 22/30\n",
      "35400/35400 [==============================] - 46s 1ms/step - loss: 0.3028 - accuracy: 0.8552 - val_loss: 0.3626 - val_accuracy: 0.8184\n",
      "Epoch 23/30\n",
      "35400/35400 [==============================] - 45s 1ms/step - loss: 0.3024 - accuracy: 0.8557 - val_loss: 0.3616 - val_accuracy: 0.8196\n",
      "Epoch 24/30\n",
      "35400/35400 [==============================] - 38s 1ms/step - loss: 0.3024 - accuracy: 0.8550 - val_loss: 0.3632 - val_accuracy: 0.8178\n",
      "Epoch 25/30\n",
      "35400/35400 [==============================] - 46s 1ms/step - loss: 0.3021 - accuracy: 0.8558 - val_loss: 0.3644 - val_accuracy: 0.8161\n",
      "Epoch 26/30\n",
      "35400/35400 [==============================] - 38s 1ms/step - loss: 0.3019 - accuracy: 0.8559 - val_loss: 0.3622 - val_accuracy: 0.8184\n",
      "Epoch 27/30\n",
      "35400/35400 [==============================] - 48s 1ms/step - loss: 0.3018 - accuracy: 0.8554 - val_loss: 0.3600 - val_accuracy: 0.8178\n",
      "Epoch 28/30\n",
      "35400/35400 [==============================] - 44s 1ms/step - loss: 0.3015 - accuracy: 0.8562 - val_loss: 0.3686 - val_accuracy: 0.8155\n",
      "Epoch 29/30\n",
      "35400/35400 [==============================] - 46s 1ms/step - loss: 0.3013 - accuracy: 0.8560 - val_loss: 0.3630 - val_accuracy: 0.8182\n",
      "Epoch 30/30\n",
      "35400/35400 [==============================] - 47s 1ms/step - loss: 0.3012 - accuracy: 0.8567 - val_loss: 0.3698 - val_accuracy: 0.8143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd5d277d430>,\n",
       "             n_jobs=6,\n",
       "             param_grid={'batch_size': [5], 'epochs': [30],\n",
       "                         'final_activation': ['sigmoid'],\n",
       "                         'init_activation': ['selu'], 'layer': [1, 2],\n",
       "                         'output_dim': [20, 30, 50, 100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ggrid.fit(X_train_nb_lda, y_train, validation_data=(X_test_nb_lda,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "49e152f4-dc00-4b47-98a6-b124e0b6c052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 5,\n",
       " 'epochs': 30,\n",
       " 'final_activation': 'sigmoid',\n",
       " 'init_activation': 'selu',\n",
       " 'layer': 1,\n",
       " 'output_dim': 20}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ggrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "58825910-3642-4f30-86f6-3541c56be176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benji/anaconda3/envs/play/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8850/8850 [==============================] - 5s 514us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8143050847457627"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_pred = ggrid.predict(X_test_nb_lda).flatten()\n",
    "(np.round(nn_pred) == y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b9bd7f16-304e-4da3-8963-6c73ff59352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e24e91d5-b25e-414f-9bde-69d5852b0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=229, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "80b90d94-e30e-49ef-a5e0-88c198a3f08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=229)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train_nb_w2v[0:10000], y_train[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9521e156-959a-4f8f-9909-72251bbacf64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7595"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = svm.predict(X_test_nb_w2v[0:10000])\n",
    "(ypred==y_test[0:10000]).sum() / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "92c1b517-7bd4-4d8e-b37a-86e5c4d7b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nb_w2v = pd.concat((X_train_nb_scale2, pd.DataFrame(w2v_train)), axis=1)\n",
    "X_test_nb_w2v = pd.concat((X_test_nb_scale2, pd.DataFrame(w2v_test)), axis=1)\n",
    "X_train_nb_w2v[ w2v_train.columns ] = scaler.fit_transform( X_train_nb_w2v[ w2v_train.columns ] )\n",
    "X_test_nb_w2v[ w2v_train.columns ] = scaler.transform( X_test_nb_w2v[ w2v_train.columns ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "50116745-3652-4423-b783-232dc1f1ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline(layer=1, output_dim=3, init_activation='sigmoid', final_activation=\"sigmoid\", optimizer='adam'):\n",
    "    np.random.seed(229)\n",
    "    tf.random.set_seed(229)\n",
    "    model = Sequential()\n",
    "    if layer==1:\n",
    "        model.add(Dense(output_dim, input_dim=X_train_nb_w2v.shape[1], activation=init_activation))\n",
    "    model.add(Dense(1, activation=final_activation))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "67eef4c1-46e5-486c-b427-9f3ccccc9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [100]\n",
    "batches = [3]\n",
    "layers = [1]\n",
    "output_dims = [20, 25, 30, 35]\n",
    "activations = ['selu']\n",
    "fin_activations=['sigmoid']\n",
    "model_grid = KerasClassifier(build_fn=create_baseline, verbose=1)\n",
    "param_grid = dict(epochs=epochs, batch_size=batches, layer=layers, output_dim=output_dims, init_activation=activations, final_activation=fin_activations)\n",
    "ggrid = GridSearchCV(estimator=model_grid, param_grid=param_grid, cv=3, verbose=3, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "df81b768-5186-4d59-8c3b-94435105dcfb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-8fb5b2ada9c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mggrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nb_w2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nb_w2v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    560\u001b[0m         \"\"\"\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/joblib/executor.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, kill_workers)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkill_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# When workers are killed in such a brutal manner, they cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexecutor_manager_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m             \u001b[0mexecutor_manager_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/play/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ggrid.fit(X_train_nb_w2v, y_train, validation_data=(X_test_nb_w2v,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0f03bfe8-6fe6-403b-b276-347505b7b56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16742"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d673db-1996-40ee-8bb4-9cb0c999b514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87579e0a-47d3-4031-aab4-140a365fe0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae080d7-cc8f-45e2-9006-39811e2c47f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd853f7b-e6a2-4689-a53f-2d5a3253e2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07156e5-6040-423e-b7bf-fd1749a2c842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b848d-59d4-450b-b557-015208e75163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f24332d9-2287-4325-9091-f8f96b09992b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8207909604519774"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model w/ params acc -> 0.821\n",
    "{'batch_size': 5,\n",
    " 'epochs': 50,\n",
    " 'init_activation': 'selu',\n",
    " 'layer': 1,\n",
    " 'output_dim': 30}\n",
    "(np.round(nn_pred) == y_test).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25024b28-e8c1-4ff1-8761-99913eafc8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
