{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import json\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "from model_metrics import format_results\n",
    "import data_clean_for_model\n",
    "import PipelineHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Load Data\n",
    "df = pd.read_parquet(\"data/all_processed_df.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "rseed = 229\n",
    "df[\"outcome\"] = np.where( df[\"state\"]==\"successful\", 1, 0, )\n",
    "df[\"un_id\"] = np.arange(0, df.shape[0], 1 )\n",
    "df[\"name_len\"] = df[\"name\"].str.len()\n",
    "df[\"cv_group\"] = np.random.choice( np.arange(0, k), size=df.shape[0] )\n",
    "df[\"binned_usd_goal\"] = pd.qcut( np.log(df[\"usd_goal\"]+1), 20 )\n",
    "\n",
    "with open(\"model_config.json\", 'r') as j:\n",
    "     model_params = json.loads(j.read())\n",
    "model_params['naive_bayes']['ngram_range'] = tuple(model_params['naive_bayes']['ngram_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading features\n"
     ]
    }
   ],
   "source": [
    "## load project metadata\n",
    "logger.info(\"Loading features\")\n",
    "try:\n",
    "    f = open(\"data/features.pkl\", \"rb\")\n",
    "    ft_dict = pickle.load(f)\n",
    "    f.close()\n",
    "    X_train, y_train, X_test, y_test = ft_dict.values()\n",
    "except:\n",
    "    X_train, X_test, y_train, y_test = data_clean_for_model.data_clean_for_model(df, \"outcome\", model_params, cv=model_params[\"cv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing text data\n"
     ]
    }
   ],
   "source": [
    "# load text\n",
    "logger.info(\"Processing text data\")\n",
    "blurb_train, blurb_test, _, _    = data_clean_for_model.process_blurb(df, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221248/221248 [1:19:40<00:00, 46.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "0       1.0\n",
      "1       2.0\n",
      "2       1.5\n",
      "3       1.5\n",
      "4       2.0\n",
      "       ... \n",
      "1628    3.0\n",
      "1633    2.5\n",
      "1640    3.0\n",
      "1662    1.0\n",
      "1736    2.0\n",
      "Name: sentiment, Length: 221248, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'] = np.empty(df.shape[0])\n",
    "for i in tqdm(range(len(df.blurb.index))):\n",
    "    if not isinstance(df.blurb.iloc[i], str):\n",
    "        df.sentiment.iloc[i] = 2\n",
    "        continue\n",
    "    result = nlp.annotate(df.blurb.iloc[i],\n",
    "                       properties={\n",
    "                           'annotators': 'sentiment,',\n",
    "                           'outputFormat': 'json',\n",
    "                       })\n",
    "    total = 0\n",
    "    numSentences = 0\n",
    "    for s in result['sentences']:\n",
    "        total += int(s['sentimentValue'])\n",
    "        numSentences += 1\n",
    "    df.sentiment.iloc[i] = total/numSentences\n",
    "print(df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"sentiment\"]\n",
    "df.to_csv('sentiment_col.csv', columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Run text models\n",
    "\n",
    "try: \n",
    "    f = open(\"data/res/text_models.pkl\", \"rb\")\n",
    "    text_models = pickle.load(f)\n",
    "    f.close()\n",
    "except:\n",
    "    raise Warning(\"Text models do not exist. Will load from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading Naive Bayes predictions\n",
      "INFO:__main__:Loading LDA topic predictions\n",
      "INFO:__main__:Loading Word2Vec dimension predictions\n"
     ]
    }
   ],
   "source": [
    "# get naive bayes predictions\n",
    "logger.info(\"Loading Naive Bayes predictions\")\n",
    "try:\n",
    "    #nb_proba_train = np.load(\"data/res/multi_nb_preds_train.npy\")\n",
    "    #nb_proba_test = np.load(\"data/res/multi_nb_preds_test.npy\")\n",
    "    nb_proba_train, nb_proba_test = text_models['nb_train'], text_models['nb_test']\n",
    "except:\n",
    "    logger.info(\"Running Naive Bayes model\")\n",
    "    nb_params = model_params['naive_bayes']\n",
    "    nb_train_pred, nb_proba_train, nb_test_pred, nb_proba_test = PipelineHelper.naive_bayes_predictions(\n",
    "        blurb_train, y_train, blurb_test,\n",
    "        tfidf=nb_params['tf-idf'], ngram_range=nb_params['ngram_range']\n",
    "    )\n",
    "    np.save(\"data/res/multi_nb_preds_train.npy\", nb_proba_train)\n",
    "    np.save(\"data/res/multi_nb_preds_test.npy\", nb_proba_test)\n",
    "\n",
    "# get LDA topic model\n",
    "logger.info(\"Loading LDA topic predictions\")\n",
    "try:\n",
    "    lda_train, lda_test = text_models['lda_train'], text_models['lda_test']\n",
    "    #lda_train = pd.read_csv(\"data/res/lda_train.csv\").drop(columns=['Unnamed: 0'])\n",
    "    #lda_test = pd.read_csv(\"data/res/lda_test.csv\").drop(columns=['Unnamed: 0'])\n",
    "except:\n",
    "    logger.info(\"Running LDA topic model\")\n",
    "    lda_params = model_params['lda']\n",
    "    tokenized_train = blurb_train.apply(data_clean_for_model.tokenize_text)\n",
    "    tokenized_test = blurb_test.apply(data_clean_for_model.tokenize_text)\n",
    "    lda_train, lda_test = PipelineHelper.train_lda_model(tokenized_train, tokenized_test, params['lda'])\n",
    "    lda_train.to_csv(\"data/res/lda_train.csv\")\n",
    "    lda_test.to_csv(\"data/res/lda_test.csv\")\n",
    "\n",
    "# get Word2Vec model predictions\n",
    "logger.info(\"Loading Word2Vec dimension predictions\")\n",
    "try:\n",
    "    #f = open(\"data/res/w2v_dict.pkl\", \"rb\")\n",
    "    #w2v_dict = pickle.load(f)\n",
    "    #f.close()\n",
    "    #w2v_train, w2v_test = w2v_dict.values()\n",
    "    w2v_train, w2v_test = text_models['w2v_train'], text_models['w2v_test']\n",
    "except:\n",
    "    raise Warning(\"Word2Vec function not implemented. Running without it -- likely will crash.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.10488e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
     ]
    }
   ],
   "source": [
    "### a. Just on metadata\n",
    "logger.info(\"Getting metadata results\")\n",
    "stat_df, pred_df, models = PipelineHelper.run_analyses(X_train, y_train, X_test, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata - binned_usd_goal_outcome_mean results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.10488e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
     ]
    }
   ],
   "source": [
    "### b. Just on metadata, - binned_usd_goal_outcome_mean\n",
    "logger.info(\"Getting metadata - binned_usd_goal_outcome_mean results\")\n",
    "stat_df_nobinusd, pred_df_nobinusd, models_nobinusd = PipelineHelper.run_analyses(\n",
    "    X_train.drop(columns=['binned_usd_goal_outcome_mean']), y_train, \n",
    "    X_test.drop(columns=['binned_usd_goal_outcome_mean']), y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata + naive bayes results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.10488e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
     ]
    }
   ],
   "source": [
    "### c. Just on metadata + nb \n",
    "logger.info(\"Getting metadata + naive bayes results\")\n",
    "X_train_nb = X_train.copy()\n",
    "X_test_nb = X_test.copy()\n",
    "# NB \n",
    "X_train_nb['nb_proba'] = nb_proba_train[:, 1]\n",
    "X_test_nb['nb_proba'] = nb_proba_test[:, 1]\n",
    "stat_df_nb, pred_df_nb, models_nb = PipelineHelper.run_analyses(X_train_nb, y_train, X_test_nb, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata + naive bayes + LDA results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.10487e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
     ]
    }
   ],
   "source": [
    "### d. Just on metadata + nb + lda\n",
    "logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "X_train_nb_lda = pd.concat((X_train_nb, lda_train), axis=1)\n",
    "X_test_nb_lda = pd.concat((X_test_nb, lda_test), axis=1)\n",
    "stat_df_nb_lda, pred_df_nb_lda, models_nb_lda = PipelineHelper.run_analyses(X_train_nb_lda, y_train, X_test_nb_lda, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata + naive bayes + w2v results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.1047e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
     ]
    }
   ],
   "source": [
    "### e. Just on metadata + nb + w2v\n",
    "logger.info(\"Getting metadata + naive bayes + w2v results\")\n",
    "X_train_nb_w2v = pd.concat((X_train_nb, pd.DataFrame(w2v_train)), axis=1)\n",
    "X_test_nb_w2v = pd.concat((X_test_nb, pd.DataFrame(w2v_test)), axis=1)\n",
    "stat_df_nb_w2v, pred_df_nb_w2v, models_nb_w2v = PipelineHelper.run_analyses(X_train_nb_w2v, y_train, X_test_nb_w2v, y_test, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Getting metadata + naive bayes + LDA results\n",
      "INFO:PipelineHelper:Fitting linear models\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.83344e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "INFO:PipelineHelper:Fitting lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PipelineHelper:Fitting random forest\n",
      "INFO:PipelineHelper:Fitting SVM\n"
     ]
    }
   ],
   "source": [
    "### f. Just on metadata + nb + lda - cols to drop \n",
    "logger.info(\"Getting metadata + naive bayes + LDA results\")\n",
    "cols_to_drop = [\n",
    "    'dummy_cat_id_290', 'dummy_cat_id_300', 'dummy_cat_id_317','dummy_cat_id_386', 'dummy_cat_id_352', #'dummy_cat_id_1',\n",
    "    'dummy_cat_id_355', 'dummy_cat_id_354', 'dummy_cat_id_321', 'dummy_cat_id_12', 'dummy_cat_id_340', 'dummy_cat_id_268', 'binned_usd_goal_outcome_mean'\n",
    "]\n",
    "stat_df_nb_lda_drop, pred_df_nb_lda_drop, models_nb_lda_drop = PipelineHelper.run_analyses(\n",
    "    X_train_nb_lda.drop(columns=cols_to_drop), y_train, \n",
    "    X_test_nb_lda.drop(columns=cols_to_drop), y_test, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df.insert(0, \"data\", \"metadata\"), \n",
    "stat_df_nobinusd.insert(0, \"data\", \"metadata_nobin\"), \n",
    "stat_df_nb.insert(0, \"data\", \"metadata_nb\"),\n",
    "stat_df_nb_lda.insert(0, \"data\", \"metadata_nb_lda\"),\n",
    "stat_df_nb_w2v.insert(0, \"data\", \"metadata_nb_w2v\"),\n",
    "stat_df_nb_lda_drop.insert(0, \"data\", \"metadata_nb_lda_drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>accuracy_rank</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.825431</td>\n",
       "      <td>0.848953</td>\n",
       "      <td>0.885703</td>\n",
       "      <td>0.750599</td>\n",
       "      <td>0.815130</td>\n",
       "      <td>0.841002</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.174569</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda_drop</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.823443</td>\n",
       "      <td>0.847502</td>\n",
       "      <td>0.882493</td>\n",
       "      <td>0.749517</td>\n",
       "      <td>0.815180</td>\n",
       "      <td>0.835932</td>\n",
       "      <td>0.825556</td>\n",
       "      <td>0.176557</td>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_w2v</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.823292</td>\n",
       "      <td>0.849325</td>\n",
       "      <td>0.872308</td>\n",
       "      <td>0.758067</td>\n",
       "      <td>0.827521</td>\n",
       "      <td>0.816899</td>\n",
       "      <td>0.822210</td>\n",
       "      <td>0.176708</td>\n",
       "      <td>3</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.822885</td>\n",
       "      <td>0.846587</td>\n",
       "      <td>0.884252</td>\n",
       "      <td>0.747070</td>\n",
       "      <td>0.812001</td>\n",
       "      <td>0.839337</td>\n",
       "      <td>0.825669</td>\n",
       "      <td>0.177115</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metadata_nb</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.814945</td>\n",
       "      <td>0.838926</td>\n",
       "      <td>0.880942</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.800736</td>\n",
       "      <td>0.836423</td>\n",
       "      <td>0.818580</td>\n",
       "      <td>0.185055</td>\n",
       "      <td>5</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data                   model  accuracy  f1_score  \\\n",
       "0           metadata_nb          LGBMClassifier  0.825431  0.848953   \n",
       "0  metadata_nb_lda_drop          LGBMClassifier  0.823443  0.847502   \n",
       "0       metadata_nb_w2v          LGBMClassifier  0.823292  0.849325   \n",
       "0       metadata_nb_lda          LGBMClassifier  0.822885  0.846587   \n",
       "1           metadata_nb  RandomForestClassifier  0.814945  0.838926   \n",
       "\n",
       "   precision_1  precision_0  recall_1  recall_0   roc_auc     brier  \\\n",
       "0     0.885703     0.750599  0.815130  0.841002  0.828066  0.174569   \n",
       "0     0.882493     0.749517  0.815180  0.835932  0.825556  0.176557   \n",
       "0     0.872308     0.758067  0.827521  0.816899  0.822210  0.176708   \n",
       "0     0.884252     0.747070  0.812001  0.839337  0.825669  0.177115   \n",
       "1     0.880942     0.735240  0.800736  0.836423  0.818580  0.185055   \n",
       "\n",
       "   accuracy_rank  random_state  \n",
       "0              1           229  \n",
       "0              2           229  \n",
       "0              3           229  \n",
       "0              4           229  \n",
       "1              5           229  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin = (pd.concat((stat_df, stat_df_nobinusd, stat_df_nb, stat_df_nb_lda, stat_df_nb_w2v, stat_df_nb_lda_drop))\n",
    "       .sort_values('accuracy', ascending=False)\n",
    "       .assign(\n",
    "           accuracy_rank = lambda x:np.arange(1, x.shape[0]+1, 1), \n",
    "           random_state = model_params['rseed']\n",
    "       )\n",
    "      )\n",
    "fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>brier</th>\n",
       "      <th>accuracy_rank</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.798825</td>\n",
       "      <td>0.827674</td>\n",
       "      <td>0.854209</td>\n",
       "      <td>0.726721</td>\n",
       "      <td>0.802739</td>\n",
       "      <td>0.792909</td>\n",
       "      <td>0.797824</td>\n",
       "      <td>0.201175</td>\n",
       "      <td>14</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.798644</td>\n",
       "      <td>0.827746</td>\n",
       "      <td>0.853090</td>\n",
       "      <td>0.727317</td>\n",
       "      <td>0.803865</td>\n",
       "      <td>0.790752</td>\n",
       "      <td>0.797309</td>\n",
       "      <td>0.201356</td>\n",
       "      <td>16</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_lda_drop</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.798478</td>\n",
       "      <td>0.827917</td>\n",
       "      <td>0.851626</td>\n",
       "      <td>0.728246</td>\n",
       "      <td>0.805492</td>\n",
       "      <td>0.787876</td>\n",
       "      <td>0.796684</td>\n",
       "      <td>0.201522</td>\n",
       "      <td>17</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nb_w2v</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.796640</td>\n",
       "      <td>0.829674</td>\n",
       "      <td>0.836493</td>\n",
       "      <td>0.738790</td>\n",
       "      <td>0.822965</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>0.789907</td>\n",
       "      <td>0.203360</td>\n",
       "      <td>22</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata_nobin</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.783473</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.866331</td>\n",
       "      <td>0.691560</td>\n",
       "      <td>0.757028</td>\n",
       "      <td>0.823445</td>\n",
       "      <td>0.790236</td>\n",
       "      <td>0.216527</td>\n",
       "      <td>28</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metadata</td>\n",
       "      <td>SVMClassifier</td>\n",
       "      <td>0.783292</td>\n",
       "      <td>0.807014</td>\n",
       "      <td>0.869546</td>\n",
       "      <td>0.689443</td>\n",
       "      <td>0.752873</td>\n",
       "      <td>0.829272</td>\n",
       "      <td>0.791072</td>\n",
       "      <td>0.216708</td>\n",
       "      <td>30</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data          model  accuracy  f1_score  precision_1  \\\n",
       "0       metadata_nb_lda  SVMClassifier  0.798825  0.827674     0.854209   \n",
       "0           metadata_nb  SVMClassifier  0.798644  0.827746     0.853090   \n",
       "0  metadata_nb_lda_drop  SVMClassifier  0.798478  0.827917     0.851626   \n",
       "0       metadata_nb_w2v  SVMClassifier  0.796640  0.829674     0.836493   \n",
       "0        metadata_nobin  SVMClassifier  0.783473  0.808000     0.866331   \n",
       "0              metadata  SVMClassifier  0.783292  0.807014     0.869546   \n",
       "\n",
       "   precision_0  recall_1  recall_0   roc_auc     brier  accuracy_rank  \\\n",
       "0     0.726721  0.802739  0.792909  0.797824  0.201175             14   \n",
       "0     0.727317  0.803865  0.790752  0.797309  0.201356             16   \n",
       "0     0.728246  0.805492  0.787876  0.796684  0.201522             17   \n",
       "0     0.738790  0.822965  0.756849  0.789907  0.203360             22   \n",
       "0     0.691560  0.757028  0.823445  0.790236  0.216527             28   \n",
       "0     0.689443  0.752873  0.829272  0.791072  0.216708             30   \n",
       "\n",
       "   random_state  \n",
       "0           229  \n",
       "0           229  \n",
       "0           229  \n",
       "0           229  \n",
       "0           229  \n",
       "0           229  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin.loc[fin['model'] == \"SVMClassifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata_metadata_LinearRegression_pred</th>\n",
       "      <th>metadata_metadata_Lasso_pred</th>\n",
       "      <th>metadata_metadata_Ridge_pred</th>\n",
       "      <th>metadata_metadata_LogisticRegression_pred</th>\n",
       "      <th>metadata_metadata_LGBMClassifier_pred</th>\n",
       "      <th>metadata_metadata_RandomForestClassifier_pred</th>\n",
       "      <th>metadata_nobin_LinearRegression_pred</th>\n",
       "      <th>metadata_nobin_Lasso_pred</th>\n",
       "      <th>metadata_nobin_Ridge_pred</th>\n",
       "      <th>metadata_nobin_LogisticRegression_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>metadata_nb_w2v_Ridge_pred</th>\n",
       "      <th>metadata_nb_w2v_LogisticRegression_pred</th>\n",
       "      <th>metadata_nb_w2v_LGBMClassifier_pred</th>\n",
       "      <th>metadata_nb_w2v_RandomForestClassifier_pred</th>\n",
       "      <th>metadata_nb_lda_drop_LinearRegression_pred</th>\n",
       "      <th>metadata_nb_lda_drop_Lasso_pred</th>\n",
       "      <th>metadata_nb_lda_drop_Ridge_pred</th>\n",
       "      <th>metadata_nb_lda_drop_LogisticRegression_pred</th>\n",
       "      <th>metadata_nb_lda_drop_LGBMClassifier_pred</th>\n",
       "      <th>metadata_nb_lda_drop_RandomForestClassifier_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.832675</td>\n",
       "      <td>0.651824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.655646</td>\n",
       "      <td>0.832675</td>\n",
       "      <td>0.652055</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800469</td>\n",
       "      <td>0.832675</td>\n",
       "      <td>0.803503</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144957</td>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.144069</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138541</td>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.137552</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136281</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072070</td>\n",
       "      <td>0.473552</td>\n",
       "      <td>0.079891</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488107</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.488423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479006</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.479338</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577682</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.581687</td>\n",
       "      <td>0.425906</td>\n",
       "      <td>0.579625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.036096</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.037228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.027969</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.028984</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.201803</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.107628</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.102822</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.154730</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.154283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192137</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.191644</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278180</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.279277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   metadata_metadata_LinearRegression_pred  metadata_metadata_Lasso_pred  \\\n",
       "0                                 0.655400                      0.832675   \n",
       "1                                 0.144957                      0.473552   \n",
       "2                                 0.488107                      0.425906   \n",
       "3                                 1.036096                      0.832221   \n",
       "4                                 0.154730                      0.290907   \n",
       "\n",
       "   metadata_metadata_Ridge_pred  metadata_metadata_LogisticRegression_pred  \\\n",
       "0                      0.651824                                          1   \n",
       "1                      0.144069                                          1   \n",
       "2                      0.488423                                          1   \n",
       "3                      1.037228                                          1   \n",
       "4                      0.154283                                          0   \n",
       "\n",
       "   metadata_metadata_LGBMClassifier_pred  \\\n",
       "0                                      1   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      1   \n",
       "4                                      0   \n",
       "\n",
       "   metadata_metadata_RandomForestClassifier_pred  \\\n",
       "0                                              1   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              1   \n",
       "4                                              0   \n",
       "\n",
       "   metadata_nobin_LinearRegression_pred  metadata_nobin_Lasso_pred  \\\n",
       "0                              0.655646                   0.832675   \n",
       "1                              0.138541                   0.473552   \n",
       "2                              0.479006                   0.425906   \n",
       "3                              1.027969                   0.832221   \n",
       "4                              0.192137                   0.290907   \n",
       "\n",
       "   metadata_nobin_Ridge_pred  metadata_nobin_LogisticRegression_pred  ...  \\\n",
       "0                   0.652055                                       1  ...   \n",
       "1                   0.137552                                       1  ...   \n",
       "2                   0.479338                                       1  ...   \n",
       "3                   1.028984                                       1  ...   \n",
       "4                   0.191644                                       0  ...   \n",
       "\n",
       "   metadata_nb_w2v_Ridge_pred  metadata_nb_w2v_LogisticRegression_pred  \\\n",
       "0                    0.761006                                        1   \n",
       "1                    0.136281                                        1   \n",
       "2                    0.577682                                        1   \n",
       "3                    1.201803                                        1   \n",
       "4                    0.140261                                        0   \n",
       "\n",
       "   metadata_nb_w2v_LGBMClassifier_pred  \\\n",
       "0                                    1   \n",
       "1                                    0   \n",
       "2                                    1   \n",
       "3                                    1   \n",
       "4                                    0   \n",
       "\n",
       "   metadata_nb_w2v_RandomForestClassifier_pred  \\\n",
       "0                                            1   \n",
       "1                                            0   \n",
       "2                                            1   \n",
       "3                                            1   \n",
       "4                                            0   \n",
       "\n",
       "   metadata_nb_lda_drop_LinearRegression_pred  \\\n",
       "0                                    0.800469   \n",
       "1                                    0.072070   \n",
       "2                                    0.581687   \n",
       "3                                    1.107628   \n",
       "4                                    0.278180   \n",
       "\n",
       "   metadata_nb_lda_drop_Lasso_pred  metadata_nb_lda_drop_Ridge_pred  \\\n",
       "0                         0.832675                         0.803503   \n",
       "1                         0.473552                         0.079891   \n",
       "2                         0.425906                         0.579625   \n",
       "3                         0.832221                         1.102822   \n",
       "4                         0.290907                         0.279277   \n",
       "\n",
       "   metadata_nb_lda_drop_LogisticRegression_pred  \\\n",
       "0                                             1   \n",
       "1                                             1   \n",
       "2                                             1   \n",
       "3                                             1   \n",
       "4                                             0   \n",
       "\n",
       "   metadata_nb_lda_drop_LGBMClassifier_pred  \\\n",
       "0                                         1   \n",
       "1                                         0   \n",
       "2                                         1   \n",
       "3                                         1   \n",
       "4                                         0   \n",
       "\n",
       "   metadata_nb_lda_drop_RandomForestClassifier_pred  \n",
       "0                                                 1  \n",
       "1                                                 0  \n",
       "2                                                 0  \n",
       "3                                                 1  \n",
       "4                                                 0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.columns = \"metadata_\" + pred_df.columns\n",
    "pred_df_nobinusd.columns = \"metadata_nobin_\" + pred_df_nobinusd.columns\n",
    "pred_df_nb.columns = \"metadata_nb_\" + pred_df_nb.columns\n",
    "pred_df_nb_lda.columns = \"metadata_nb_lda_\" + pred_df_nb_lda.columns\n",
    "pred_df_nb_w2v.columns = \"metadata_nb_w2v_\" + pred_df_nb_w2v.columns\n",
    "pred_df_nb_lda_drop.columns = \"metadata_nb_lda_drop_\" + pred_df_nb_lda_drop.columns\n",
    "pred_fin = pd.concat((pred_df, pred_df_nobinusd, pred_df_nb, pred_df_nb_lda, pred_df_nb_w2v, pred_df_nb_lda_drop), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}